\chapter{Protocol Runtime}
\label{sec:protocol_runtime}
In this section we explore the Rust implementation of Reo-generated protocol objects. Rather that generating the needed structures and behaviour from scratch each time, the Rust back-end follows the precedent of the well-established Java back-end and relies on a single, re-usable dependency for the work common to all protocols. Here, we explore the implementation of this \textbf{Reo-rs} library, picking up where we left off from the generation step in Chapter~\ref{sec:imperative_form} above.

\section{Examining the Java Implementation}
\label{sec:java_examined}
The work of this project can draw from the efforts of previous work on the Reo Compiler. The Java implementation in particular has seen the most frequent and recent updates. This section treats the Java code generator as a touchstone for Reo-generated application code in general. We give a brief overview of the properties inherent to the generated code, and consider the effects of projecting the underlying ideas to the Rust language.

\subsection{Structure: Ports, Threads and Components}
Fundamentally, the generated code adheres closely to Reo's literature, revolving around the interplay between \code{Port} and \code{Component} objects. From the perspective of a developer looking to integrate a generated Java protocol into their application, the entry point is the \code{Protocol} component (where `Protocol' is the name of the associated Reo connector).

Running a system requires an initialization procedure: (1) a \code{Port} is instantiated per logical port, (2) a \code{Component} is instantiated per logical component, and (3) pairs of components are linked by overwriting a port-field for both objects with the same instance of \code{Port}. To get things going, each component must be provided a thread to enter it's main loop; in idiomatic Java, this manifests as calling \code{new Thread(C).start()} for each component \code{C}. A simplified example of the initialization procedure is shown in Listing~\ref{listing:java_gen_1} for the simple `sync' protocol which acts as a one-way channel. In this example, the ports are of type \code{String}.


\begin{listing}[ht]
	\centering
	\inputminted[]{java}{java_gen_1.java}
	\caption[Reo-generated Java protocol initialization.]{A simplified example of initialization for a system centered around a \code{Sync} protocol object, which acts as a channel for transmitting objects of type \code{String}. Both ports and components are constructed before they are `linked' in both directions: each port stores a reference to its components, and each component stores references to its ports. The system begins to \textit{run} when each component is given a thread and started.}
	\label{listing:java_gen_1}
\end{listing}


In a sense, this implementation primarily hinges on \code{Port} as a communication primitive between threads, and equivalently, between components. For matters of concurrency, operations on port-data involves entering a \textit{critical region}. In contrast, \code{Components} are used only to store their ports and to be used as name spaces for their \code{run} function which implements their behavior (which corresponds to RBA rules in the case of the protocol component). Essentially, anything that interacts with \code{Port} objects can reify a logical component, whether or not this is done by an object implementing the \code{Component} interface.

\subsection{Behavior: Rules}
The representation of protocol rules is very intuitive; a rule is implemented as a block of code which operates on a component's ports. Once generated into Java, the only obvious sign that a component was generated from Reo is its linkage to multiple other components\footnote{The distinction between `protocol' and `compute' components is tenuous at the best of times. If compute components are allowed to interact directly with one another, the distinction observed here disappears also.}. The (simplified) generated \code{Component} code of the `sync' protocol from the previous section is shown in Listing~\ref{listing:java_gen_2}. This demonstrates that rules are indeed \textit{commandified}, in that their behavior is encoded in discernible structures (appropriately called \code{Command}).

The behavior and structure of a component go together, and are generated by Reo at a relatively granular level. As such, the encoding of memory cells is natural also. Memory cells can be found next to ports in the fields of a \code{Component}.

\begin{listing}[ht]
	\centering
	\inputminted{java}{java_gen_2.java}
	\caption[Reo-generated Java protocol class of the sync connector.]{A simplified example of a Reo-generated Java protocol class for the \textit{sync} connector. By convention, it is started by invoking \code{start}, which is a method inherited from the \code{Runnable} interface which \code{Component} extends. This method assumes that all ports are correctly initialized and linked to another `compute' port. Its RBA-like behavior comes from an array of guards and commands which it iterates over in a loop, firing rules as possible forever.}
	\label{listing:java_gen_2}
\end{listing}

\subsection{Observations}
\label{sec:java_observations}
It is very easy to see the correspondence between a generated Java protocol and its Reo definition. This carries over to how components and ports are used by an application developer. Next, we consider their higher-level properties that follow from the observations in the previous sections:




\begin{enumerate}
	\item \textbf{Protocol Event Loop}\\
	Protocols are fundamentally \textit{passive} in that they do not act until acted upon. Nevertheless, protocols each have their own dedicated thread that waits in a loop for a \textit{notification} from its monitor. Notifications originate from a component's own \code{Ports} in the event of a \code{put} or \code{get} invocation. For this reason, protocols and components are related in both directions, afforded by setting a port variable in one direction, and functions \code{setProducer} and \code{setConsumer} in the other.
	
	True to the intuition behind the RBA model, the protocol must \textit{check} which (if any) commands can be fired, and keep spinning, trying rules while \textit{any} guard is satisfied. This is unfortunate, as this approach requires guards to be evaluated repeatedly. As the protocol relies on the actions of other components to make progress, it is counter-productive for it to spend a lot of system resources evaluating guards to \textit{false}. In cases where threads must share processor time, the excessive work of the protocol component will begin to get in the way of other components making progress, in turn leading yet more guards to evaluate to \textit{false}.
	
	\item \textbf{Reference Passing}\\
	Java is a managed programming language whose garbage collector is central to how the language works. To support the transmission of arbitrary data types, \code{Port} is generic over a type. The language only supports this kind of polymorphism for objects. Unlike primitives (such as \code{int}), the data for objects is stored on the heap and is garbage collected by the Java Virtual Machine. Variables of such objects are therefore moved around the stack by \textit{reference}. Moving and replicating values is cheap and easy, as they always have a small (pointer-sized) representation on the stack.
	
	A minor drawback is the need for indirection when performing operations that need to \textit{follow} the reference. For example, comparing two \code{Integer} objects requires that the \code{int} primitives backing them on the heap be retrieved and compared. Equality is an example of an operation that the Reo protocol thread can be expected to perform frequently. The cost of this indirection depends on a myriad of factors, but is at its worst when it results in new, spread-out locations each time. This case might arise, for example, if the \code{Sender} continuously created new \code{Integer} objects and sent them through its port. Another drawback is the \textit{requirement} to allocate primitives on the heap before they can be sent through a port. This is not usually a problem in the case of Java, as in practice, almost everything is going to be stored on the heap with or without Reo.
	
	This aspect of the generated Java code will require the most change for the Rust version, as Rust has a very different model for memory management; it does not use a garbage collector by default, and structures are stored first and foremost on the \textit{stack} as in the C language.
	
	\item \textbf{Two Hops for Data}\\
	As protocols are components like any other, even the most trivial of data-movements require values to hop at least twice: into the protocol, and out of the protocol. Fortunately, as stated above, the cost of the `hop' itself is trivial, as it will always be a small reference. The problem is the time delay \textit{between} the hops, as it will often involve actions of three distinct threads in series (with the protocol in the middle). 
	
	\item \textbf{Vulnerable to User Error}\\
	The construction and linking of components with ports is not something the protocol itself is concerned with. Indeed, \textit{every} component assumes that their port-variables will be initialized by their environment. At the outermost level, this environment is in the application developer's hands. Components make no attempt to verify that they are correctly linked according to the specification; currently, there is not any infrastructure in place to support this checking if it were desired. As a result, it is possible make mistakes such as fusing two of a protocol's ports into one. Whether this is a problem worth solving depends on the burden of responsibility that Reo intends to place on the end user. These difficulties cannot be completely avoided, but approaches exist to minimize these opportunities for mistakes.
	
	While ports are clearly directional `from the inside out' (ports store distinct references to their producer and consumer components), the same is not so `from the outside in'. Neither of a port's components is prevented from indiscriminately calling \code{put} or \code{get}. The assignment of a port's values for `producer' and `consumer' component is in user-space also. As a consequence, these fields may not agree with the components that interact with the ports at all. In fact, any number of components may store a reference to a port, each arbitrarily calling \code{put} and \code{get}. If done unintentionally, this would lead to \textit{lost wakeups}; the thread blocking for a notification after calling acting on the port is not the same as the thread receiving the notification. Solutions can be conceived to \textit{wrap} ports in objects that constrain the API of a port to one of the two `directions'. However, without affine types, there is no obvious way to ensure the \textit{number} of components accessing a port is correct. In Rust, limiting these accesses becomes feasible.
	
	\item \textbf{Port Data Aliasing}\\
	In Reo, it is common for connectors to replicate port data. Owing to the nature of Java, this is currently achieved by duplicating references, where replication is also known as \textit{aliasing}. For immutable objects, aliasing has no observable side effects, and thus does not threaten Reo's value-passing semantics. However, Reo ports permit instantiation with \textit{any} object-type. Even if the operations are thread-safe, this causes \textit{incorrect} behavior, as a component might observe their data changing seemingly under their feet. Worse still, objects which are not thread-safe can cause undefined behavior. This is a result of Java's view on memory safety having inverted priorities to Rust. In Java, operations are unsafe by default, and the programmer must go out of their way to protect themselves from data races, access of invalid memory and corruption. In Rust, the \textit{ownership system} is based on the prohibition of mutably-aliased variables. Achieving replication in Rust will require some effort to convince the compiler of safety before a program will compile.
	
	\item \textbf{Non-Terminating Protocols}\\
	Currently, Reo-generated protocol objects loop forever unless they raise an exception and crash. For protocols that can perform actions with observable side-effects in the absence of other components, this is perhaps a good idea. However, in the majority of realistic cases, protocols are indeed passive, and cannot do meaningful work as the only component. Reo semantics tend to reason about \textit{infinite} behaviors. However, real programs often do \textit{end}, and it is desirable that the program's exit is not held up by an endlessly-blocked protocol thread.
	
	\item \textbf{Protocol Components Cannot be Composed at Runtime}\\
	(TODO is this the place to explain this?)
	Ports allow data to move from the putter (or `producer') and getter (or `consumer') components as an \textit{atomic} operation by delaying \code{put} or \code{get} operations until their counterpart is called also. This causes problems for the implementation of RBAs with rules whose guards are predicated by the data they move. How can a protocol \textit{decide} if it should fire as a function of values it can only obtain \textit{by} firing? This ability to reason about the future is currently still a luxury limited to models such as TDS. The Java implementation gets around this problem by introducing \textit{asymmetry} between `compute' and `protocol' components. Protocols are allowed to \textit{cheat}. The \code{Port} object has additional operations to inspect a value without consuming it: \code{peek} and \code{hasGet}. However, this asymmetry means that composing two Java protocol components (by linking them with ports) does \textit{not} result in a component with their composed behavior. Solving this problem in earnest requires continuously-connected protocols to reason about their distributed state, which is a problem beyond the scope of this work. Reo's relationship with \textit{liveness properties} is explored in Section~\ref{sec:api}.
	
	\item \textbf{Sequential Coordination}\\
	The Java implementation is structured such with \textit{ports} being the critical region between components. As protocols have multiple ports, at first glance it may appear that coordination events could occur in parallel. However, no communication through protocol $P$ happens without the single thread in $P$'s \code{run} method. Indeed, \code{put} and \code{get} operations can be \textit{started} in parallel by the boundary components, but $P$ can only complete it's half of these operations sequentially.
	
\end{enumerate}

\section{Requirements}
The Reo compiler's Java code generator were examined in Section~\ref{sec:java_examined}, resulting in the extraction of some high-level observations, enumerated in Section~\ref{sec:java_observations}. In this section, we lay out the requirements for Reo-rs. These requirements serve a dual purpose; firstly, it serves to structure the argumentation in sections to follow, primarily linking design choices together by providing over-arching motivations. Secondly, it provides a lens through which to view the work to follow, particularly for helping future readers to identify differences in their requirements such that different decisions can be made.

\subsection{Requirements Defined}
First, we enumerate and name the most vital \textbf{functional requirements} for the Reo-rs library. These requirements determine \textit{what} functionality must be available to the end user of protocols and ports, and which safety properties must be preserved.

\begin{enumerate}
	\item[$\boldsymbol{R^F_{correct}}$] Preserve Reo's value passing semantics. No user interaction should contradict these semantics. This precludes data races as a result of \textit{mutably aliasing} resources which the user considers to be independent values.
	
	\item[$\boldsymbol{R^F_{init}}$] Prevent the protocol from being initialized in an inconsistent state. Prevent port objects from being unitialized, unsafely accessed in parallel, or incorrectly connected to the protocol.
	
	\item[$\boldsymbol{R^F_{ffi}}$] Facilitate a foreign function interface with other systems languages C and C++. Ports and protocol objects should be accessible from those languages as well as Rust, such that they can be constructed, used and destroyed.
\end{enumerate}

Next, we enumerate the requirements which are \textit{qualitative}. By their nature, they cannot be met absolutely. Rather, they serve to guide the design of the implementation to prioritize the design decisions they affect. For those associated with run time, Chapter~\ref{sec:benchmarking} will assess the extent to which these goals are met.

\begin{enumerate}
	\item[$\boldsymbol{R^N_{data}}$] Allow the transmission of large data types without requiring the user to move the from the stack to the heap. Minimize the number of times data must be \textit{moved} in memory such that data transmission remains performant for types with large representations.	
	
	\item[$\boldsymbol{R^N_{fast}}$] Minimize the overhead of \textit{control
	operations} for the protocol object to route payloads and perform bookkeeping. In particular, minimize the cost of \textit{evaluating} the rules before one is selected for firing.
	
	
	\item[$\boldsymbol{R^N_{end}}$] Facilitate the protocol object being destroyed and its resources freed. Minimize the hassle of detecting when a system has terminated.
\end{enumerate}

\subsection{Requirements Evaluated}
\hl{TODO}

\section{Protocol Runtime}
\label{sec:protocol_runtime}
Here we explore the Reo-rs implementation of Reo protocol objects. 

\subsection{User-Facing}
\label{sec:user_facing}
The Reo compiler generates protocol descriptions in imperative form, which then are transformed by Reo-rs into runnable objects. The user therefore interacts mostly with Reo-rs itself, and Reo provides only the entry point for building particularly instances of protocol object. In this section we explain which functionality of Reo-rs is user-facing, focusing primarily on which requirements are satisfied.


\subsubsection{Construction and Destruction}
\label{sec:construction_and_destruction}
Reo-rs is built to interface with the Reo compiler, but it is not dependent on it. The entry point for protocol objects is the \code{ProtoDef} type, which is a concrete realization of the (logical) imperative form. Instances of this type are visible in Listings~\ref{listing:reo_out} and~\ref{listing:reo_out2}, but its definition is omitted for brevity (available in the source code). Regardless of whether the constructed \code{ProtoDef} was Reo-generated, it is instantiated along with any initial memory cells (in the \code{MemInitial} structure) to produce a \code{ProtoHandle}. This type has a small, pointer-sized shallow representation (ie. 32 or 64 bits) to the \code{Proto} structure on the heap. The handle is opaque to the user, at first glance offering no functionality other than to replicate the handle (aliasing the \code{Proto}) or to destroy the handle (in Rust this is done implicitly by letting its binding go out of scope, or explicitly by invoking~\code{mem::drop}). Once the last handle to a \code{Proto} instance goes out of scope, its resources are freed. This is achieved by relying on the Rust-idiomatic \code{Arc} type, (`atomic reference-counted') for the definition of \code{ProtoHandle}.

The system cannot come to life until the user acquires some of the protocol's \textit{ports}. In Reo-rs, there is indeed a singular type for a port object (\code{PortCommon}), but the user does not acquire it directly; instead, users are able to create and destroy two distinct types that \textit{wrap} \code{PortCommon}: \code{Putter} and \code{Getter}. In this manner, the \textit{direction} of the logical type is enforced; only \code{Putter} can put, and only \code{Getter} can get. Both are created by the \code{claim} function, which is invoked parameterized with (1) a \code{Protohandle}, (2) the data type of the port as a \code{TypeInfo}, and the name of the port to identify it (`name' is a string, corresponding to the one used in the definition of the \code{ProtoDef}, exemplified in Listing~\ref{listing:reo_out}). In this manner, the \code{Proto} is involved in the creation of these port objects and is able to enforce that (1) ports have the correct \textit{direction}, (2) no logical port may have more than one putters or getters at a time, and (3) the port type is instantiated with the correct \textit{data type}. All of these types and operations are also perfectly thread-safe, relying on the proto-lock, to be discussed in Section~\ref{sec:protocol_object_architecture}. When used from Rust, \code{Getter} and \code{Putter} have generic type paramters that do not influence their memory representation, but rather enforce that the data-type with which they are claimed matches that used in puts and gets. These generic arguments are not available in C; instead, a variant of these port types are available that store the \code{TypeId} as data, and reflect on it whenever putting or getting to preserve safety.

Putters and getters store replicas of their proto-handles (by necessity), which can be examined for subsequent claims; this means that the original \code{ProtoHandle} can be safely discarded. The \code{Proto} is destroyed only when all proto-handles \textit{and} all of its ports are destroyed. \code{Proto} is also involved in the destruction of ports, which affords the user discarding and \textit{reclaiming} ports at will. These port objects can also be treated as data, sent across threads, stored in buffers or moved to the heap. However, there is no safe means of \textit{replicating} a port object, ensuring that no two threads can be putting or getting on the same logical port at once.


\subsubsection{Port Operations}
\label{sec:port_operations}
Putters and getters rely on Rust's \textit{mutability} rules for ensuring that at most one thread is accessing each of a protocol's logical ports at a time; concretely, \code{Get} has method \code{get} with signature \code{fn get(\&mut self) -> T}, and likewise for \code{put}. Otherwise, the operations of these two types are distinct.

Getters offer \code{get}, which blocks the calling thread, and returns an object of type \code{T}, where \code{T} is the data type with which the putter was claimed. Other variants of this method exist which may be more ergonomic for the user depending on the circumstance. \code{get\_timeout} takes an extra \code{Duration} parameter, and will attempt to return once the duration has elapsed without the port being involved in a rule firing. Rather than \code{T}, this method returns \code{Option<T>}, where the \code{Option::None} variant communicates that timeout was exceeded before a value was acquired. For cases where the getter wishes to participate in a rule firing, but for whatever reason does not actually want the data, \code{get\_signal} is available; this method behaves like \code{get}, but returns no value. Finally, \code{get\_signal\_timeout} behaves as expected, returning a boolean \code{true} to communicate whether the getter participated in a rule firing before timing out; in either case, no element of the port's data type is returned.

Putters also have variants of \code{code} available that mirror those of the getter; \code{put\_timeout} behaves as expected. However, putters do not have a parallel to the getters' \code{get\_signal}. At the moment the datum is offered, it is unknown whether any getters (directly involved in the firing, or indirectly acquiring it after it is stored in the protocol's memory) will want the data. As putters `go first', they are subservient to the choice of the getters, and must be ready to deal with the situation in which their put-datum was involved in a rule firing, but not consumed. Reo-rs attempts to avoid the costs of creating or destroying port-data values wherever possible, as these operations may be arbitrarily expensive. As such, rather than the expected signature of \code{fn(\&mut self, T)}, the \code{put} method returns a value of type \code{Option<T>}; if their value is not consumed, it is instead \textit{returned} to the putter. The expectation is that this option is beneficial to the user, they are able to re-send the same datum, or use it elsewhere; Here, a return value of \code{Option::None} communicates that the value was consumed. If the putter is not concerned with retaining an unconsumed value, the method variant \code{put\_drop} is available which returns the datum regardless of the actions of getters.


Both putters and getters transfer their data into and out of the stack frames of their port operations respectively \textit{by value}. Owing to its focus on resource affinity, Rust relies on its \textit{move semantics} for both (a) relocating bytes in memory, and (b) transferring a semantic resource binding. For cases where the relocation of bytes is not necessary, LLVM can often be relied upon to optimize the memory movements away, passing consumed resources by reference `under the hood'. However, these optimizations are not guaranteed. Users of the Rust language have grappled with this shortcoming for years, but the search for a satisfying solution remains an open problem~\cite{matsakis_2015}. For us, this problem it presents itself when defining our API. Neither of the available options satisfy all of our requirements; $\boldsymbol{R^F_{correct}}$ asserts that we cannot rely on reference passing from user-controlled code, as it becomes impossible to enforce Reo's value passing semantics. On the other hand, relying on Rust's move semantics has the potential to insert up to two copies of our values, working against our satisfaction of $\boldsymbol{R^N_{data}}$. Our choices are as follows:

\begin{enumerate}
	\item \textbf{Value passing.}\\
	We expose safe functions \code{put} and \code{get} to consume and return data \textit{by value}, guaranteeing correctness. Depending on the compilation environment, it may require up to two moves of the data.
	
	\item \textbf{Reference passing. User provides correctness.}\\
	We expose unsafe functions \code{put\_in\_place} and \code{get\_in\_place} to consume and return data \textit{by reference}, relying on the user's care to initialize or drop the corresponding value themselves. According to Rust's idiom, these functions are marked with the \textit{unsafe} keyword, moving the burden of preserving correctness to the user. Their use necessitates explicitly wrapping them in \code{unsafe} blocks, such that it is easy to identify weak spots in a program's correctness.
	
	These functions are ideal for a \textit{foreign function interface} (to C, for example), for which \textit{unsafe} is often necessary anyway.
	
	\item \textbf{Value pass a `referring' type.}\\
	The user passes type \code{Q} through ports by value, where \code{Q} \textit{represents} the real type, \code{T}, ie. the user re-interprets what Reo-rs will consider to be the port's data type. As far as the protocol is concerned, \code{put} and \code{get} is called as in case (1).
	The simplest approach is to mimic that of Java, passing type \code{Box<T>}, representing an owned heap-allocated resource as an \textit{owned pointer}. Other approaches may be simple (eg: transmitting an integer which keys into a shared map) or arbitrarily complicated (Several Rust libraries exist for decoupling an object's data from its \textit{ownership}, such as \code{rent\_to\_own}, \code{managed} and \code{swapper}\footnote{These libraries are publically available on \url{crates.io}.}). 
\end{enumerate}

Options (1) and (3) are already supported by the methods described thus-far. To cover the remaining case, we rely on Rust's \textit{unsafe} API idiom to expose this trade-off for users to make on a case-by-case basis. Additional `raw' method variants are available which mimic Rust's move semantic by consuming and producing port data at the source and destination of a provided \textit{pointer}. Users are responsible for safely initializing and uninitializing the datum appropriately to avoid leaking memory or encountering undefined behavior. As is the idiom, these functions are explicitly marked with \textit{unsafe}, communicating to users that their use requires additional care to use these functions in accordance with their documentation. This option is therefore well-suited to the foreign-function interface with C.

In sections to follow, we ignore this complication and presume the safer value-passing variants are used only.

\subsection{Internal}
\label{sec:internal}
\hl{here we discuss how the protocol object is internally represented at a more granular level, and how it is able to coordinate the events according to its}

\subsubsection{Protocol Object Architecture}
\label{sec:protocol_object_architecture}
\hl{here we give an illustration of how a protocol object is laid out. fundamentally, the protocol has a structure that corresponds to the imperative form. no symbolic names are found, instead indexes only. 
1. read-only section: rules, name mappings, port info
2. explicit CR: mem ref counts, ready and mem sets. allocator, unclaimed set
3. implicit CR: space vector. each associated with a location. each given what they need. putter-space with rendezvous OR messagebox
}


\subsubsection{Coordinator and Interpreter}
\label{sec:coordinator_and_interpreter}
\hl{
there is no protocol thread. instead, there is a coordinator ROLE, and putters and getters adopt the role every time they perform actions that may further the state of the protocol.
The coordinator traverses rules, \textit{interpreting} them. instructions are protected by ready sets, and mem flags. when these are in place, INSTRUCTIONS are performed in sequence. if one triggers rollback, the actions are undone in reverse order and the rule is skipped.
when all instructions are ready successfully, the rule COMMITS. this unsets readiness flags and updates state flags to indicate that memory cells are in a state of flux, and that ports are no longer waiting. it then sends out MESSAGES and returns. later, ports become ready again, and the memory cells have been reset. observe that imperative form manipulates memory cells. this is done by the coordinator during instructions. BUT the memory cannot be cleaned up can only happen later. this is explained in the section to follow.
}

\subsubsection{Data Exchange}
\label{sec:data_exchange}
\hl{
we illustrate from the point of view of a simple rule: a single data movement with 5 getters. later, we will explain how modifications of this setup affect the outcome.
putters and getters arrive, starting the PUT and GET operation. putters have a pointer to their datum, ready for it to be consumed. at this stage, the putter clearly has unique access to it. it uses an atomic operation to SWAP the pointer to its datum and sets itself as ready. this event represents te putter relinquishing access to the datum: it is given into the protocol now. getters have a pointer to their uninitialized datum to be initialized and returned. at this point in the process, the datum to be transmitted still belongs to 
first, they mark themselves as ready. they yield their threads to coordinate! then they wait for a message to arrive at their messagebox, potentially blocking.
when their message arrives, getters spring into action. They have been notified of a rule firing in which they are involved. getters receive (as their message) the identity of their putter. they look up this putter;s space and converge at its rendezvous. using the RENDESVOUS structure and procedure, each races to acquire a copy of the datum. using atomic operations to switch coounters and flags, eventually the dust settles. one has MOVED and N-1 have cloned. the mover knows they are last, and they send the message to the PUTTER, notifying them that the deed has been done and their datum has been consumed. all threads return and the data exchange is complete.
complications:
1. no getters
2. memcell putter
3. memcell getters
4. getting from aliased data
}

\subsubsection{Type Reflection}
\hl{a key observation for reo coordinators, is that they actually perform very few operations on the data that are particular to the type. for the most part, it doesnt matter what type the data is. for the purpose of instructions, it needs to only sometimes REPLCATE, create new ALLOCATIONS, DESTROY and check for EQUALITY. for this reason, it makes sense to treat all data the same, and instead REFLECT on its concrete type at runtime when necessary. this is achieved using DYNAMIC DISPATCH

Rust has two main mechanisms for polymorphism: static and dynamic.
blah blah.
dynamic dispatch is close to what we need, but comes with two major downsides: you cannot DOWNCAST (make concrete) and they are represented with FAT POINTERS. Instead we have a custom approach which decouples the behavior pointer and the data pointer. this is useful for re-using allocations, using the behavior pointer as a KEY, clustering slots by type. the type pointer is not needed, as Reo knows the type of data movements based on context: movements to getters are always of the same type as the putter.
}


\begin{listing}[ht]
	\centering
	\inputminted{rust}{reflection.rs}
	\caption[Tricking Rust into exposing a vtable.]{`Tricking' the Rust compiler into retrieving the vtable of a given type \code{T} for dynamic dispatch to virtual functions of trait \code{PortDatum}. The safe cast on line~7 inserts a pointer to a vtable which the compiler will ensure is present in the program text. \code{TypeInfo} structures can later be used for type reflection, by manually appending this pointer to reconstruct the \textit{fat pointers} that Rust natively uses for dynamic dispatch.}
	\label{listing:reflection}
\end{listing}

To illustrate how our dynamic dispatch system works, we see how the user is able to safely extract an object's vtable themselves. As an example, we see which assembly is generated for the \code{TypeInfo::of} function when the trait \code{PortDatum} consists of only one function, such that \code{u32} can implement the trait by specifyding only \code{fn something(\&self) -> usize { 45 }}. Listing~\ref{listing:reflection2} shows the result of compilation when exposing a simple public function which constructs and results the \code{TypeInfo} for~\code{u32} using the function from Listing~\ref{listing:reflection}. Here, \code{.L\_\_unnamed\_1} shows the text region of the compiled binary containing a 24-byte-long vtable for \code{u32} when dynamically dispatched as implementors of trait \code{PortDatum}. In Rust, all vtables carry information about the type's \textit{layout} (\code{u32} occupies 4 bytes, and must be 4-byte aligned in memory), as well as a pointer to its \code{drop} function for deallocation (which for \code{u32} is trivial, simply returning). The remaining field points to the single function pointer associated with the trait, returning 45 as expected.  

\begin{listing}[ht]
	\centering
	\inputminted{text}{reflection2.rs}
	\caption[Example of assembly generated for extracting a vtable.]{The resulting assembly showing the vtable of type~\code{u32} for dynamic dispatch of trait \code{PortDatum} (here simplified to only having a single function `\code{something}', returning an integer). Here, a function \code{foo} is exposed which creates and returns the \code{TypeInfo} of type~\code{u32} using the function shown in Listing~\ref{listing:reflection}. Observe how this function simply returns \code{.L\_\_unnamed\_1}, the vtable of \code{u32}.}
	\label{listing:reflection2}
\end{listing}


\subsubsection{Memory Cells}
\hl{
memory cells clearly outlive the stacks of any putters. therefore, the protocol has its own independent persistent memory on the heap. However, it does not use the system allocator directly; data moves through ports very quickly and the overhead of allocating new objects is exceptionally wasteful. instead, we leverage the information made available by the reo specification: we know ahead of time which memory allocations we will need, and we know precisely in which sizes and alignments they will be. we can allocate a fixed number of STORAGE SLOTS and then re=use them. A sensible implementation would simply assign such a slot to each MEMORY CELL SPACE and swap values in and out, initializing and uninitializing the same memory region repeatedly. Clearly, as these memory variables are of irregular sizes, this necessitates a level of indirection: spaces have POINTERS to an allocated heap space. while we are at it, a minor change provides a powerful optimization: we decouple storage slots and memory cells entirely with the addition of a custom ALLOCATOR with REFERENCE COUNTING. when a memory cell moves data to others, only the POINTER moves to its storage slot, and the refcount is updated accordingly. this makes movement and replication within the protocol trivially cheap. it also means that the cost of dropping values is postponed until the last possible moment: the `original' is destroyed only when the LAST memory cell removes its reference.
}

\subsubsection{Performance Characteristics}
\hl{
talk about the central lock. goal is to minimize the duration for which it is held. the only thing the coordinator does is traverse rules, trying to fire them. as such, we can understand how this time is minimized by decomposing the work of a single rule into its constituent steps:
1. evaluate the readiness and memory bits. also true for batch UN-assigning
BITVECS for BATCHING

2. instructions
assume they are rare

3. movements
the protocol object just initializes the rendesvoux and fires messages and drops the lock. the actual data-exchange happens concurrently with new rules being fired. in this way, many ports can exchange data in parallel, as their READINESS flags are protected by the CR and thus only rules for which all ports and memory cells are in stable state can be fired concurrently.

\textbf{}

}