\chapter{Protocol Runtime}
\label{sec:protocol_runtime}
Previously, Chapter~\ref{sec:imperative_form} described how a Reo protocol specification is translated by the Reo compiler into the Rust language as an executable protocol object. In this chapter we discuss how these objects are able to act as the \textit{communication medium} between a set of communicating omponents. This approach allows the user's component code to exchange data with its environment through the protocol object's exposed ports. Components make no assumptions about the world beyond their ports, and consequently, have no notion of the system in which they play a part. From a user's perspective, ports are entirely opaque, and their components may use them to exchange data with their environment without any concern for global coordination.

Internally, protocol objects orchestrate the actions on their boundary ports into interactions defined by its protocol specification. As much as possible, the protocol will work to facilitate data flow. However, whenever a boundary port initiates an action which does not yet fall into a suitable interaction, the protocol exercises its power to block its completion until the time is right. 

Section~\ref{sec:java_examined} begins by examining the Reo-generated protocol objects for the Java language, allowing us to use this previous work as a touchstone for our own. Within, Section~\ref{sec:java_observations} observes opportunities for our implementation to improve upon it by the addition of safety properties, and exploiting opportunities for optimization. Section~\ref{sec:requirements_defined} makes our goals explicit by defining the requirements and guidelines used to inform our design process and determine the assumptions used to facilitate out implemented optimizations.  Section~\ref{sec:protocol_objects} follows with the implementation of the \textbf{Reo-rs} library, which defines our protocol and port objects. Within, Section~\ref{sec:user_facing} explains how we leverage Rust's affine type system to expose a safe user-facing API. Sections~\ref{sec:chosen_design}--\ref{sec:behavior_implementation} explain how the protocol object behaves at runtime, detailing the implementation of optimizations which enable it to (1)~coordinate actions without needing a dedicated thread, (2)~increase parallelism by delegating data movement to component threads, and (3)~internally perform reference counting and reference passing while preserving Reo's semantics. Finally, Section~\ref{sec:requirements_evaluated} gives an overview of how our requirements and guidelines are satisfied, including references to the sections containing the relevant details.

\section{Examining the Java Implementation}
\label{sec:java_examined}
The Reo compiler has seen extensive development for its Java code generator in particular. In this section, we examine the properties of the source code it generates. Later, Section~\ref{sec:java_observations} makes particular note of opportunities for our own version to improve upon this design, or at least deviate to the end of specializing its implementation to better suit the Rust language.

\subsection{Architecture}
Fundamentally, the generated code adheres closely to Reo's literature, revolving around the interplay between \code{Port} and \code{Component} objects. From the perspective of a developer looking to integrate a generated Java protocol into their application, the entry point is the \code{Protocol} component (where `Protocol' is the name of the associated Reo connector).

Running a system requires an initialization procedure: (1) a \code{Port} is instantiated per logical port, (2) a \code{Component} is instantiated per logical component, and (3) pairs of components are linked by overwriting a port field for both objects with the same instance of \code{Port}. To get things going, each component must be provided a thread to enter it's main loop; in idiomatic Java, this manifests as calling \code{new Thread(C).start()} for each component \code{C}. A simplified example of the initialization procedure is shown in Listing~\ref{listing:java_gen_1} for the simple `sync' protocol which acts as a one-way channel. In this example, the ports are of type \code{String}.


\begin{listing}[ht]
	\centering
	\inputminted[]{java}{java_gen_1.java}
	\caption[Reo-generated Java protocol initialization.]{A simplified example of initialization for a system centered around a \code{Sync} protocol object, which acts as a channel for transmitting objects of type \code{String}. Both ports and components are constructed before they are `linked' in both directions: each port stores a reference to its components, and each component stores references to its ports. The system begins to run when each component is given a thread and started.}
	\label{listing:java_gen_1}
\end{listing}


In a sense, this implementation primarily hinges on \code{Port} as a communication primitive between threads, and equivalently, between components. For matters of concurrency, operations on port data involves entering a critical region. In contrast, \code{Components} are used only to store their ports and to be used as name spaces for their \code{run} function which implements their behavior (which corresponds to RBA rules in the case of the protocol component). Essentially, anything that interacts with \code{Port} objects can reify a logical component, whether or not this is done by an object implementing the \code{Component} interface.

\subsection{Behavior}
The representation of protocol rules is very intuitive; a rule is implemented as a block of code which operates on a component's ports. Once generated into Java, the only obvious sign that a component was generated from Reo is its linkage to multiple other components. The (simplified) generated \code{Component} code of the `sync' protocol from the previous section is shown in Listing~\ref{listing:java_gen_2}. This demonstrates that rules are indeed commandified, in that their behavior is encoded in discernible structures (appropriately called \code{Command}).

The behavior and structure of a component go together, and are generated by Reo at a relatively granular level. As such, the encoding of memory cells is natural also. Memory cells can be found next to ports in the fields of a \code{Component}.

\begin{listing}[h!]
	\centering
	\inputminted{java}{java_gen_2.java}
	\caption[Reo-generated Java protocol class of the sync connector.]{A simplified example of a Reo-generated Java protocol class for the $sync$ connector. By convention, it is started by invoking \code{start}, which is a method inherited from the \code{Runnable} interface which \code{Component} extends. This method assumes that all ports are correctly initialized and linked to another `compute' port. Its RBA-like behavior comes from an array of guards and commands which it iterates over in a loop, firing rules as possible forever.}
	\label{listing:java_gen_2}
\end{listing}

\subsection{Observations}
\label{sec:java_observations}
Reo-generated Java objects have a very clear correspondence to their declarative Reo specification. This carries over to how components and ports are used by an application developer. For example, Port objects act both as points of data exchange and as primitive concurrency mechanisms aligning \code{put} with \code{get}. From this design, we observe the following noteworthy properties:

\begin{enumerate}
	\item \textbf{Protocol Event Loop}\\
	Protocols are fundamentally passive in that they do not act until acted upon. Nevertheless, protocols each have their own dedicated thread that waits in a loop for a \textit{notification} from its monitor. Notifications originate from a component's own \code{Ports} in the event of a \code{put} or \code{get} invocation. For this reason, protocols and components are related in both directions, afforded by setting a port variable in one direction, and functions \code{setProducer} and \code{setConsumer} in the other.
	
	True to the intuition behind the RBA model, the protocol must check which (if any) commands can be fired, and keep spinning, trying rules while any guard is satisfied. This is unfortunate, as this approach requires guards to be evaluated repeatedly. As the protocol relies on the actions of other components to make progress, it is counterproductive for it to spend a lot of system resources evaluating guards to $false$. In cases where threads must share processor time, the excessive work of the protocol component will begin to get in the way of other components making progress, in turn leading yet more guards to evaluate to $false$.
	
	\item \textbf{Reference Passing}\\
	Java is a managed programming language whose garbage collector is central to how the language works. To support the transmission of arbitrary data types, \code{Port} is generic over a type. The language only supports this kind of polymorphism for objects. Unlike primitives (such as \code{int}), the data for objects is stored on the heap and is garbage collected by the Java Virtual Machine. Variables of such objects are therefore moved around the stack by reference. Moving and replicating values is cheap and easy, as they always have a small (pointer-sized) representation on the stack.
	
	A minor drawback is the need for indirection when performing operations that need to follow the reference. For example, comparing two \code{Integer} objects requires that the \code{int} primitives backing them on the heap be retrieved and compared. Equality is an example of an operation that the Reo protocol thread can be expected to perform frequently. The cost of this indirection depends on a myriad of factors, but is at its worst when it results in new, spread out locations each time. This case might arise, for example, if the \code{Sender} continuously created new \code{Integer} objects and sent them through its port. Another drawback is the requirement to allocate primitives on the heap before they can be sent through a port. This is not usually a problem in the case of Java, as in practice, almost everything is going to be stored on the heap with or without Reo.
	
	This aspect of the generated Java code will require the most change for the Rust version, as Rust has a very different model for memory management; it does not use a garbage collector by default, and structures are stored first and foremost on the stack as in the C~language.
	
	\item \textbf{Two Hops for Data}\\
	As protocols are components like any other, even the most trivial of data movements require values to hop at least twice: into the protocol, and out of the protocol. Fortunately, as stated above, the cost of the `hop' itself is trivial, as it will always be a small reference. The problem is the time delay between the hops, as it will often involve actions of three distinct threads in series (with the protocol in the middle). 
	
	\item \textbf{Vulnerable to User Error}\\
	The construction and linking of components with ports is not something the protocol itself is concerned with. Indeed, every component assumes that their port variables will be initialized by their environment. At the outermost level, this environment is in the application developer's hands. Components make no attempt to verify that they are correctly linked according to the specification; currently, there is not any infrastructure in place to support this checking if it were desired. As a result, it is possible make mistakes such as fusing two of a protocol's ports into one. Whether this is a problem worth solving depends on the burden of responsibility that Reo intends to place on the end user. These difficulties cannot be completely avoided, but approaches exist to minimize these opportunities for mistakes.
	
	While ports are clearly directional `from the inside out' (ports store distinct references to their producer and consumer components), the same is not so `from the outside in'. Neither of a port's components is prevented from indiscriminately calling \code{put} or \code{get}. The assignment of a port's values for `producer' and `consumer' component is in user space also. As a consequence, these fields may not agree with the components that interact with the ports at all. In fact, any number of components may store a reference to a port, each arbitrarily calling \code{put} and \code{get}. If done unintentionally, this would lead to lost wakeups; the thread blocking for a notification after calling acting on the port is not the same as the thread receiving the notification. Solutions can be conceived to wrap ports in objects that constrain the API of a port to one of the two `directions'. However, without affine types, there is no obvious way to ensure the number of components accessing a port is correct. In Rust, limiting these accesses becomes feasible.
	
	\item \textbf{Port Data Aliasing}\\
	In Reo, it is common for connectors to replicate port data. Owing to the nature of Java, this is currently achieved by duplicating references, where replication is also known as \textit{aliasing}. For immutable objects, aliasing has no observable side effects, and thus does not threaten Reo's value-passing semantics. However, Reo ports permit instantiation with any \code{Object}. Even if the operations are thread-safe, this causes incorrect behavior, as a component might observe their data changing seemingly under their feet. Worse still, objects which are not thread-safe can cause undefined behavior. This is a result of Java's view on memory safety having inverted priorities to Rust. In Java, operations are unsafe by default, and the programmer must go out of their way to protect themselves from data races, access of invalid memory and corruption. In Rust, the ownership system is based on the prohibition of mutably-aliased variables. Achieving replication in Rust will require some effort to convince the compiler of safety before a program will compile.
	
	\item \textbf{Non-Terminating Protocols}\\
	Currently, Reo-generated protocol objects loop forever unless they raise an exception and crash. For protocols that can perform actions with observable side effects in the absence of other components, this is perhaps a good idea. However, in the majority of realistic cases, protocols are indeed passive, and cannot do meaningful work as the only component. Reo semantics tend to reason about infinite behaviors. However, real programs often do end, and it is desirable that the program's exit is not held up by an endlessly-blocked protocol thread.
	
	\item \textbf{Protocol Components Cannot be Composed at Runtime}\\
	(TODO is this the place to explain this?)
	Ports allow data to move from the putter (or `producer') and getter (or `consumer') components as an atomic operation by delaying \code{put} or \code{get} operations until their counterpart is called also. This causes problems for the implementation of RBAs with rules whose guards are predicated by the data they move. How can a protocol decide if it should fire as a function of values it can only obtain \textit{by} firing? This ability to reason about the future is currently still a luxury limited to models such as TDS. The Java implementation gets around this problem by introducing asymmetry between `compute' and `protocol' components. Protocols are allowed to \textit{cheat}. The \code{Port} object has additional operations to inspect a value without consuming it: \code{peek} and \code{hasGet}. However, this asymmetry means that composing two Java protocol components (by linking them with ports) does not result in a component with their composed behavior. Solving this problem in earnest requires continuously-connected protocols to reason about their distributed state, which is a problem beyond the scope of this work. Reo's relationship with liveness properties is explored in Section~\ref{sec:api}.
	
	\item \textbf{Sequential Coordination}\\
	The Java implementation is structured such with ports being the critical region between components. As protocols have multiple ports, at first glance it may appear that coordination events could occur in parallel. However, no communication through protocol $P$ happens without the single thread in $P$'s \code{run} method. Indeed, \code{put} and \code{get} operations can be started in parallel by the boundary components, but $P$ can only complete it's half of these operations sequentially.
	
\end{enumerate}

\section{Requirements and Guidelines Defined}
\label{sec:requirements_defined}
Following the observations of Roe-generated Java objects in Section~\ref{sec:java_examined}, we identify and make explicit the design choices and goals that inform the design and implementation of our own protocol objects for the Rust language. 
First, we identify a number of functional requirements, representing the goals which can be assessed for satisfaction without ambiguity.


\begin{enumerate}
	\item[$\boldsymbol{R_{value}}$] Preserve Reo's value passing semantics. No user interaction should contradict these semantics. This precludes data races as a result of aliasing values which the user considers to be independent.
	
	\item[$\boldsymbol{R_{init}}$] Prevent the protocol from being initialized in an inconsistent state. Prevent port objects from being unitialized, unsafely accessed in parallel, or incorrectly connected to the protocol.
	
	\item[$\boldsymbol{R_{ffi}}$] Facilitate a foreign function interface with other systems languages C and C++. Ports and protocol objects should be accessible from those languages as well as Rust, such that they can be constructed, used and destroyed.
\end{enumerate}

Not all useful properties can be meaningfully quantified by strict requirements. We identify a set of guidelines intended to focus the design process, and to form a basis for the assumptions that make meaningful optimizations possible. By their nature, these guidelines cannot be clearly satisfied. Instead, the extent to which guidelines are satisfied is motivated by argumentation, and supported by experimental evaluation in Chapter~\ref{sec:benchmarking} where applicable.

\begin{enumerate}
	\item[$\boldsymbol{G_{data}}$] Allow the transmission of large data types without requiring the user to move them from the stack to the heap. Minimize the number of times data must be moved in memory such that data transmission remains performant for types with large representations.	
	
	\item[$\boldsymbol{G_{fast}}$] Minimize the overhead of control operations for the protocol object to route payloads and perform bookkeeping. In particular, minimize the cost of evaluating the rules before one is selected for firing.
	
	\item[$\boldsymbol{G_{end}}$] Facilitate the protocol object being destroyed and its resources freed. Facilitate a means of detecting termination which is correct and ergonomic.
\end{enumerate}


\section{Protocol Objects}
\label{sec:protocol_objects}
Here, we detail the structure and behavior that cause our Rust protocol object type, \code{Proto}, to coordinate the actions of boundary ports at runtime in accordance with its associated Reo specification. Section~\ref{sec:user_facing} details the user-facing API, and explaining how its helps to provide safety properties. Protocol objects offer an expansive design surface, and so Section~\ref{sec:chosen_design} relates our implementation at a conceptual level to that of the Java version that came before. Section~\ref{sec:protocol_object_architecture} lays out the structural definition of \code{Proto}, which is relevant for understanding its connection to the code generation process and imperative form explained in Chapter~\ref{sec:imperative_form}. Finally, Section~\ref{sec:behavior_implementation} details the implementation of \code{Proto}'s behavior at runtime, explaining the roles of the boundary components, how actions are arranged into interactions, and the effects of our implemented optimizations.

\subsection{Application User Interface}
\label{sec:user_facing}
The Reo compiler generates protocol descriptions in imperative form, which then are transformed by Reo-rs into runnable objects. The user therefore interacts mostly with Reo-rs itself, and Reo provides only the entry point for building particularly instances of protocol object. In this section we explain which functionality of Reo-rs is user-facing, focusing primarily on which requirements are satisfied.


\subsubsection{Construction and Destruction}
\label{sec:construction_and_destruction}
Reo-rs is built to interface with the Reo compiler, but it is not dependent on it. The entry point for protocol objects is the \code{ProtoDef} type, which is a concrete realization of the (logical) imperative form. For a concrete example, the previous chapter includes Listing~\ref{listing:generic_resolve}, exemplifying a \code{ProtoDef} representation of a simple imperative form. Regardless of whether the constructed \code{ProtoDef} was Reo-generated, it is instantiated along with any initial memory cells (in the \code{MemInitial} structure) to produce a \code{ProtoHandle}. This type has a small, pointer-sized shallow representation (i.e., 32 or 64 bits) to the \code{Proto} structure on the heap. The handle is opaque to the user, at first glance offering no functionality other than replication (safely aliasing the \code{Proto}) or destruction. If the the last handle to a \code{Proto} instance is destroyed, all of its resources are freed. This is achieved by relying on the canonical \code{Arc} type, (`atomic reference-counted') for the definition of \code{ProtoHandle}.

The protocol remains inert until the user acquires some of its ports. However, they cannot be constructed independently. Instead, the user must invoke \code{claim} on a \code{ProtoHandle}, which identifies the port through the inclusion of a parameter specifying the port's logical name; this corresponds with the symbolic name as it appears in the imperative form. By encoding both its orientation (i.e.,\ \code{Putter} or \code{Getter}) and its data type as type parameters for each port object, \code{claim} is able to reflect on these properties and return an error (Section~\ref{sec:rust_language} explains how Rust represents exceptions with enumeration types) if the port's properties are incongruous with the protocol's definition, or if the port of that name is currently claimed. Similarly, port objects notify their \code{ProtoHandle} that their name is again available to be claimed in the event of their destruction. All together, this API is able to guarantee that (1) every logical port has at most one port object at once, and that (2) the types of ports enforce that their orientation and data type align with their specification.

\code{Proto} objects are stored on the heap, but their ownership is shared between all of their existing \code{ProtoHandle}s. Internally, ports contain a \code{ProtoHandle} each also. These handles are thin wrappers around Rust's \code{Arc} (`atomic reference-counted') type, ensuring that the handles are moved, acted upon and destroyed in a thread-safe manner. Once the last handle is destroyed, the \code{Proto} is destroyed also, freeing all of its resources in the process without a trace. \code{Proto} objects do not rely on any static variables, allowing any number of them to be instantiated and used throughout a program without them interfering with one another's execution (except, of course, their sharing of the underlying hardware resources). 

\subsubsection{Port Operations and Variants}
\label{sec:port_operations}
The API that defines \code{put} and \code{get} operations for ports is partitioned over port types in the expected way. Concretely, ports are represented in Reo-rs by distinct types \code{Putter<T>} and \code{Getter<T>}, each generic over their data type, where \code{get} is only defined for getters, and \code{put} is only defined for putters. In both cases, the operations rely on Rust's borrowing rules to ensure that even if the port objects is shared within the user's program, it is impossible to act on a port from two threads concurrently (without circumventing the Rust compiler with \code{unsafe} operations. For example, the signature of \code{get} is specifies that the getter is accessed via a mutable reference\footnote{This terminology is often confusing; despite the name, `mutability' is more often used to mean `mutually exclusive', as is the case here. The Rust compiler will only permit this operation in a context where it is certain that the port is not concurrently being used elsewhere.} (written~\code{\&mut}).

The \code{get} operation blocks the calling thread until an element of type \code{T} is returned. Users are able to customize their involvement in the interaction by invoking one of \code{get}'s variants. For example, \code{get\_timeout} blocks the thread up to a specified timeout, and returns an \code{Option<T>} to distinguish success from failure. The latter case represents the failure to participate in an interaction, allowing the caller to reclaim the control flow and continue working. Getters also have the option of calling \code{get\_signal}, which expresses a wish to participate in an interaction, but no desire to acquire the datum. The utility of this option is that Reo-rs will attempt to avoid the work of acquiring the value at all, potentially avoiding a \code{clone} operation and other associated overhead (explained in Section~\ref{sec:data_exchange}). The effects of this variant on performance are shown in Section~\ref{sec:benchmarking}. \code{get\_signal\_timeout} is also available, and behaves as expected.

Similarly, putters have access to \code{put\_timeout}, which varies from~\code{put} in the expected way. Both operations have the potential to return the putter's value. This may occur even if the value was involved in an interaction, but was not acquired by any getters. Returning the value allows the user's program to decide what to do with the value. For example, a user may decide to put the value again until it is read. If this behavior is undesired, putters offer the \code{put\_lossy} and \code{put\_timeout\_lossy} variants which will not return the value regardless of the actions of getters, dropping it if needs be.

\subsubsection{Value-Passing API Semantics}



The Rust language conflates the movement of values to new variable bindings with two meanings: (1) the value's ownership is transferred to the new binding and scope, and (2) the value's shallowest representation is moved in memory. Reo's semantics require that the data transmitted through ports is truly \textit{moved}, transferring ownership. Clearly, not doing so would violate Reo's semantics; values acquired through ports might be dropped or acted upon at the whims of their original putter, of which the getter would have no knowledge. As is idiomatic for the Rust language, our API transfers ownership into the scope of \code{put} and out of the scope of \code{get} by moving the value itself. Na\"ively, this has significant performance implications, as the cost to move a value is dependent on the size of its representation. For example, a 10MB array is significantly more costly to move than a byte. For cases where the relocation of bytes is not necessary, Rust programmers can often rely on LLVM to optimize the memory movements away, passing consumed resources by reference `under the hood' (but retaining the semantic movement of ownership). However, these optimizations are not guaranteed. Users of the Rust language have grappled with this shortcoming for years, but the search for a satisfying solution remains an open problem~\cite{matsakis_2015}. The only way to guarantee that the data is passed by reference at runtime is to expose an \code{unsafe} API, which relies on the user to pass references and manage the associated ownership manually. Our requirements prioritizing safety ($\boldsymbol{R_{value}}$) and performance ($\boldsymbol{G_{data}}$) are in conflict. Our solution is to compromise by exposing these options to the user as variants for \code{put} and \code{get}, and allow them to decide on a case-by-case basis: 

\begin{enumerate}
	\item \textbf{Value passing.}\\
	We expose safe functions \code{put} and \code{get} to consume and return data by value, guaranteeing correctness. Depending on the compilation environment, it may require up to two moves of the data.
	
	\item \textbf{Reference passing. User provides correctness.}\\
	Operations are parameterized by references (or raw C-like pointer types) which Reo-rs writes to and reads from directly. The caller takes responsibility for ensuring that the value at the pointer's destination is initialized or dropped as necessary to correspond with Rust's usual ownership system. For example, this version of \code{put} is given a pointer to initialize memory, which the operation will initialize.
	
	\item \textbf{Value pass a `referring' type.}\\
	As far as Reo-rs is concerned, this is indistinguishable from case~(1). However, the user intentionally reinterprets the data types of their ports such that they represent indirections. For example, \code{Box<T>} is a pointer-sized owned type which will be transmitted by Reo-rs much like any other pointer-sized integer, oblivious to the fact that it indirectly represents another type \code{Q}. Taken to the extreme, a na\"ive solution replaces all data types with heap-allocated indirections, inheriting the associated downsides shared with the Java implementation. Other approaches may be simple (eg: transmitting an index to a shared vector) or arbitrarily complicated (Several Rust libraries exist for decoupling an object's data from its ownership, such as \code{rent\_to\_own}, \code{managed} and \code{swapper})\footnote{These libraries are publicly available on \url{crates.io}.}. 
\end{enumerate}

To reflect our priority of safely, the `default' port operations use value passing, corresponding to options (1) and (3). Users are able to take safety into their own hands by opting into \texttt{*}\code{\_raw} port operation variants. We rely on Rust's idiom of marking such operations as \code{unsafe}, communicating to the user that they are adopting the responsibility of reading the API documentation to determine and provide the necessary guarantees, as is usual in languages such as~C; this keyword requires the user's code to be explicitly qualified as an \code{unsafe} block, making it impossible for them to easily overlook this requirement. 

\subsubsection{Interface with C and C++}
Programming languages rely on an \textit{ABI} (application binary interface) for translating functions and types into binary according to a dependable convention. When languages agree on this interface, it ensures that both caller and callee with agree on the minutia of the calling convention, and how structures are laid out in memory. It is common for Rust, C and C++ to interface using the C ABI, and as such, there is syntactic support for selecting the ABI to be used per function and per structure. Reo-rs makes use of this feature to expose C-friendly types and functionality as part of its foreign function interface. In most cases, this requires nothing more than the addition of preprocessor annotations, i.e.,\ \code{\#[repr(C)]} and~\code{\#[no\_mangle]}, and visibility keywords, i.e.,~\code{extern}.

Rust makes frequent use of generic type parameters, which rely on the Rust compiler for dispatch at the call site (see Section~\ref{sec:rust_language}). C has no analog for this feature, and thus, some structures and functions are be provided secondary concrete representations. As an example, Rust represents the \code{Putter} and \code{Getter} types with a generic argument, affixing its data-type at compile-time. Reo-rs preserves safety guarantees by relying more extensively on reflection at runtime for these cases.

Rust has no analog to C's header files; it does have trait-associated functions, which can declare functions without defining them. However, they are of no use here, as they are not usable from C, as they are inherently coupled with Rust's generic system. To facilitate the sort of workflow that is idiomatic to C, whereby definitions and declarations can be distinguished such that \textit{compilation} can be distinguished from \textit{linkage}, the Rust ecosystem offers an addon for generating C header files from Rust source. This module can be loaded as the \texttt{bindgen}\footnote{url: \url{https://crates.io/crates/bindgen}.} addon to Cargo, Rust's package manager (comparable to Pip for Python, NPM for Node-js, and perhaps Maven for Java). With this tool, we are able to generate C~header files without much friction, and include them in any distributions such that downstream dependents on Reo-rs can incorporate them into their applications as they would do for any other C library. Once compiled and linked, their~C or~C++ applications would execute as would any other binary, and the use of Rust for compiling Reo-rs is no longer visible. Owing to its nature, calls that cross the Rust-C boundary do not induce any significant overhead~\cite{klabnik2018rust}.

\subsection{Design Process}
\label{sec:chosen_design}
Many designs for the implementation of Reo-like coordinators are possible. Their structure and workings all depend on how information is arranged, and how multiple threads come together to coordinate on an a priori unknown task without stepping on one another's toes. In our case, we concentrate on the case where all participants in the system share a memory address space, which opens up many means of exchanging data between threads.\footnote{This assumption provides context for our work, but is not an inherent assumption of all of our design choices. Wherever possible, we make this distinction in the text.} As is typical in multithreading, the problem is not accessing the data, but rather restraining oneself from accessing the data at the wrong time. Before we can approach any design decisions, we examine what we know for certain: ports invoke \code{put} or \code{get}, each from their own thread. They cannot return immediately, as this would not result in the correct system behavior; when not aligned in time, getters will often (unknowingly) read uninitialized data, and putters will write their data, never to be read. They wish to exchange data in accordance with some defined protocol, but a priori have no knowledge of the protocol, nor their role in it. The aim is to facilitate rule firing `greedily' as opportunity allows: i.e.,\ protocol objects should fire rules as frequently as possible such that the behavior of the system is not constrained \textit{beyond} the constraints of the protocol itself.

\subsubsection{The Coordinator}
The most obvious starting point is asking `who decides which rule to fire?' Reaching consensus prevents the system from reaching some malformed state where two rules are being committed to in tandem, violating the protocol or deadlocking on some resource they have in common. It is easy to contrive of such examples where numerous ports are involved. For example, consider a case where two rules disagree on which of two putter ports distribute their datum to a set of getters. If not done carefully, some getters may receive one value, and the rest another. The most approachable solution is to stick more closely to the Reo model by introducing a specialized \textit{coordinator} for each protocol. Consensus is trivial when one participant is elected the leader for every circumstance. Unfortunately, we cannot rely on some port $x$ being involved in every rule firing such that they are the coordinator. Many protocols do not have such an $x$ that can be relied upon to be present. The Java back-end solves this problem by adding a fresh `protocol' thread whose task is to only coordinate the others. This approach is easy to think about, as there is a clear mapping from threads to roles. However, the protocol thread is not inherently coupled to the actions of ports. It has to wait for opportunities to coordinate, necessitating the transmission of explicit events from compute threads to the coordinator. These messages can use a channel, or use something like semaphores or monitors to send signals instead, and then relying on the coordinator to rediscover which ports are ready by reading the state of shared memory. Next, one must decide who organizes the actions into an interaction. The Java backend's approach is to spread ports out over space such that they can become ready concurrently.\footnote{Conceptually this could be in parallel, but the actual implementation the exchange necessitates the use of a \textit{class monitor lock} (a structure for coordinating actions for all instances of a class) to prevent interfering with the protocol thread itself.} The coordinator then treats the port structures like messaging pigeonholes, and performs the task of moving data around itself. The coordinator's notification to the ports is subtle; taking the form of \code{put} and \code{get} calls which release port-local locks, unblocking the compute threads, completing the interaction. This solution is effective, but has some downsides, as discussed in Section~\ref{sec:java_observations}. 

\subsubsection{Event Handling}
A minor change with the potential for improvement is to remove the necessity of the protocol thread to rediscover the nature of the event which generated a wakeup signal. Rather than signals with no payload, we can use events which carry explicit information, eg: `Port $x$ is ready to get!'. With this approach, the coordinator waits in an event loop, handling incoming events. The Rust ecosystem has a number of libraries for defining event loops built atop system signal handles. An early implementation made use of the \code{mio} crate for sending events which communicated \textit{which} port has become ready. With this minor change, the coordinator does not need to inspect the contents of ports directly, which, owing to their modification by multiple threads, inherently cause several cache misses for the coordinator. Rather, the coordinator is able to manage a private, dense, redundant record of which ports are ready. Aside from the unfortunate data duplication, this optimization contributes greatly to the satisfaction of $\boldsymbol{G_{fast}}$. Unfortunately, regardless of how fast \code{mio} may be, the event must still cross the boundary between threads. In overburdened systems, this has the consequence of causing context switches.

\subsubsection{Threadless Protocol}
If the coordinator has its own `protocol thread', threads focus on their own work; the coordinator coordinates, and port threads interact with their ports. However, for all interactions that involve one or more ports (which are frequent in practice) we observe that despite the presence of multiple specialized threads, their tasks are not concurrent. Port threads perform external work until they instigate a port operation, until the coordinator is woken up to complete the interaction by firing the rule. Port threads and coordinator cannot know when to act, and must rely on notifications from one another. Threads must wake up and go to sleep frequently. 

One pivotal decision of our final design is to attempt to alleviate this problem. If compute threads are going to block, waiting for progress anyway, why not have them do the coordination themselves? In our approach, we discard the dedicated protocol thread and reinterpret the coordinator as a \textit{role} which the other threads take turns adopting. Conceptually, this change is a minor one; there is ultimately still at most one thread acting as coordinator. Until now, we have taken for granted that the coordinator can complete interactions with impunity; as they are the only elected leader of their kind, there is no concern for data races. In our new model, if anyone can be a coordinator, we must go our of our way to prevent two threads from adopting the role at once. Where before the bottleneck existed (implicitly) as a single coordinator thread processing a sequence of events one at a time, we now make the lock explicit: upon becoming ready, every thread attempts to acquire the \textit{protocol lock}, the holder of which acts is the only coordinator for the duration.

\subsubsection{Delegating the Task of Data Exchange}
Owing to our focus on values at the systems level, we do not have the simplifying luxury of the Java backend to presume that moving data is cheap. In Rust, as in C and C++, values are not represented by indirect references by default; often, their shallowest representations are all there is to them. To satisfy $\boldsymbol{G_{data}}$, the Java backend's (admittedly intuitive) representation of ports as data pigeonholes is wasteful. For many realistic Reo protocols, data often moves through protocols synchronously, moving from \code{Putter} to \code{Getter} without any storage in memory cells in between. 

Our implementation introduces a new idea in an attempt to capitalize on this observation: getters fetch their data directly from the source. In this approach, the coordinator does not necessarily handle data itself. Rather, it decides which rule to fire and delegates the task of moving the data to the getters themselves. In addition to skipping a redundant `data hop' from putter to coordinator, this also facilitates the dissemination of a putter's datum to all its getters in parallel. This change requires extra messaging form the coordinator, as getters are given more responsibility. Where before a signal from coordinator to getter sufficed (`Your datum is ready!'), coordinators must now communicate the location of the getters' source (`Your datum can be found at~$P$!'). Note that this idea is applicable in a context where components are distributed, i.e.,\ they do not all share an address space. In such cases, it becomes vitally important to manage the task of data movement for the sake of performance, which is likely to complicate this optimization further. 


\subsection{Architecture}
\label{sec:protocol_object_architecture}
\code{Proto} is a type corresponding closely to its imperative form specification type, \code{ProtoDef}. While they represent the same thing, their differences in structure and contents are a result of them being used for different purposes. Despite the increase in granularity from Reo's RBA-like form, \code{ProtoDef} still represents a specification of the protocol; as such, it strives to minimize redundancy to simplify parsing and minimize the surface for internal inconsistency. On the other hand, \code{Proto} is structured to facilitate execution at runtime.

\begin{enumerate}
	\item \textbf{Layout optimized for speed.}\\
	As discussed in Section~\ref{sec:translation_phase_2}, the \code{build} method is the only user-accessible means of constructing \code{Proto} instances. The methods of this type can rely on this to assume that their contents are internally consistent, thereby avoiding the cost of performing many checks at runtime. For example, if a rule's guard includes an equality check between the values in memory cells $m_0$ and $m_1$, \code{Proto} is able to assume that these cells have the same type; it is safe to use the result of $m_0$'s definition of type-equality.
	
	Additionally, concise structures can be rearranged such that their layout facilitates less computation time. A general example of this paradigm is caching. Here, a clear example is the replacement with symbolic names for ports, functions and memory cells (represented by strings in the \code{ProtoDef} type), using integers for keying into vectors, maps and other such structures directly.
	
	\item \textbf{Additional data for primitive concurrency.}\\
	Where \code{ProtoDef} can leave information implicit, \code{Proto} must be explicit. Interface ports require some data structures for storing concurrency primitives. For example, coordinators must send control messages to getters, as explained in Section~\ref{sec:chosen_design} above. 
\end{enumerate}

\subsubsection{Critical Region}
Section~\ref{sec:chosen_design} explains how threads initiating actions at boundary ports of a protocol assume the role of coordinator. It is fruitful to examine the fields of \code{Proto} in accordance to which roles access them, and how their access is safely controlled. The most coarse-grained distinction is that between fields inside and outside the protocol's lock-protected critical region. This divide is so fundamental, that is is immediately apparent by looking at the definition of \code{Proto} itself, seen in Listing~\ref{listing:proto}. \code{ProtoCr} stores all of the fields manipulated only by the coordinator, such as the \textit{allocator}, to which the coordinator delegates the task of storing persistent values. This is explained further in Section~\ref{sec:memory_cells} to follow. Also observe the field responsible for managing which ports are \textit{claimed} (See Section~\ref{sec:port_operations}). While this is not a task traditionally associated with the coordinator, it's mutually exclusive access between threads necessitates that this structure is protected by the lock.

\subsubsection{Spaces}
Clearly, \code{ProtoCr} can contain only the data that is not contended by multiple threads. Some structure is still needed for threads to rendezvous such that information can be exchanged and actions can be aligned in time. In the Java implementation, the class \code{Port} served two distinct purposes: (1) stored the value being exchanged by two threads, and (2) acted as the rendezvous for putter and getter. As explained in Section~\ref{sec:chosen_design} above, the former of these tasks does not involve the coordinator in Reo-rs. However, the latter is still relevant. To meet this need, \code{ProtoR} associates a \code{Space} for every identifier (for ports and memory cells alike). The difference is name exists to distinguish them from ports, to which they are certainly related, but not identical. For every identifier, its \code{Space} contains precisely the data needed for it to communicate with its peers. For ports, this includes a \code{MsgBox}, which serves as a control-message channel from coordinator to compute-thread. Spaces are discussed further in Section~\ref{sec:data_exchange} to follow. 

\begin{listing}[ht]
	\centering
	\inputminted{rust}{proto.rs}
	\caption[Proto type with parts inside and outside the lock.]{Definitions of the most coarse-grained structures of a protocol instance. \code{Proto} is the entrypoint, composed of \code{ProtoCr} in the critical section, accessed by only the coordinator, and \code{ProtoR} outside it, accessed by all.}
	\label{listing:proto}
\end{listing}


\subsection{Behavior}
\label{sec:behavior_implementation}
This section explains how the data structures of the \code{Proto} type comes to life at runtime to emerge as coordination according to the protocol with which it was configured. 

\subsubsection{Rule Interpreter}
Unlike the Java implementation, Reo-rs moves the specification of the protocol type very late into the pipeline from Reo to the final application. Rather than relying on Reo to generate native application code, in this work we make more extensive use of the virtualization pattern. At runtime, the coordinator traverses rules in data form, performing tasks as a rudimentary \textit{interpreter}. The tasks associated with such a \code{Rule} correspond closely to the conceptual interpretation of the imperative form. At this granulairty, interactions do not exist explicitly. Rather, the interpreter must perform the work associated with each rule interaction as a sequence of actions which, all together, appear to the observer as an interaction. For simple rules, it is clear to see how such interactions can be created. For example, consider a simple rule with constraint $P=C$ where $P$ and $C$ are putter and getter ports respectively. Here, $P$'s value is simply moved to $C$ if both ports are ready. As RBF rules become more complex, more actions become necessary to achieve the results of the interaction. Section~\ref{sec:imperative_form_sec} explains how by imperative form's restrictive representation already captures the result of this action-centric breakdown such that the interpreter does not need to compute it at runtime. These actions preserve their interaction-based semantics by behaving as \textit{transactions}, with actions clearly divided into two sequences around an instant where the rule can be thought to \textit{commit}. As long as their effects can be reversed, action prior to the commit can create temporary variables and trigger commit as they please. This approach is flexible enough to represent Reo's \textit{transform} channels, allowing values to be created and destroyed synchronously by being represented inside the transaction itself. 


\subsubsection{Minimizing the Bottleneck}
\label{sec:minimizing_the_bottleneck}
Reo-rs shares its centralized locking architecture with the Java backend. Regardless of whether the coordinator and the thread that performs the role are decoupled, the importance of providing it mutual exclusion is clear; two coordinators in tandem would not be safe in the knowledge that the state does not change between evaluating the guards and changing the state. Methods exist for fragmenting protocols such that the locking becomes finer grained as protocols are into sets of smaller ones. As such, the Reo compiler internally produces a set of protocols as its output, though the work on this feature is ongoing. Nevertheless, we consider this decomposition an orthogonal concern and consider it no farther. Reo-rs embraces this central lock, but takes measures to minimize the duration for which it is held. In this section we discuss these measures and how they work together to help satisfy $\boldsymbol{G_{fast}}$. To structure our reasoning, we identify the tasks a coordinator performs from the moment to acquires the lock (accepting its role), to the moment it releases it (relinquishing the role). 

\begin{enumerate}
	\item \textbf{Initialization}\\
	Section~\ref{sec:port_operations} explains how the time spent purely on overhead is diminished by avoiding the event-signal interaction used by the Java implementation, necessary to wake a sleeping protocol thread. Once the coordinator has acquired its lock (a task needed in both versions), transitioning into the work of the coordinator is nothing more than the time taken to invoke the \code{coordinate} function call.
	
	\item \textbf{Checking Readiness and Memory State}\\
	Imperative form shares the explicit representation of the synchronization constraint with RBAs, encoding precisely which ports are involved with the firing. Clearly, a rule cannot fire until all ports involved are \textit{ready}. Per port, this is a boolean property which can be represented by a single bit flag. Owing to the simplicity of this data, each of these sets can be represented as a single \textit{bit-vector}, a data structure for which set operations are exceptionally fast. Reo-rs takes this optimization a step further by extracting another boolean property per memory cell: fullness. The idiomatic encoding for memory cells storing data of type \code{T} in Rust would be the \code{Option<T>} type, such that \code{Option::None} represents emptiness. Instead, the relevant flags for fullness are extracted, separated from their data and instead coalesced into another bit-vector. With just a handful of fast bit-wise operations, the coordinator is able to quickly detect whether a rule cannot fire, as a result of a port not being ready, or a memory cell being full when it should be empty, or empty when it should be full. In practice, the vast majority of cases where a rule's guard is unsatisfied are detected in this step.
	
	
	\item \textbf{Instructions}\\
	Instructions are relatively expensive compared to the other steps in a rule's interpretation. Their cost scales with their complexity, as they can be defined as arbitrarily large and deep formula terms. Even individually, the cost of each operation can be high, as they include arbitrary user-defined function invocations, arbitrary user-defined equality checks, and allocation space for newly-created data objects. Section~\ref{sec:memory_cells} explains how the cost of memory allocation is mitigated such that the allocation itself is amortized to constant time. For the rest of these operations, there is not much that can be done to avoid the cost; for the most part, they would be expensive even if each rule were performed by a native Rust function. Fortunately, the vast majority of rules for Reo connectors require no instructions at all. In practice, Reo connectors tend not to inspect the data whose flow they coordinate. The more intrusive the protocol's routing logic becomes, the more it begins to resemble computation (i.e.,\ not coordination), a task for which Reo should probably not be optimized. For the protocols without instructions (including $fifo1$, $alternator$, $sequencer$, $sync$, and more), the support for instruction parsing costs no more than the time to determine that there are zero instructions to execute.
	
	\item \textbf{Movements}\\
	Once a rule is committed, the role of the coordinator is to kick any getters into action, delegating the data exchange to them. Each movement encodes one resource (\code{Putter} or memory cell) being distributed amongst a set of \textit{recipients} (each a \code{Getter} or memory cell). This meta interaction is not synchronous; getters may take arbitrary time before waking up and actually participating in the data exchange. This is not the case for memory cells; as part of the configuration of the protocol, this is manipulated by the coordinator only. As such, operations which move values \textit{into} memory (where memory cells act as getters) are performed first. Section~\ref{sec:memory_cells} explains this procedure in more detail. Here, it suffices to say that the movement of memory between memory cells is fast.
	
	For port-getters, the coordinator does not move the value itself. Rather, the work is delegated to the compute-thread by sending a control message to the getter's \code{MsgBox}. 
	
	Usually, the coordinator does not have to interact with the resource (acting as putter) at all. It can rely on getters to `clean up'. The coordinator returns, releasing the protocol lock. The only exception is for movements with zero getters. Such cases can represent a resource being destroyed. In these cases, there is no getter to perform the cleanup, and so, the coordinator does it itself. For a \code{Putter}, this is no more than sending a control message, releasing it. For memory cells, this may require running the \code{drop} function associated with the memory cell's data type.  Section~\ref{sec:memory_cells} provides more detail on how these are managed.
	
\end{enumerate}

\subsubsection{Data Exchange}
\label{sec:data_exchange}

Eventually, each \code{Getter} waiting at their \code{MsgBox} receives a control message from the coordinator, revealing to them the identifier from which they must fetch their value. Their task is to locate the corresponding \code{Space} and contend with an unknown number of fellow getters to complete the movement. The correctness of this exchange relies on the satisfaction of a number of properties:
\begin{enumerate}
	\item \textbf{One getter cleans up the resource}\\
	Regardless of whether the resource is a \code{Putter} or a memory cell, the set of getters are responsible for cleaning up the resource to finish the interaction. In the case of a putter, this takes the form of sending them a control message, notifying them that everyone has finished inspecting their datum and they may return to the caller. Clearly it is unsafe for anyone to release the putter before some getter has finished reading the datum; by returning, the putter may invalidate the memory region storing the datum.
	
	In the case of a memory cell resource, cleanup takes the form of resetting its ready-flag inside \code{ProtoCr}, signifying that the memory cell is in a stable state can again be involved in rule firings. This is necessary as there is no dedicated thread guaranteed to set this flag in future, as is the case for getters and putters. Section~\ref{sec:memory_cells} to follow also explains how these memory cells are emptied in these events such that they can again store new values. This manipulates the protocol's state, potentially making new rules' guards satisfiable. As such, this last getter must once again acquire the protocol lock and attempt to \code{coordinate}.
	
	\item \textbf{At least $N-1$ getters \code{clone}}\\
	Rust generalizes the operation for replicating a datum to produce another instance from it. It is idiomatic to rely on the standard trait \code{Clone} with single operation \code{clone} to implement this behavior. This approach covers cases for which there is a non-trivial means of replicating objects; sometimes, performing a bit-wise copy of the structure's shallowest representation is not enough. Consider the example of \code{Arc} (`atomic reference-counted') in Rust's standard library. This type consists of just a pointer to some heap-allocated tuple \code{(refcount, data)}, and is used for shared, reference-counted ownership of \code{data}. For this type, coping the pointer to the tuple is not sufficient. Cloning must follow the pointer and increment \code{refcount}.
	
	\item \textbf{One getter moves instead of cloning}\\
	Data movements represent the transmission of data from source to a set of destinations. Generally, the value is no longer present at the source afterwards. Na\"ively, the original must be dropped to complete the interaction. However, it is wasteful and illogical to replicate an object only to destroy the original. Instead, we wish to move a value between threads, much as Rust's move semantics allow the movement of affine types between bindings. This cannot be done in the conventional way, as movement is defined is generally within the context of a single thread and scope. Regardless of Rust's expressiveness, it is nonetheless an action-centric language, and does not offer the interaction we need.\footnote{Rust is able to understand uni-directional movement of values into new threads using the same mechanism by which closures can enclose variables in their parent scope. More complex types are able to also create their own notions of safe `movement' by composing actions as we suggest in this section. As in our case, they require the use of \code{unsafe}, as by definition the Rust compiler cannot reason about their correctness in the usual way.} 
	
	When orchestrated correctly, we are able to implement a safe move operation between threads by invoking a pair of \code{unsafe} operations, one on either end. In unsafe Rust it is possible to copy a value without influencing the original. If not done correctly, this can easily lead to double frees. On the other hand, it is possible to leak resource memory with \code{forget}, an operation of Rust's standard library which causes the compiler to consider the value moved without invoking \code{drop}. These pitfalls should be familiar to C programmers, as unsafe Rust gives one the capability to interact with `raw' pointers in a fashion similar to that of~C. Together, these actions constitute the inter-thread move primitive we need.
	
	We elaborate our task by requiring an election between getters, such that one is designated the \textit{mover}, and the rest are \textit{cloners}. 
	
	\item \textbf{All clones must be complete before the move}\\
	It is unsafe to move a value before or while performing \code{clone} on the original. Essentially, every data exchange must proceed in two strict phases such that all clones occur in the first, and the move in the second.
	Consider again the example of type \code{Arc} by examining this sequence of events that results in undefined behavior: (1) \code{Arc} $x$ represented by a pointer to heap region at $p$ is moved to binding $y$. (2) $y$ goes out of scope, it's \code{refcount} is reduced to zero, and so its heap allocation is freed. (3) \code{Arc::clone} is invoked with $x$, which traverses its pointer to memory position $p$, and attempts to increment \code{refcount}. $p$ is no longer allocated, and arbitrary memory corruption ensues. To prevent such cases, Reo-rs must take care to order all clones of some value before it can be moved, as the Rust compiler would do.
\end{enumerate}

Many solutions are possible, but have in common that these getters must exchange some meta-information safely across thread boundaries. Our solution uses a pair of atomic variables for this purpose, \textit{count} and \textit{mover}, initialized by the coordinator a priori to $N$ and $true$ respectively. In a nutshell, mover is true if no getter has yet claimed the role of mover, which represents both (1) the responsibility to clean up, and (2) the privilege of moving the original value, rather than cloning it. Part of the procedure at large is a pair of elections between getters to determine a mover and a \textit{last} getter. We elect a mover first. The time between the elections gives the losers (the `cloners') the opportunity to clone, safe in the knowledge that the mover will not clean up until they are finished. If the mover is also elected last, they clean up and return immediately, as all clones must already be complete. Otherwise, the mover must await a signal from whomever is last before cleaning up.

This process is complete enough to implement the desired functionality for \mbox{Reo-rs}. However, we identify two important optimization opportunities which have the unfortunate consequence of complicating the data exchange procedure further.
\begin{enumerate}
	\item \textbf{Not all getters want data}\\
	Getters participating as a result of the \code{get\_signal} operation will not return a value. Clearly these getters cannot avoid participating in the mover election, as then nobody would clean up. These getters specialize their interactions by participating in the last election first. The intuition is that if they lose this election, it is safe for them to return without participating in the mover election; clearly this covers the case of no getters wanting the data. It is also safe to rearrange these elections in this case; these getters have no intention to \code{clone}, and thus are not a threat to the invariant that required these elections to be ordered in the first place: all clones are complete by the time the last getter is
	
	\item \textbf{\code{Copy}-types can be replicated without \code{clone}}\\
	Section~\ref{sec:rust_language} explains how \code{Copy} marks types for which have a trivial destructor, and are safe for multiple getters to replicate by copying their value bit-wise. This is the case for primitives, and structures composed entirely out of primitives, such as arrays of integers. 
	
	For copy-types, the mover and the copiers may copy the original datum in parallel. Afterward, only the last getter is elected to clean up, safe in the knowledge that all copies are finished.
\end{enumerate}

The full data exchange procedure is spelled out in Rust-like pseudocode in Listing~\ref{sec:data_exchange} in the Appendix.

\subsubsection{Memory Cells}
\label{sec:memory_cells}
Section~\ref{sec:protocol_object_architecture} explains that per \textit{location} (generalizing ports and memory cells), Reo-rs maintains a persistent \code{Space} structure at a fixed location on the heap such that threads have a predetermined location to rendezvous on communication primitives. Section~\ref{sec:data_exchange} follows up, explaining how these structures are also pivotal to data exchange. When getters converge on the space of a \code{Putter}, they rely on the presence of a prepared data reference in the space to the location of the putter's datum on its own stack. In this manner, values moving between ports are never moved to the heap at all. The memory alignment of the putters datum generally differs per data exchange, necessitating that their space's reference be updated to the location of their value each time. 

Memory cells differ from putters in that their value \textit{persists} beyond the lifetime of any individual thread participating in the protocol; consequently, the data itself \textit{must} be stored on the heap. A na\"ive implementation treats memory cells similarly to putters by continuously \textit{updating} the data reference in the associated \code{Space} such that it points to a freshly allocated value on the heap every time the memory cell is filled.

We are able to rely on a property of Reo for an optimization: memory cells have predefined types. Instead of shifting the pointer around to a fresh allocation each time, we are able to \textit{preallocate} the space needed to store one value per memory cell. In this model, the references do not change. Instead, each has a single allocation which is repeatedly reused. Whenever the cell is empty, the contents of the allocated space are \textit{uninitialized}. This can be done safely by relying on auxiliary structures for tracking when memory cells are empty; Section~\ref{sec:minimizing_the_bottleneck} explains how \textit{bit vectors} serve this purpose for Reo-rs. This approach removes the cost of creating and allocating spaces at runtime. Unfortunately, this approach suffers a drawback inherited from its strict interpretation of \textit{value-passing semantics}: moving data between memory cells is expensive. While small optimizations are possible for some circumstances (e.g.,\ we are able to swap references when the contents of two memory cells are \textit{swapped}), they are only applicable in a handful of situations. 

Requirements~$\boldsymbol{G_{data}}$ and~$\boldsymbol{G_{fast}}$ incentivize a more extensive optimization. Reo-rs intentionally decouples memory cells (including their spaces and their fullness flags) from \textit{storage}, which describes where the contents of the cells is kept on the heap. We observe that Reo protocols perform logical replication of values often, while mutating existing values rarely. As such, many situations exist in which we are able to safely \textit{alias} values between memory cells by relying on \textit{reference counting}. We extend the idea of reusing allocations, but rather that fixing them per memory cell, we allow all memory cells of the same data type to draw from a shared pool of reused allocations; this is often referred to as an \textit{arena allocator}. The intricacies of this process are delegated by the coordinator to the \code{Allocator}, which tracks which \textit{storage cells} of a type are available (free) and which are occupied. Rules which replicate, destroy or move data between memory cells thus can often moving data altogether, instead manipulating only the references within spaces, and reference counters of storage cells. For example, a rule which empties memory cell $m_0$ (destroying the contents) needs to only decrement the reference counter. Only when the counter reaches zero does the allocator need to be involved, invoking the value's \code{drop} function in place and freeing the storage slot. This approach has another advantage: \code{clone} is invoked \textit{lazily}, in some cases being avoided altogether. Consider a connector for which values originate from putters, get stored in memory slots, are replicated repeatedly, only to be destroyed before ever being emitted to a getter. In this example, \code{clone} is never necessary. This approach has an additional consequence; the data exchange operation explained in Section~\ref{sec:data_exchange} may be initialized such that \textit{nobody} is permitted to move. The procedure already given (in Listing~\ref{sec:data_exchange}) is able to handle this case.

\subsubsection{Type Reflection}
\label{sec:type_reflection}

Section~\ref{sec:rust_language} explains how Rust offers both static and dynamic dispatch for executing generic code, similar to how it is done for C++. These options offer a trade-off in runtime speed, binary size and flexibility. Reo-rs cannot hope to rely on static dispatch to resolve the concrete types of port data, as they are only discovered later in the moment our \code{Rule} structures are interpreted. The idiomatic approach to such situations is to rely on dynamic dispatch, which virtualizes the operations on some generic type by adding indirection which is resolved at runtime through the traversal of function pointers. As with C++, Rust uses \textit{virtual function tables} (`vtable') for this purpose. Dynamic objects are stored in place with a pointer with the relevant vtable, and operations traverse the table according to a statically-defined layout to resolve the concrete functions. Clearly, this is only possible if the method creating the dynamic object and the operations on it agree on the vtable's contents. To this end, Rust relies on its trait system: dynamic objects are created and interacted with in terms of some trait, which provides it with both an interface and a type. As such, Reo-rs defines a trait \code{PortDatum}, which defines all the operations belonging to all port data: (1) how is the object laid out in memory, (2) how are objects checked for equality, (3) how are objects cloned, etc. Two problems present themselves with this idiomatic approach:
\begin{enumerate}
	\item Who defines \code{PortDatum} for the user's data types? The idiomatic approach is to expose the trait and simply require the user to implement the trait's associated operations to their type. However, if we do not trust the user entirely, some of our desired optimizations become impossible.\footnote{This is a limitation of Rust's trait system, which prohibits the inclusion of associated functions and properties for traits used for the creation of dynamic objects. Rust does not support representing them in the vtable. This limitation may be removed in future.} For example, users must mark their objects as \code{Copy}, communicating that their shallow representation can be safely copied in memory. 
	
	\item How do we express types of \code{PortDatum} which do not implement an equality or clone operator? These may not be defined for the type. One is able to express Reo connectors which will not use these operations (and thus is is correct not to require them), but we cannot know whether they are used statically.
\end{enumerate}

We solve both of these problems by using an experimental feature the Rust language not yet available in the stable version: \textit{specialization}. With this feature, we solve the first problem by defining \code{PortDatum} for every conceivable generic type ourselves, with their fields populated as a function of the type's properties. In this manner, \code{PortDatum} can be made entirely private, benefiting the user in alleviating their need to implement it, and benefiting Reo-rs by guaranteeing it is implemented correctly for every type. This also solves the second problem; as \code{PortDatum} is under our control, we can provide dummy implementations for operations which the type does not define, such that all \code{PortDatum}-implementor types can use the same vtable layout, despite differing in the subset of the trait's operations they define. Conceptually, we can represent undefined functions with null pointers in the vtable. For safety's sake, we instead use dummy functions which trigger an explicit panic, unwinding the stack and throwing unrecoverable errors in the event a programming oversight attempts to traverse these undefined function pointers. Listing~\ref{listing:specialization} gives a simplified\footnote{The real trait definition contains more fields, and must perform some manipulations of raw pointers to get around Rust's restrictions on which traits may be used for dynamic dispatch. For this reason, it is important for us to control its definition for any type~\code{T}. These details are omitted for brevity.} view of the \code{PortDatum} trait, and its implementation for any\footnote{In the final implementation, we must include some trait bounds for all \code{PortDatum} types. \code{Send} and \code{Sync} are common Rust marker traits for types that can be passed between threads by value and reference respectively. They are implemented by default for all reasonable types such that users almost never need to consider them~\cite{klabnik2018rust} (they are derived for user-defined types by default also), but this requirement covers some prickly safety pitfalls.} data type,~\code{T}.

\begin{listing}[ht]
	\centering
	\inputminted{rust}{specialization.rs}
	\caption[Rust specialization to implement traits.]{Using Rust's specialization feature to define \code{PortDatum} (simplified) for every generic type~\code{T} by relying on \code{T} always implementing helper traits \code{MaybeCopy} and \code{MaybeClone}. \code{MaybeCopy} can be implemented for any~\code{T}, defining a default behavior in one block, and then overriding it for a more specialized behavior in the other. The Rust compiler will resolve which block to use based on the static properties of \code{T}, deriving a \code{PortDatum} implementation with precisely the desired definition. In this manner, \code{PortDatum} can be made inaccessible to the user, allowing Reo-rs to trust that it was defined in the expected manner. The helper traits are necessary to satisfy the requirements of the specialization feature: there must be a strict ordering on the specificity of implementation blocks for the same trait.}
	\label{listing:specialization}
\end{listing}

Rust's chosen representation of dynamic objects is the \textit{fat pointer}, which represents a dynamic object as a pair of pointers, one to its \textit{data} (i.e., some structure with fields), and one to its \textit{behavior} (i.e., the vtable). These trait objects can be thought to carry their behavior around with them; they move with their vtables. While ergonomic in general, this is often redundant in the case of Reo, where values are guaranteed to only move between ports and memory cells of the same type anyway. In our case, we would repeatedly overwrite these tuples to overwrite the \textit{data}, and redundantly overwrite the vtable pointer with an identical one. This is a symptom of Rust's approach to dynamic objects in general; it `resolves' their concrete type \textit{per operation}. This approach is detrimental to Reo-rs for two reasons:
\begin{enumerate}
	\item Dynamic objects are accessible through their trait interface. Behind this interface, their concrete types are erased. There is no means to check type-equality between two dynamic \code{PortDatum} objects, as is needed during the \code{build} procedure (see Section~\ref{sec:translation_phase_2}) to ensure that memory is initialized with the expected type and so on.
	
	\item Dynamic objects carry their vtable pointers with them. This increases the size of their representation significantly (in the case of small types)
\end{enumerate}

Our solution is to implement our own dispatch system that makes use of Rust's native vtables and dynamic dispatch, but without the above properties. Essentially, we split Rust's fat pointers into their \textit{data} and \textit{behavior} components, using the former as data as usual, and using the latter as a \textit{key} to reflect on the concrete type's behavior as needed. Section~\ref{sec:imperative_form_sec} introduced the \code{TypeInfo} type, which appears to the user as nothing more than some \textit{identifier} for its type. Under the hood, this value is the vtable pointer itself, thereby usable as a \textit{key} to identify the type and to reflect on the behavior of some dynamic~\code{PortDatum} object inside Reo-rs. Listing~\ref{listing:reflection} shows how function \code{TypeInfo::of} provides the user with the only means of creating a \code{TypeInfo} for some~\code{T}. Only in the creation of the \textit{imperative form} structure (the \code{ProtoDef} type) does Reo-rs accept the user's provided \code{TypeInfo} directly, as it would be unsafe to rely on the user providing some \code{T} with a matching \code{TypeInfo}. Instead, the API of Reo-rs includes one layer of \textit{static dispatch} into the library where necessary such that the creation of the \code{TypeInfo} can be trusted. For example, when populating some \code{MemInitial} structure with the initial values of memory cells (as described in Section~\ref{sec:translation_phase_1}), values can only be input with the \code{with} function. The user uses Rust's safe dispatch system, oblivious to Reo-rs translating their concrete objects into dynamic ones behind the scenes. For example, the user might see:~\code{MemInit::default()::with("hello")}, and Reo-rs would resolve the \code{TypeInfo} for \code{\&'static str} type behind the scenes.


\begin{listing}[ht]
	\centering
	\inputminted{rust}{reflection.rs}
	\caption[Tricking Rust into exposing a vtable.]{`Tricking' the Rust compiler into retrieving the vtable of a given type \code{T} for dynamic dispatch to virtual functions of trait \code{PortDatum}. The safe cast on line~7 inserts a pointer to a vtable which the compiler will ensure is present in the program text. \code{TypeInfo} structures can later be used for type reflection, by manually appending this pointer to reconstruct the fat pointers that Rust natively uses for dynamic dispatch.}
	\label{listing:reflection}
\end{listing}

Listings~\ref{listing:refl_test_in} and~\ref{listing:refl_test_out} in the appendix demonstrate how \code{TypeInfo::of} appears in the generated binary.

\section{Requirements and Guidelines Evaluated}
\label{sec:requirements_evaluated}
In this section, we give a summary of the means by which the requirements and guidelines of Section~\ref{sec:requirements_defined} are satisfied and adhered to respectively. This doubles as an overview of this chapter at large, motivating its points by referring to the relevant subsections above.


\begin{enumerate}
	\item[$\boldsymbol{R_{value}}$] Values passing through ports preserve value-passing. This is achieved even in the presence of reference-passing optimizations `under the table' by leaning on the same philosophy that Rust uses to prevent data races: prohibit mutable aliasing. Objects are only aliased (accessible via multiple bindings) if they are be identical. Section~\ref{sec:port_operations} explains how protocols limit aliasing to their internals by relying on value-passing port operations. On the other hand, Reo-rs aliases values, but only until they are mutated. Section~\ref{sec:memory_cells} explains how memory values are safely aliased.
	
	Section~\ref{sec:imperative_form_sec} explains how Reo-rs interprets an imperative form protocol description at runtime, relying on a transaction-like model to safely allow the creation of new values to be incorporated in synchronous interactions. In this manner, protocols whose rules create and reason about temporary values can be faithfully represented.
	
	\item[$\boldsymbol{R_{init}}$] Section~\ref{sec:user_facing} explains how users are shielded from the granular initialization procedure by exposing an API with explicit constructor functions \code{build} and \code{claim} of protocols and ports respectively. Protocol objects are extensively customizable by the expressiveness of imperative form, with which \code{build} is parameterized. At the same time, these structures are kept internally-consistent by the preservation of invariants, and relying on \code{build} as the only user-facing means of instantiation.
	
	\item[$\boldsymbol{R_{ffi}}$] C and C++ foreign-function interfaces are provided by relying simply declarations with the C ABI where possible. As C cannot support Rust's notion of generics, where necessary, the \code{ffi} module provides generic-free alternatives for data types and functions where generics are represented as data instead. Reo-rs can thus be compiled once into either a statically- or dynamically-linked library for use in these other languages without any additional runtime overhead.
	
	\item[$\boldsymbol{G_{data}}$] Reo-rs facilitates the transmission of any fixed-size data types by value. This permits but does require data to be heap-allocated. Sections~\ref{sec:data_exchange} and~\ref{sec:memory_cells} explains how Reo-rs has a value-passing API, but relies on reference-passing to minimize the number of times values are moved in memory.
	
	\item[$\boldsymbol{G_{fast}}$] Section~\ref{sec:chosen_design} explains Reo-rs coordinates the actions of multiple threads while minimizing the overhead of inter-thread communications. Section~\ref{sec:minimizing_the_bottleneck} explains how meta-operations are represented such that they can be batched, allowing the coordinator to reduce the overhead of processing rules for firing.
	
	\item[$\boldsymbol{G_{end}}$] Section~\ref{sec:chosen_design} explains how protocol objects are not given their own threads, trivially facilitating termination detection if no ports remain to interact with it. Section~\ref{sec:construction_and_destruction} describes how protocol structures are implicitly cleaned up once all of their ports are destroyed. 
\end{enumerate}