\chapter{Generating Static Governors}
\label{sec:api}

The cumulation of the previous chapters describe a standalone contribution to the Reo compiler. We have seen that users are able to generate Rust source code from a Reo specification (Chapter~\ref{sec:imperative_form}) which may be used in conjunction with their own Rust code to behave according to the corresponding protocol specification at runtime (Chapter~\ref{sec:protocol_runtime}). The programmer is able to rely on these protocol objects to constrain the behavior of their program at runtime such that no deviations from the protocol specification may be observed. 

In this chapter, we design the \textit{governor generator}, a tool to augment the user's Reo-coordinated Rust programs. As with the Reo compiler before, this tool generates a Rust source file from the Reo protocol specification which the user may import as a dependency. Within, a Rust type which corresponds with a \textit{governor}. If integrated into the implementation of the user's components, the Rust compiler will enforce that the user's code does not inhibit the behavior of the system at large. In effect, users are provided an ergonomic means to opt into their Rust compiler enforcing liveness properties of their programs. 

Section~\ref{sec:governor_defined} provides the formal definition of governors, and how they relate to protocols, components and liveness. Section~\ref{sec:unintended_constraints} describes the problem the \textbf{governor generator} aims to solve from the perspective of a Rust programmer relying on Reo to coordinate their components' communication. Section~\ref{sec:soluition_static_governance} gives a high-level overview of our corresponding solution. Section~\ref{sec:making_it_functional} explains in detail how the governor generator works, concentrating only on what is required to make it minimally functional. Finally, Section~\ref{sec:making_it_practical} elaborates on the means by which the solution is made ergonomic and practical.

\section{Governor Defined}
\label{sec:governor_defined}
A Reo protocol specification defines which interactions are permitted between its boundary ports. In other words, protocols constrain the behavior of any system in which they are a component. This is the result of Reo's semantics, which 
guarantees that the behavioral constraints of a system are the composition of that of its components, at any granularity. However, protocols do not prevent their boundary components from adding constraints of their own. As a consequence, the definition of a component viewed in isolation does provide any guarantees on which interactions \textit{are} observable in the system at large. To make this possible, a component needs some knowledge about the behavior of the system beyond its own ports. Fortunately, Reo specifications take us halfway there, as they make explicit which behaviors they permit in an unambiguous form that can be transformed, and can be inspected. To proceed, we define the \textit{governor}.

Protocol $P$ with interface ports $I_P$ defines $G_{P,I_P}$, its governor with respect to its interface ports. $G_{P,I_P}$ shares interface $I_P$ with $P$ itself, and also constrains the interactions between them in the same manner as~$P$. However, all port actions in $G_{P,I_P}$ are the complement of those in $P$, i.e.,\ all \code{put}s are \code{get}s and vice versa. $G_{P,I_P}$ characterizes the behavior of a component that, if connected to $P$ with interface $I_P$, would result in a composite system with the same behaviors of $P$ itself. In other words, $G_{P,I_P}$ describes the behavior which $P$ would permit to occur, from the perspective of a component interfacing with all of $P$'s ports.

Governors are generalized such that they are defined for any subset of a protocol's interface ports, i.e.,\ a protocol $P$ with interface $I_P$ defines a set of governors $\{G_{P,x} \; | \; x\subseteq I_P\}$. Governors characterize the reverse-oriented behaviors as before, but such that these behaviors are \textit{projected} onto the governor's own interface; projection is defined precisely by Baier et al.~\cite{baier2006modeling}, and is explained in Section~\ref{sec:rba_projection} when it is needed. Here, it suffices to say that the behavior as constrained by the governor omits the actions of all ports not in the governor's interface. This captures the intuition that the governor only specifies the interactions of its own boundary ports, not constraining the actions of other ports at all. As such, the behavior of a governor is at most as constrained as that of the protocol itself; for every port not included the interface, the governor potentially becomes more `lenient'. This is made clear for the trivial case of a governor with the empty interface, which has no constraints whatsoever.

The utility of this construction is that it provides a means by which a component interfacing with some protocol $P$ with any of its ports may compute precisely which behavior the protocol permits. By relying on the fact that protocol objects will facilitate any and all permitted interactions as possible at runtime, this boundary component is able to predict precisely the behavior the component that arises from its composition with the protocol. In the simplest case, one is able to enforce that the resulting behavior matches the constraints of the protocol; equivalently, the protocol's boundary components do not contribute any behavioral constraints that the protocol itself did not define already. For such systems, one may understand the entirety of the system's coordination behavior by inspecting the definition of the protocol alone. In these cases, we say that the component is \textit{adherent} to the protocol.

\section{The Problem: Unintended Constraints}
\label{sec:unintended_constraints}
A central tenet of Reo's design is the \textit{separation of concerns}, part of which is the desire to minimize the knowledge a compute component must have of its protocol. In this view, coordinating the movements of data is not a concern relevant to the task of computation. A desirable balance is possible with the observation that protocol objects are able to partially impose protocol adherence on their neighbors; Section~\ref{sec:chosen_design} explains that, while external ports may instigate a \code{put} or \code{get} at any moment, the coordinator will complete the operations only once the specification allows it. In this way, coordinators possess a crucial subset of the features of governers: aligning the timing of two actions that compose an interaction. Unfortunately, in the properties of the realm of sequential, action-centric programming itself implicitly imposes constraints on the behavior of the system: \code{put} or \code{get} block until their interaction is completed, and no subsequent code (potentially, other port operations) will occur until they do. This is beyond the capabilities of the coordinator to influence.

In the context of application development, this has an interesting consequence; the behavior of the system is influenced by the behavior of (potentially) all of its components. This is sensible in theory, but becomes unwieldy in practice. Even small changes to the behavior of a compute component influences the system's behavior in unexpected ways, as we are not used to thinking about synchronous code as a composable protocol, nor are we able to intuit the outcome of the composition. For example, Listing~\ref{listing:transform_not} gives the definition of a compute function which a user may write to interact with a protocol. When \code{p} and \code{g} are connected to a $fifo1$ protocol (which forwards \code{p} to \code{g}, buffering it asynchronously in between), it runs forever and the output will be something like:
\begin{verb}
	I saw true. I saw false. I saw true. I saw false. (...)
\end{verb}.\\However, when connected with the $sync$ protocol (which forwards \code{p} to \code{g} synchronously), the system has no behavior. The problem is that even though $fifo1$ and $sync$ have the same interface, \code{transform\_not} is adherent to the former, but not the latter. By definition, $sync$ fires when both \code{p} and \code{g} are ready, but \code{transform\_rot} does not \code{put} until the \code{get} is completed; effectively \code{transform\_rot} constraints the behavior at its ports by imposing an ordering. This property may be obvious at the small scale of this example, but it becomes more difficult the larger and more complex the program becomes. Once the intricacies of these programs grow beyond a programmer's ability to keep track of these relationships, the composed system may have unintended behavior. In the worst cases, an innocuous change adds a new constraint such that no next interaction exists, observed at runtime as deadlock. 


\begin{listing}[ht]
	\inputminted[]{rust}{transform_not.rs}
	\caption[Rust example of a compute component.]{A function in Rust which can be used as a compute component in a system, connected to a protocol component.}
	\label{listing:transform_not}
\end{listing}


\section{Solution: Static Governance with Types}
\label{sec:soluition_static_governance}
In this work, we accept that it is necessary to write compute code that has blocking behavior. Rather than attempting to empower the coordinator with the ability to further influence its boundary components, we empower the boundary components with the ability to manage themselves by exposing the behavior of their protocols. Specifically, we create a means by which we are able to generate the relevant governor for a given protocol and interface. With this information exposed, we ensure that the implementation is adherent to the protocol by prohibiting it from adding any new constraints. Counter-intuitively, this takes the form of disallowing the component from performing the `wrong' port operation, as the resulting blocking behavior would inhibit its ability to perform the `right' port operation.

There is a vast possibility space for facilitating this enforcement on the users code given a governor as it is defined in Section~\ref{sec:governor_defined}; any solution that results in protocol adherence is sufficient. A user with a keen eye would be able to check protocol adherence manually by reasoning about the relationship between their component's control flow. Instead, we opt for a more ergonomic approach that leverages a tool the user is guaranteed to have at their disposal anyway: the Rust compiler. Our solution involves the interplay between two novel facets of the Rust language that follow from its affine type system; 
\begin{enumerate}
	\item We are able to model the protocol's underlying constraint automaton (see Section~\ref{sec:semantic_models}) as a type-state automaton (see Section~\ref{sec:type_state}), such that the Rust compiler is continuously aware of the protocol's \textbf{state} throughout control flow of the user's code wrt.\ its execution at runtime,
	
	\item and we are able to protect the API of Reo-rs's port objects (see Section~\ref{sec:user_facing}) such that the Rust compiler statically allows their use only if doing so in the current \textbf{state} preserves protocol adherence.
\end{enumerate}

From the user's perspective, they are able to opt into the Rust compiler enforcing protocol adherence in their component code. Concretely, the are able to modify their implementation such that it takes the form of a function with a declaration (i.e.,\ type signature) as defined in the Rust dependency generated by the governor generator. The user defines the function with \code{put} and \code{get} operations interspersed with arbitrary Rust code as usual. However, any port operations that would violate protocol adherence will result in the Rust compiler generating a static type error; if their implementation is completed without type errors, the user can be certain that their component's behavior at runtime will be protocol adherent.

\section{Making it Functional}
\label{sec:making_it_functional}
This section details the workings of the \textbf{governor generator} tool which generates Rust code given (a) a representation of a protocol's RBA, and (b) the set of ports which comprise the interface of the compute component to be governed.

\subsection{Encoding CA and RBA as Type-State Automata}
% How to do type-state pattern for CA and RBA
\label{sec:type_space_automaton}
The type state pattern described in Section~\ref{sec:type_state} provides a means of encoding finite state machines as affine types. Their utility is in guaranteeing that all runtime traces of the resulting program correspond to runs in the automaton. For this class of machines, the encoding is very natural, as there can be a one-to-one correspondence between the states of the abstract automaton, and the types required to represent them. This is also the case for transitions and functions; in the worst case, this mapping is one-to-one also. For an arbitrary transition from states $a$ to $b$ with label $x$, a function can be declared to consume the type for $a$, return the type for $b$, and perform the work associated with $x$ in its body. 

The encoding is more complicated for CA, where not only states but data constraints must be encoded into types and must interact with transitions. One approach is to treat configurations as states were treated before by enumerating them into types. For example, the configuration of state $q_0$ with memory cell $m=0$ is represented by type \code{q\_0\_0}, while state $q_0$ with $m=1$ is represented by \code{q\_0\_1}. On a case-by-case basis, one might be able to represent several configurations using one type in the event these configurations are never distinguished. For example, a connector may involve positive integers, but only distinguish their values according to whether they are odd or even and nothing else; in this case \{\code{q\_0\_0}, \code{q\_0\_1}, \code{q\_0\_2}, ...\} may be collapsed to \{\code{q\_0\_odd}, \code{q\_0\_even}\}. For an arbitrary case unique types are needed for every combination of state with every value of every variable. As RBAs are instances of CA, we are able to represent them using the same procedure. As RBAs are used by both the Reo compiler and Reo-rs, they are the model of choice for governors also. 

We extend this idea to the first of the two tenets of our design, as they appear in Section~\ref{sec:soluition_static_governance}. Namely, we model the current configuration of the protocol as a type, updating it throughout our control flow such that it always corresponds with the protocol's configuration. From the user's perspective, they have precisely only token type in scope at all times. As defined previously, we are able to simulate `updating' this type by overwriting it with a replacement token as the return result from a functions whose behavior alters the type. Concretely, our transition function consumes the old token (taking it by value as a parameter), and produces the new token as part of its return value. It follows that at all times we have precisely one token, whose type corresponds with the configuration of the protocol.

\subsection{Rule Consensus}
% how to represent choice
\label{sec:rule_consensus}
The protocol works by firing rules at runtime which correspond to those of the RBA which defines its Reo connector. Section~\ref{sec:type_space_automaton} above explains how various compute components are able to proceed in lockstep with the protocol's RBA in a type-state automaton of their own. For deterministic RBAs, this is easy enough; everyone can trivially know which action occurs next, and they can transition through configuration space independently, safe in the knowledge that their representations of the run will stay aligned. This ignores temporary misalignments in time for transitions in which the compute component does not communicate with the protocol; for these cases, one may work head, leaving the other in a previous state. However, they will catch up eventually when they both reach a transition that involves them communicating (which is ultimately all that matters). This process becomes more complicated when the protocol can reach configurations with multiple choices for the next transitions. Without a priori agreement on how these situations are handled, the choice is defined to be nondeterministic. Clearly, all is well as long as all parties agree on this choice; problems only present themselves when compute components and protocols disagree on what may happen next. If the view of a governor are out of sync with its protocol it is generally unable to guarantee that the actions it permits are adherent, or it may prohibit something it ought not to, resulting in unintended constraints of the intended behavior (in the worst case, deadlock). This is a problem of consensus. 


Many means of creating consensus exist. We are able to enforce a meta-protocol a priori between governors and protocol such that consensus emerges at runtime. This can be achieved without any overhead by making the decision based only on information statically available. For example, peers may rely on a shared, total priority ordering on rules to remove all nondeterministic choice. Many such meta-protocols are possible, each making assumptions about the desired system behavior.

This work takes the approach of statically `electing' the protocol itself as the leader in every case, and having all governors follow the lead of its arbitrary choice by `asking' it what to do next dynamically. This approach is primarily motivated by its flexibility; by supporting an arbitrary choice on the part of the protocol, we make the choice itself an orthogonal concern for future work. Electing the coordinator in particular as the leader is also somewhat natural, as it is only actor in the system with a complete view of the protocol's state, and can thus make the choice as a function of the state, i.e.,\ the protocol is capable of making the best-informed decisions.

In terms of implementation, we make a modification to the encoding of our governor's automaton such that it can represent all choices available from a particular configuration. Before proceeding, the governor `collapses' these options to match the choice of the protocol by communicating with the coordinator. Concretely, the Rust function for a rule no longer returns a particular type-state token, but rather a \code{StateSet} which enumerates the options. This object is collapsed as a result of calling \code{determine}. Handling the returned variants branches the governor's control flow in a manner akin to a \code{match} (similar to a \code{switch} statement in other languages), with each arm given a single state token to proceed. Na\"ively, this must be encoded as a distinct \code{enum} type with a variant for every possible outcome. Clearly creating new type definitions for every conceivable combination of branches is prohibitively expensive.\footnote{Early versions of our implementation indeed enumerated these types with a relatively effective powerset construction. However, it was unable to avoid explosion if there simply were many solutions to be found. The nail in the coffin was the changing from the exponential base from~2 to~3 as a result of the modification explained in Section~\ref{sec:user_defined_simplification}.} Ideally we wish to be able to create enumeration types on-the-fly with precisely the variants needed on a case-by-case basis. Rust provides tuples for this purpose in the case of \code{struct} (product types), it has no parallel for \code{enum} (sum types). This feature has been requested for some time~\cite{anon_sum}. If it is supported one day, this may be ideal fore representing these \code{StateSets} with minimal code generation. 

Until anonymous sum types are supported, our solution to the problem of representing the generic \code{StateSet} type relies on Rust's traits to encode the variants as a tail-recursive list of nested tuples. Matching the elements of the lists is achieved by repeatedly attempting to match the head. Listing~\ref{listing:state_set} shows one possible representation which uses a final sentinel list element to make for an ergonomic definition of the \code{StateSetMatch} trait, which provides distinct head-matching behavior for singleton lists from that of larger ones. From the user's perspective, \code{StateSet} objects are opaque, and prevent the automaton from proceeding with transitions until the object is collapsed to some usable \code{State} object.

\begin{listing}[h!]
	\centering
	\inputminted{rust}{state_set.rs}
	\caption[Rust implementation of an arbitrary state set.]{Definition of type \code{StateSet}, which acts as an anonymous sum type by encoding its variants as a tail-recursive tuple in its generic argument. Two non-overlapping definitions of trait \code{StateSetMatch} are provided to make the type behave as expected in response to associated method~\code{match\_head}. Function \code{example} demonstrates how the arbitrary number of variants are matched two at a time by repeatedly attempting to match the first element of the list (the head), translating it into a conventional \code{Result} enum which Rust can pattern-match as usual. The result of this match can depend on the contents of field \code{data}, which is instantiated dynamically at runtime by interacting with the coordinator.}
	\label{listing:state_set}
\end{listing}

\subsection{Governed Environment}
So far, this section has described only the first of two facets of our design, as they appear in Section~\ref{sec:soluition_static_governance}. Namely, we are able to model the protocol's configuration space, and trace its changes throughout the control flow of the user's component by continuously updating the type of a singleton token in scope. What remains is the step that connects this protocol configuration to its relationship with a given port operation.

We define the \code{Governed<Putter>} and \code{Governed<Getter>} types as wrappers for the \code{Putter} and \code{Getter} types existent in Reo-rs, corresponding to (logical) input and output ports respectively. As is idiomatic in the Rust language, our \code{Governed} type offers a type-safe means of `changing' the API of the type it wraps, without altering the underlying data structure as it is represented at runtime. In other languages, this may be achieved with function overloading.

Everything comes together with the alteration of the API of our wrapper types such that its port operations are specified to consume a particular token, and produce a replacement. For this to work as intended, the function's requirement for the functions' input and output token types must correspond with a transitions in the type-state automaton. In other words, we rely on our ability to determine the API of our \code{Governed} type such that we enforce the conflation of two otherwise orthogonal actions such that one cannot occur without the other: for every port action~$a$ which changes the protocol's configuration from $C_x$ to $C_y$ (1)~$a$ occurs, (2) the token's type for $C_x$ is updated to the type for $C_y$. The effect is the (static) prohibition of port operations which do not correspond to transitions through the protocol's configuration space, i.e.,\ they do not occur `next' for a protocol in the state matching the type of the token. 

For cases there the token corresponds with a protocol configuration in which there are several possible next actions (described in Section~\ref{sec:rule_consensus}), the user's component cannot safely commit to any choice, as it would necessarily constrain the component's behavior, violating its protocol adherence. Such cases are detected statically by having a \code{StateSet} with two or more elements. At runtime, this problem is solved by `asking' the protocol which branch to take, after which we have a single state token and proceed as before. Statically, the choice is not yet known, and so the programmer must provide the definition of the resultant behavior for each case. Section~\ref{sec:rule_consensus} explains that our solution emulates matching by recursively defining behavior in response to suffixes of a list whose elements match those of the \code{StateSet}.

\section{Making it Practical}
\label{sec:making_it_practical}
With a basic outline for the implementation, we are able to realize some functional, yet na\"ive governors. However, there is a long way to go before these systems can be applied in any realistic scenario. In this section, we explain which problems remain to be solved, whether for the sake of managing complexity, or for the user's ergonomics.

\subsection{Approximating the RBA}
The approach to generating a type-state automaton from an RBA was given in~\ref{sec:type_space_automaton}. Our type-state automaton suffer the same state space explosion of Constraint Automata, prior to the inclusion of memory (explained in Section~\ref{sec:semantic_models}). We cannot hope to represent realistic programs with this approach alone, as the type-state automata would be wildly unmanageable in its number of states and transitions. In this section, we explain how the type-state automaton is adapted to approximate the protocol's configuration space such that we strike a balance between accuracy and simplicity, without any effect on the governor's correctness.

\subsubsection{Data Domain Collapse}
% making RBA automata feasible
\label{sec:approximating_rba}
We abandon the goal of faithfully representing the entirety of the protocol's configuration space in favor of representing an approximation by assuming all data types to be the trivial unit type. With this assumption, memory cells may be in one of two states: (a) empty, (b) filled with `unit'. Converting existing RBAs may see large subexpressions of data constraints becoming constant, including checks for equality and inequality between port values. In practice, the vast majority of Reo protocols do not reason about the contents of memory cells beyond distinguishing fullness from emptiness. This is the same rationale behind the optimization explained in Section~\ref{sec:minimizing_the_bottleneck} In this context, this means that usually, two configurations that are only distinguished by having different data values in memory cells or begin put by putters satisfy precisely the same subset of the RBA's guards. Consequently, they do not need to be distinguished. This simplification greatly reduces the total number of types to encode an RBA's configuration space. However, it is still necessary to consider the possible combinations of all empty and full memory cells, requiring potentially $2^N$ types for $N$ cells. Rather than enumerating these types explicitly, we can rely on the structure the RBA provides by simply encoding each automaton configuration as a tuple of types \code{Empty} and \code{Full}. In a sense, each tuple is indeed its own type, but neither the code generator nor the compiler need to pay the price of enumerating all the combinations eagerly. For example, a configuration of three empty memory cells would be represented by type \code{(Empty,Empty,Empty)}. For brevity, we will henceforth abbreviate these tuples by omitting commas, and shortening~\code{Empty} and~\code{Full} to~\code{E} and~\code{F} respectively.


As before, we are able to represent an RBA rule as a function in the Rust language by encoding a configuration change from $q$ to $p$ determines its declaration such that it consumes the type-state of $p$ and returns the type-state of $q$. The na{\"i}ve approach of generating functions per type-state is susceptible to the same exponential explosion that plagued CAs in the first place. Fortunately, tuple types have inherent structure which Rust's generic type constraints are able to understand. The use of generics to ignore elements of the tuple coincides with an RBA's ability not ignore memory values. Consequently only one function definition per RBA rule is required. The way the rule's data constraint manifests is somewhat different, as our function must explicitly separate the guard and assignment parts and represent them as constraints on the parameter type and return type respectively. As an example, Listing~\ref{listing:fifo_tsa} demonstrates the type definitions and rule functions for the $fifo2$ protocol first seen in Section~\ref{sec:semantic_models} with the associated RBA shown in Figure~\ref{fig:fifo2_rba}. Observe that the concrete choices for tuple elements act as value checks for memory cells in either empty or full states. Omission of a check must be done explicitly using a type parameter such that the function is applicable for either case of \code{Empty} or \code{Full}, and to ensure the new state preserves that tuple element; this causes memory cells to have the expected behavior of propagating their values into the future unless otherwise overwritten by assignments. This serves as an example of a case where our simplification coincides with a faithful encoding of the original protocol as $fifo2$ never discriminates elements of the data domains of~$A$ and~$B$.


\begin{listing}[ht]
	\inputminted[]{rust}{fifo_tsa.rs}
	\caption[Type state automaton in Rust for the fifo2 connector.]{Type-state automaton for the $fifo2$ protocol in Rust. The three latter functions correspond to the three rules seen for the RBA in Listing~\ref{fig:fifo2_rba}. Function bodies are omitted for brevity. Note that \code{M} is not a type, but rather a generic type parameter to be instantiated at the call site.}
	\label{listing:fifo_tsa}
\end{listing}




\subsubsection{RBA Projection}
% removing silent transitions p1
\label{sec:rba_projection}
When a protocol's interface is provided as-is to a compute component, its model itself (an RBA in our case) defines precisely what it is permitted to do, just with the orientation of operations reversed; for the component to be compatible, it must put on port $P$ whenever the protocol gets on $P$, and get on port $Q$ whenever the protocol puts on port $Q$. In such cases, the procedure for encoding the RBA described in Section~\ref{sec:approximating_rba} can be applied directly. Otherwise, the interface of a compute component does not subsume the entirety of the interface of its protocol. In such systems, the protocol interfaces with several compute components. Indeed such cases form the majority in practice; compute components tend to only play a small role in a larger system.

The contents of Section~\ref{sec:approximating_rba} are sufficient to generate some functional governors. We consider a system containing protocol $P$ and connected compute component $C$ with interfaces (port sets) $I_P$ and $I_C$ respectively such that $I_P \supseteq{} I_C$. We wish to generate governor $G_C$ whose task is to ensure that $C$ adheres to $P$. As a first attempt, we translate $P$'s RBA to Rust functions and types as-is. We would quickly notice that the RBA's data constraints represent port operations that are excluded from $I_C$. These interactions involve no actions on $C$'s part; from the perspectives of $C$ and $G_C$, these actions are \textit{silent}. Equivalently, we do not use the RBA of $P$ directly, but consider instead its projection onto $I_C$, which \textit{hides} ports not in the interface projected upon, omitting the actions of those ports from the specification. 


\begin{table}
	\centering
	\begin{tabular}{l|ll|}
		rule & guard & assignment \\
		\hline
		0 & $m_0=*$ & $\gapwedge{}m_0'=d_A$\\
		1 & $m_0\neq{}*\gapwedge{}m_1=*$ & $\gapwedge{}m_1'=m_0\gapwedge{}m_0'=*$ \\
		2 & $m_1\neq{}*$ & $\gapwedge{}d_B=m_1\gapwedge{}m_1'=*$ \\
		\hline
	\end{tabular}
	\caption[RBF for the fifo2 connector.]{RBF of the \textit{fifo2} protocol, equivalent to the RBA in Figure~\ref{fig:fifo2_rba}. Formatted with an outermost disjunct per line such that guard and assignment parts per rule are discernible.}
	\label{tab:fifo2_rbf_tsa}
\end{table}

\begin{listing}[ht]
	\inputminted[]{rust}{fifo_tsa_2.rs}
	\caption[Type state automaton in Rust with silent rules.]{Type-state automaton rules which govern the behavior of a compute component with interface ports $\{A\}$ for the $fifo2$ protocol. Function bodies list the actions which the component contributes to the system. Observe that rules but 0 are silent.}
	\label{listing:fifo_tsa2}
\end{listing}

As an example, we once again generate a governor for a compute component with interface $\{A\}$ with the $fifo2$ protocol. This time the protocol is represented as an RBF in Table~\ref{tab:fifo2_rbf_tsa} to make the correspondence to the generated governor in Figure~\ref{listing:fifo_tsa2} more apparent. Observe that all but one of its rule functions are silent, serving no purpose but to advance the state of the automaton by consuming one type-state and producing the next. As demonstrated here, this approach to generating governors is correct, but has two undesirable properties:
\begin{enumerate}
	\item \textbf{API clutter}\\
	The user is obliged to invoke functions which correspond with rules in the protocol's RBA. In many cases, these rules will serve no purpose other than to consume a type-state parameter, and return its successor.
	
	\item \textbf{Protocol entanglement}\\
	The type-state automaton captures the structure and rules of the protocol's RBA in great detail. This is a failure to separate concerns, which further couples the compute component to its protocol. This has the immediate effect of making components difficult to reuse (their implementations are more protocol specific), as well as making them brittle to changes to the protocol, making them difficult to maintain. 
	
\end{enumerate}

\subsubsection{RBA Normalization}
% removing silent transitions pt 2
\label{sec:rba_normalization}
Section~\ref{sec:rba_projection} introduced a procedure for generating governors, but also discussed a significant weakness; all governors are represented by type-state automata based on the original protocol's rules. In this section, we introduce a notion of \textit{normalization} that intends to specialize the governors according to its needs such that it is still `compatible' with the protocol's RBA in all ways that matter, but has greatly reduced api clutter and protocol entanglement. 

Let an RBA be in normal form if it has no silent rules. We observe that the presence of silent rules contributes to both api clutter and protocol entanglement. Ideally, we wish to abstract away the workings of the protocol as much as possible; at all times, the governor only needs to know which actions the component must perform next. To make this notion more concrete, we introduce some definitions which build on one another to define the term we need: our normalization procedure should generate an RBA with starting configuration which \textit{port-simulates} the protocol's RBA in its starting configuration:
\begin{itemize}
	\item $Act(r)$ of an RBA state $r$:\\
	The set of ports in $r$ which perform actions (ie: are involved in interactions).
	
	\item \textit{Rule sequence} from $c_0$ to $c_1$ of RBA $R$:\\
	Any sequence of rules in $R$ that can be applied sequentially, starting from configuration $c_0$ and ending in configuration $c_1$.
	
	\item \textit{$P$-final} wrt.\ port set $I$:\\
	A rule sequence of RBA $R$, with last rule $r_{last}$ is $P$-final with respect to port set $I$ if $Act(r_{last})\cap{}I=\{P\}$ and for all rules $r$ in the sequence, $r=r_{last} \lor{} Act(r)\cap{}I=\varnothing$.	
	
	\item RBA $R_1$ in config.\ $c_1$ port-simulates $R_2$ in config.\ $c_2$ wrt.\ Interface $I$:\\
	If for every $P$-final rule sequence of $R_2$ starting in $c_2$, ending in $c_2'$ there exists some $P$-final rule sequence of $R_1$ starting in $c_1$, ending in $c_1'$ such that $R_1$ in $c_1'$ port-simulates $R_2$ in $c_2'$.
\end{itemize}

The intuition here is that it does not matter how the governor's RBA structures its rules. It is unnecessary for governors to advance in lockstep with the protocol to the extent that they agree on the protocol's configuration at all times. It suffices if the protocol and governor always agree on which actions the ports in their shared interface do next. Figure~\ref{fig:path_sim} visualizes this idea; observe how the normalized RBA has entirely different transitions (different labels and configurations), but is ultimately able to pair actions of the protocol for ports in its interface with its own local actions.

\begin{figure}[ht]
	\centering
	\footnotesize
	\begin{tikzpicture}[node distance=2cm, inner sep=0.5mm ]
	
	\node[state, initial, initial text=(a)\\\\] (qee) {\code{(E,E)}};
	\node[state, right of=qee] (qfe) {\code{(F,E)}};
	\node[state, right of=qfe] (qef) {\code{(E,F)}};
	\node[state, right of=qef] (qee2) {\code{(E,E)}};
	\node[state, right of=qee2] (qfe2) {\code{(F,E)}};
	
	\node[state, initial, below of=qee, yshift=7mm, initial text=(b)\\\\] (qee') {\code{(E,E)}};
	\node[state, right of=qee'] (qfe') {\code{(F,E)}};
	\node[state, right of=qfe'] (qef') {\code{(E,F)}};
	\node[state, right of=qef'] (qee2') {\code{(E,E)}};
	\node[state, right of=qee2'] (qfe2') {\code{(F,E)}};
	
	\node[state, initial, below of=qee', yshift=7mm, initial text=(c)\\\\] (qee'') {\code{(E,E)}};
	\node[state, below of=qfe', yshift=7mm] (qfe'') {\code{(F,E)}};
	\node[state, below of=qfe2', yshift=7mm] (qfe2'') {\code{(F,E)}};
	
	\draw
	(qee) edge[above] node{\code{A.get}} (qfe)
	(qfe) edge[above] node{$\cdot$} (qef)
	(qef) edge[above] node{\code{B.put}} (qee2)
	(qee2) edge[above] node{\code{A.get}} (qfe2)
	
	(qee') edge[above] node{\code{A.put}} (qfe')
	(qfe') edge[above] node{$\cdot$} (qef')
	(qef') edge[above] node{$\cdot$} (qee2')
	(qee2') edge[above] node{\code{A.put}} (qfe2')
	
	
	(qee'') edge[above] node{\code{A.put}} (qfe'')
	(qfe'') edge[above] node[pos=0.9]{\code{A.put}} (qfe2'')
	;
	\end{tikzpicture}
	\caption[RBAs in lockstep with and without normalization.]{Rules being applied to walk three RBAs in lockstep, with time horizontally, showing the (simplified) configurations traversed, and annotating rules by showing which port actions they involve.\\(a)~RBA of protocol $fifo2$. (b)~RBA of $fifo2$ projected onto port set $\{A\}$. (c) RBA of $fifo2$ projected onto port set $\{A\}$ and normalized to remove silent rules.}
	\label{fig:path_sim}
\end{figure}



\begin{listing}[ht]
	\inputminted[]{rust}{normalize.rs}
	\caption[Normalization procedure Rusty pseudocode.]{Normalization procedure, expressed in (simplified) Rust code. In a nutshell: while one exists, an arbitrary silent rule $x$ is removed, and the list of rules is extended with composed rules $x\cdot{}y$ such that $y$ is another rule.}
	\label{listing:normalize}
\end{listing}

The final normalization procedure is given in Listing~\ref{listing:normalize} in the form of simplified Rust code. It works intuitively for the most part: silent rules are removed, and new rules are added to retain their contribution of moving the RBA through configuration space. The function \code{normalize} ensures that the returned rule set is in the same configuration as the protocol after matching a non-silent, but the configuration is allowed to `lag behind' while the protocol performs rules which it considers to be silent. New rules must be added to `catch up' to the protocol after any such sequence of silent rules. The procedure does this by building these \textit{composed} rules from front to back, i.e., replacing every silent rule $x$ with a set of rules $x\cdot{}y$, where $y$ is any other rule. Once completed, the RBA may contain rules that are subject to simplification. For example, \{$m=*\wedge{}n=*$, $m\neq{}*\wedge{}n=*$\} can be represented by only $n=*$.

The normalization algorithm is \textbf{correct} as clearly it does not have silent rules once it returns (\code{not\_silent} containing zero silent rules is invariant). Observe that for each silent rule removed, it does not consider composing with itself. The immediate result is that the algorithm never inserts some rule $x\cdot{}x$ for silent rule $x$. This is not a problem, as all silent rules of our approximated RBAs are idempotent with respect to their impact on the configuration. The algorithm is able to take for granted that the result any chain of silent rules $x\cdot{}x\cdot{}x\cdot{}...$ is covered by considering $x$ itself. Furthermore, the incremental removal of rules prohibits the creation of any silent cycles at all. This is due to the reasoning above being extended to any sequences also\footnote{The reader may note the similarity between this observation and that made by the pumping lemma for regular languages~\cite{linz2006introduction}. In both cases, we observe that an arbitrary sequence of `idempotent' cycles as part of a walk through configuration space have no influence on the rest of the path.}. 


The normalization algorithm is \textbf{terminating}. It consists of finitely many algorithm steps in which the RBA $A$ is replaced by RBA $B=(A \setminus{}\{r\}) \cup{} \{r\cdot{}x | r\in{} A\setminus{}\{x\} \wedge{} composable(x,r)\}$ for some silent rule $x \in{} A$. Initially, $A$ is the input RBA with silent rules. The algorithm terminates, returning $B$ when $A$ is replaced by $B$ where $B$ has no silent rules. Let $P(x)$ be the set of acyclic paths through RBA $x$'s configuration space. Observe that initially, $P(A)$ is finite. It suffices to show that in each algorithm round, $|P(A)|$ strictly decreases. Within a round, for every `added' $p$ in $P(B)\setminus{}P(A)$, $p$ contains a rule $m\cdot{}n$ such that there exists $p'$ in $P(A)\setminus{}P(B)$ identical to $p$ but with a 2-long sequence of rules $m, n$ in the place of $x$. From this we know that $|P(A)| \geq |P(B)|$. However, the 1-long path of $x$ itself is clearly in $P(A)\setminus{} P(B)$. Thus, $|P(A)| > |P(B)|$. \textsc{qed}.

To demonstrate the normalization procedure, Table~\ref{tab:fifo2_rbf_tsa_norm} shows the result of projecting the $fifo2$ connector's RBF onto port set $\{A,B\}$ and normalizing. The two additional rules can be understood to `cover' the behavior lost as a result of omitting the silent rule 1 from the original~RBF.


\begin{table}
	\centering
	\begin{tabular}{l|ll|}
		rule & guard & assignment \\
		\hline
		0 & $m_0=*$ & $\gapwedge{}m_0'=d_A$\\
		2 & $m_1\neq{}*$ & $\gapwedge{}d_B=m_1\gapwedge{}m_1'=*$ \\
		\hline
		$1\cdot{}0$ & $m_0\neq{}*\wedge{}m_1=*$ & $\gapwedge{}m_0'=d_A\wedge{}m_1'=m_0$ \\
		$1\cdot{}2$ & $m_0\neq{}*\wedge{}m_1=*$ & $\gapwedge{}m_0'=*$ \\
		\hline
	\end{tabular}
	\caption[RBF of fifo2 connector, projected and normalized.]{RBF of the $fifo2$ protocol, projected onto port set $\{A,B\}$ and normalized. Rules 0 and 2 are retained from Table~\ref{tab:fifo2_rbf_tsa}, and new rules $1\cdot{}0$ and $1\cdot{}2$ are composed of rules from the original RBF.}
	\label{tab:fifo2_rbf_tsa_norm}
\end{table}


\subsection{User-Defined Protocol Simplification}
\label{sec:user_defined_simplification}
Recall, the purpose of a governor is to preserve a system's liveness.
They do this by ensuring that their governed compute component performs port operations that allow the interfacing protocol (and the system around it) to progress. 
Governors do this by enforcing that their compute component's implementation \textit{covers} each possible transition by providing code that performs the required task, and ensuring it is chosen correctly in accordance with the wishes of the protocol. Section~\ref{sec:rule_consensus} explains how our type-state automaton represents this by each configuration requiring the definition of a set of transitions, one for each action. We say the implementation `covers' each of these cases by defining the component's behavior in each cases, including the invocation of the relevant port operation.

An overzealous governor which requires to cover additional (unnecessary) cases would still serve its purpose. In effect, such a governor would enforce adherence to some other, more permissive protocol. However, liberty of the protocol means responsibility to the compute component: the more the protocol might do, the more the compute component must consider doing. There is incentive for governors to do this: permissive protocols are simpler to enforce.

This conservatism becomes a problem when it infringes on the component's ability to express its behavior as intended. Consider the example of a compute component~$X$ that forwards values from its input port~$A$ to its output port~$B$. Perhaps this component is used in a pipeline as intended such that the component is involved in an endlessly alternating sequence, represented by regular expression~$(AB)^*$. Perhaps there is a sensible way for $X$ to implement the more permissive protocol which permits~$B$ firings to be omitted, expressed $(A(B|\lambda{}))^*$. $P$ has no problem discarding values input from $A$. However, if the governor takes it a step further such that `anything goes' (expressed $(A|B)^*$), $X$~cannot meaningfully represent its work. How on earth can it forward a message to $B$ before receiving it on~$A$? Not even clairvoyance can help; what if $A$ never fires at all? This is how the user would experience the problem of a governor infringing on the component's own behavior; in a sense,~$P$ has a protocol of its own which must be preserved on its interface ports which the governor violates.



\begin{table}
	\centering
	\begin{tabular}{l|ll}
		rule & guard & assignment \\
		\hline
		0 & $m_0=*$
		& $\gapwedge{}m_0'=d_A$\\
		1 & $m_0\neq{}*\wedge{}m_1=*$
		& $\gapwedge{}m_1'=d_A\wedge{}m_0'=*$\\
		2 & $m_0=m_1\neq{}*\wedge{}m_2=*$
		& $\gapwedge{}m_2'=d_A\wedge{}m_0'=m_1'=*$\\
		3 & $m_0=m_1=m_2\neq{}*$
		& $\gapwedge{}d_B=m_0\wedge{}m_0'=m_1'=m_2'=*$\\
		\hline
	\end{tabular}
	\caption{RBF of the $a7b1$ connector, which is characterized by cycling through a predictable sequence of period~8, where~$A$ inputs seven times and~$B$ outputs once. It works by encoding its configuration in an 8-long cycle as a three bit integer using the fullness of memory cells $m_{0-2}$.}
	\label{tab:counting_rbf}
\end{table}

Nevertheless, there is value in providing a compute component with a simplified (permissive) view of the protocol where possible. As a motivating example, consider the $a7b1$ connector, given as RBF in Table~\ref{tab:counting_rbf}. This connector uses the fullness of three memory cells to count in binary from zero to seven (using the binary alphabet of memory cell states $\{\text{\code{E}}, \text{\code{F}}\}$), and cycling back again to zero. Configurations in this cycle are distinguished by specifying different behaviors on~$A$ and~$B$. Here, the projection and normalization of the protocol's RBF is trivial, as no rules are silent. Without the ability to simplify, the~$Y$ must be implemented such that it corresponds exactly with the protocol's (predictable) walk through its approximated configuration space, given in Figure~\ref{fig:counter_RBAs}. As all states are distinguishable, so too are their corresponding state types distinct. Now consider this protocol interfacing with some compute component~$Y$, which is always ready to consume and emit some data element~$Q$. Without simplification, the resulting governor would require that the traversal through configuration space be spelled out; the user would be forced to distinguish these states, even though~$Y$ has no need for this specificity. Most likely, the resulting implementation will be repetitive and verbose, if the behavior is the same for configurations \code{(EEE)}, \code{(EEF)}, et cetera.

\begin{figure}[ht]
	\centering
	\footnotesize
	\begin{tikzpicture}
	[ inner sep=0.6mm ]
	\matrix (m) [ matrix of nodes, row sep=0.5cm, column sep = 0.7cm, 
	nodes = {anchor=center,circle, draw=black, thick, fill=gray!10},] {
		\node(m0)[initial]{\texttt{EEE}}; & \node(m1){\texttt{EEF}}; & \node(m2){\texttt{EFE}}; & \node(m3){\texttt{EFF}}; & \node(m4){\texttt{FEE}}; & \node(m5){\texttt{FEF}}; & \node(m6){\texttt{FFE}}; & \node(m7){\texttt{FFF}};\\
	};
	\draw
	(m0) edge[above] node{$A$} (m1)
	(m1) edge[above] node{$A$} (m2)
	(m2) edge[above] node{$A$} (m3)
	(m3) edge[above] node{$A$} (m4)
	(m4) edge[above] node{$A$} (m5)
	(m5) edge[above] node{$A$} (m6)
	(m6) edge[above] node{$A$} (m7)
	(m7) edge[bend left, above] node{$B$} (m0)
	;
	\end{tikzpicture}
	\caption[Configuration space of the a7b1 connector.]{Rules transitioning through configuration space of approximated RBAs for the $a7b1$ connector, with states named after the `count' the three memory cells represent in base~2 (in binary alphabet $\{\text{\code{E}}, \text{\code{F}}\}$). Here, the normalization procedure with interface set~$\{A,B\}$ is trivial as no transitions are silent.}
	\label{fig:counter_RBAs}
\end{figure}

Our solution to this problem is to introduce a third type for representing the state of a memory cell which may be either full or empty:~\code{Unknown} (abbreviated as~\code{U}). Rather than corresponding to a specific configuration of the (approximated) RBA, the governor now reasons about the set of states which the protocol may be in. For example, type \code{(UUE)} encapsulates all the concrete configuration types $\{\text{\code{(EEE)}}, \text{\code{(EFE)}}, \text{\code{(FEE)}}, \text{\code{(FFE)}}\}$, and is liable to covering the union of the rules applicable to any of those states. In this manner, it is safe for the programmer to arbitrarily `forget' the state of a memory cell, replacing its element in the tuple type with~\code{U}. To be clear, \code{U} is not special as far as Rust is concerned; we have changed to a ternary alphabet for representing memory cells in types. However, \code{U} does not correspond to any real configuration that memory cells are ever `really' in at runtime; they are always either empty or full. \code{U} is a stand-in for an empty or full memory variable, an abstraction in which the protocol is not (explicitly) involved.
With this tool in their belt, the implementation of the compute component is able to arbitrarily unify the state types of multiple branches. Our example component~$Y$ above is able to implement its behavior to the satisfaction of its governor with transitions through configuration space in Figure~\ref{fig:weakening}. This weakening can be communicated quite ergonomically, resulting in something very close to what the user would implement themselves: a single loop where the four rules (numbered 0-3) may be applied to configuration type~\code{(UUU)}, each resulting again in~\code{(UUU)}.


\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[node distance=2cm, inner sep=0.5mm ]
	\node[state, initial]      (q000) {\texttt{EEE}};
	\node[state, below right of=q000] (q???) {\texttt{\textcolor{red}{UUU}}};
	\node[state, above right of=q???] (q??1) {\texttt{\textcolor{red}{UU}F}};
	\node[state, below right of=q???] (q?10) {\texttt{\textcolor{red}{U}FE}};
	\node[state, below left of=q???] (q100) {\texttt{FEE}};
	\draw
	%	weakenings
	(q000) edge[dashed, bend left] node{} (q???)
	(q??1) edge[dashed, bend left] node{} (q???)
	(q?10) edge[dashed, bend left] node{} (q???)
	(q100) edge[dashed, bend left] node{} (q???)
	
	%	actual transitions
	(q???) edge[above left, bend left] node{0} (q??1)
	(q???) edge[above right, bend left] node{1} (q?10)
	(q???) edge[below right, bend left] node{2} (q100)
	(q???) edge[below left, bend left] node{3} (q000)
	;
	\end{tikzpicture}
	\caption[Configuration traversal for a7b1 connector using weakening.]{Rules transitioning between configurations of the $a7b1$ connector shown in Figure~\ref{fig:counter_RBAs}. Here, the user employs weakening to convert (dashed arrows) state tokens to configurations to the configuration set `???' containing all concrete configurations. RBA rules firing are shown with solid arrows, annotated with the rule name, corresponding to those given in Table~\ref{tab:counting_rbf}.}
	\label{fig:weakening}
\end{figure}



\subsection{Match Syntax Sugar}
Section~\ref{sec:rule_consensus} explains how the set of transitions to be covered by a configuration type can be represented in Rust's type system as a tail-recursive list. This alleviates the problem of having to explicitly enumerate the needed sets each as their own enumeration type. This is necessary, as the upper bound\footnote{Many factors reduce this number drastically in practice. For example, state sets are usually not large because they are only ever encountered when reached by transitions from some state.} of state sets is $2^{3^M}$, where $M$ is the number of memory cells;\footnote{The number of unique state sets is $2^S$, where $S$ is the number of configurations (automaton state types). This, in turn is $3^M$, as each memory cell's state is represented by a type in $\{\text{\code{E}}, \text{\code{F}}, \text{\code{U}}\}.$} suffice it to say, it is a large number.
Unfortunately, these are not natively-supported enumeration types, and thus cannot be matched as is idiomatic in the Rust language. However, Rust has extensive support for abstract syntax tree macros, allowing us to have the best of both worlds; the user interacts with \code{StateSet} types by using a match-like macro which enumerates the branches, but there is no need for concrete \code{enum} classes to be defined for all the conceivable combinations. Figure~\ref{listing:sugar} gives an example of how these cases compare to one another.


\begin{listing}[ht]
	\centering
	\inputminted{rust}{sugar.rs}
	\caption[Example of mimicing enum matching with a sugaring macro.]{Example of three methods for matching a state set, representing a sum type of three variant types simplified here to \code{X}, \code{Y} and \code{Z}. First, \code{match\_standard} shows how this is done in idiomatic Rust, requiring an enum type \code{StateSetXyz} be explicitly defined. \code{match\_recursive} shows how the same state set represented by a tail-recursive \code{StateSet} type can be similarly matched by exhaustively `unzipping' head elements using a function \code{match\_head}. finally, \code{match\_macro} functions identically to the second case, but relies on a sugaring macro \code{match\_set} to mimic the syntax of Rust's \code{match} statement, seen in the first function.}
	\label{listing:sugar}
\end{listing}