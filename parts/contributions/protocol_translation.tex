\chapter{Protocol Translation}
\label{sec:imperative_form}

The task of the Reo compiler is to translate a Reo protocol specification into the target language. The resulting code must interface with other components written in the language such that, at runtime, the resulting system behaves as specified. In this chapter, we explain how we extend the Reo compiler to support the Rust language target.

Section~\ref{sec:two_phase} examines the task of the backend, the translation from the Reo compiler's internal representation (`RIR') to an executable protocol object in the target language. This task is broken down into smaller, more specialized subtasks. Section~\ref{sec:decoupling_reo_rust} organizes these subtasks into a pipeline that sees the translation through from Reo specification to executable Rust protocol object. To bridge the gap between Reo and Rust compilers, Section~\ref{sec:imperative_form_sec} defines \textit{imperative form} (`IF') as a novel representation of a protocol's behavior in a manner conducive to imperative languages, but not yet fine-grained or inherently coupled to one language in particular. Section~\ref{sec:translation_pipeline} goes into detail about the implementation of the translation pipeline by explaining how the previously-defined subtasks are completed in stages. This includes an example of the output of the Reo compiler: Rust source code whose contents are primarily a Rust-embedded representation of IF.

%\hl{
%	The task of the Reo compiler is to translate a Reo protocol specification into the target language. The resulting code must interface with other components written in the language such that, at runtime, the resulting system behaves as specified. Rust is an example of an imperative language, unable to represent port interactions at the same high level. Our generated code must implement the specification in terms of imperative actions
%	
%	Imperative languages must instead 
%	between a set of \textit{components} written in the target language. When connected together in the manner corresponding to the s
%	
%	the task is to generate a rust protocol object from the reo spec such that it can be used in a rust program.
%	3. naive extreme: 100 percent reo is infeasible: must do signficiant work emulating rust. and they both become tightly coupled
%	4. java solution is to move common object defs to a library. this is fine but its not enough! (WHY)
%	5. 
%	4. java recognized this problem and has the solution of using a lib for protocol and port. still, if we attempted to emulate this choice of granulairty, reo would still do the majority of the heavy lifting
%	5. we have a structured approach. isolate the tasks involved in the transformation. we identify that two are language-independent if beyond the target being imperative. 
%	6. we make this distinction concrete in considering it a two-step process with imperative form in the middle: representing the specification of an imperative protocol.
%	
%	3. follow the precedent of moving as much as possible to a library. minimizes repetition and avoids reo compiler from being too coupled on the implementation. on the other hand, moving things into the library prevent them from being entirely statically generated; forces us to express it in terms that can be computed at runtime. we strike a balance by performing all the high level transformations at runtime 
%}

%In this chapter, we describe the process of translating the Reo compiler's internal representation of a protocol specification into an executable \textit{protocol object} in the Rust language.

\section{Structuring the Translation Process}
\label{sec:two_phase}
In this section, we explore the nature of the task which characterizes the Rust backend for the Reo compiler. Section~\ref{sec:sub_tasks} breaks the problem down into simpler subtasks, and explains their relationship to one another and how they apply in the case of a different target language. Section~\ref{sec:decoupling_reo_rust} explains how these tasks are organized by defining their place within a translation pipeline. The implementation of the pipeline itself is given in Section~\ref{sec:translation_pipeline}.

\subsection{Translation Subtasks}
\label{sec:sub_tasks}
The Reo compiler's frontend parses its input in the Reo language with textual syntax. It performs significant transformations on its internal representation before arriving at what we call RIR. Everything that follows is the task of the backend, transforming it further until code in the target language can be emitted. Reo and Rust differ significantly in how they represent work. Accordingly, a protocol expressed in the former must be transformed significantly before it can be expressed in the latter. In this section, this task is decomposed into \textit{subtasks} which serve a dual purpose (1) smaller tasks are more easily understood, and help to characterize Reo and Rust by identifying their differences, and (2)~only isolated subtasks can be separated, allowing the entire task to be performed in stages, as the \textit{pipeline}.  Here, we explain how the pipeline is structured; the implementation of the subtasks is left to Section~\ref{sec:translation_pipeline}.

\subsubsection{Input Representation}
RIR embodies the completion of several of the operations on Reo connectors described in the literature~\cite{baier2006modeling, dokter2018rule}; namely, \textit{composition}, \textit{merging}, \textit{hiding}, and so on. For our purposes, it suffices to say that RIR is presented in a form corresponding closely to an RBA, one of the semantic models described in Section~\ref{sec:semantic_models}. RIR is self-contained, and defines a list of \textit{rules} which correspond 1-to-1 to interactions between the protocol's ports. It captures the intuition of an RBA as they are usually understood in an imperative context; rules are subdivided into parts \textit{guard} and \textit{assignment}. Helpfully, RIR presents the latter not as a monolithic formula, but rather as a mapping from identifier to \code{Term} objects. In our imperative context, terms can be understood as expressions whose evaluation at runtime will create new values. For example, \code{True} is a boolean type term, while \code{Port("A")} may be understood as the value put by port~$A$.

\subsubsection{Subtasks Involving Actions and Data Types}
Reo specifications represent connectors declaratively as relations between ports. They are thus well suited to reasoning about the protocol's properties. In contrast, our target imperative languages such as Java and Rust represent computation such that it corresponds more closely to machine instructions; they are \textit{imperative}, laying out sequences of actions which together emerge as interaction at runtime. Where interactions in the former can be oriented around the synchronous observations of port values, interactions of the latter must be expressed as sequences of actions, laid out over time. RIR is somewhere in between. Per RIR rule, the guard is distinguished from the assignment, suggesting a coarse-grained ordering of operations: the guard is evaluated before values are assigned. This is a step in the right direction, but requires further transformation before it can correspond to executable Rust. For example, RIR is able to disambiguate the order in which memory cells are read and written to by implying an ordering by annotating their identifiers with qualifiers comparable to those in temporal logic (in both syntax and semantics). For example, the assignment corresponding to $m=A\wedge{}m'=B$ does not explicitly express an ordering, but nevertheless implies it by annotating $m$ with a qualifier to represent its `next' value. Rust's imperative nature requires that operations on values occur in the order of their appearance in the program's control flow, as this determines the order in which they will be executed (Rust compiler optimizations aside).

Java, Rust and Reo have in common that they are strongly-typed languages. In the broader sense, `type' describes the classification of just about everything in Reo, including connectors and primitives. The Reo compiler's internals perform transformations that handle the majority of what could be considered `type checking'. The only exceptions are (1) the data types of each port, determining the types of values they transmit, and (2) the types of functions applied to values within the channel, which are expressed as relations between an identifier and a list of arguments (each expressed as \code{Term}). For the sake of programmer ergonomics, Reo permits the data types of ports to be omitted, such that they can later be derived in context. As this task is not performed by the Reo compiler's frontend, it becomes the responsibility of the backend to resolve these types. In compiling to Rust, the backend must take care that these types adhere to Rust's rules for types as well as Reo's. For imperative languages without types, it suffices to represent them with a universal type, e.g., \code{Object} in Java.

\subsubsection{Subtasks for Abstract and Concrete Targets}
Regardless of any intermediate representation, protocols must ultimately be emitted in the target language at the required level of specificity. Imperative languages place the burden of defining \textit{how} their work is performed squarely on the shoulders on the programmer. For example, where a declarative language might not distinguish \textit{merge sort} from \textit{bubble sort}, Rust certainly does; a Rust programmer operations on variables which correspond (relatively) closely to machine instructions as they will be executed at runtime. This is also true in the case of our problem; what is implied in Reo must be made explicit in Rust. This includes the initialization of system resources, operations on concurrency primitives, and all the minutia necessary to implement the optimizations described in Section~\ref{sec:behavior_implementation}. 

We observe that one can perform meaningful protocol translation work, resulting in its expression in imperative manner without committing to a particular language's minutia. On the other hand, an abstract specification may be made concrete by translating it into a particular language. We distinguish these notions by differentiating between specification and implementation.\footnote{These abstract concepts tend to fall apart under scrutiny, as they depend on what is meant by `computation' at all. Nevertheless, this observation is helpful in the context of our problem, as we prescribe the relationship between Reo and Rust by using the former to `model' the latter.}  

It is beneficial to recognize that a significant portion of the translation from Reo to Rust would be shared by the same procedure to a similar language; the more similar language, the more we can expect their respective transformations to have in common. For example, despite their significant differences, Rust and Java are more similar to each other than they are to Reo. We attempt to generalize Rust, Java and languages like them in accordance with common terminology. We characterize \textit{imperative} languages by a need to sequentially order their actions of values with respect to causal dependency. Recall the example of a memory cell, for which both a read and a write are expressed in $m=A\wedge{}m'=B$. An imperative language would require that these two distinct actions be laid out in a sequence: namely, $[m=A, m=B]$. Observe that with the explicit ordering, the implicit ordering is no longer necessary, and the `next' qualifier can be discarded without introducing ambiguity.

Toward compilation to Rust, we are forced to resolve the data types of ports and functions. This resolution is inherent to Reo itself, and thus, would be inherited by any target imperative language. For this reason, we are able to reason about the \textit{properties} that characterize a port type, insofaras the releation is meaningful to Reo itself (and not introduced only when implementing the protocol). For example, we may reason that some ports type must have a property to allow its value to be \textit{replicated}, as an interaction exists that replicates a value of its type. However, Reo does not prescribe what these types are called in the target language, nor does it prescribe any additional relationships between them. For example, two types distinguished by Reo may be unified in implementation. 

In the sequel, we consider translation work \textit{abstract} if is produces a representation valuable to any imperative language, and \textit{concrete} otherwise.


\subsubsection{Translation Subtasks Defined}

Ultimately, we partition the task of translating from RIR to Rust as four subtasks, where those that are \textit{abstract} precede those that are \textit{concrete}:

\begin{tabular}{l|p{5cm}p{5cm}}
	& Action & Data Type \\
	\hline
	Abstract & $T_{AA}$: From each abstract interaction, a sequence of imperative actions are laid out. & $T_{AT}$: Ports are mapped to data types characterized by properties. \\
	\hline
	Concrete & $T_{CA}$: Abstract actions are reified into concrete, executable Rust code. & $T_{CT}$: Abstract data types are resolved to satisfactory concrete Rust types.
\end{tabular}


\subsection{Pipelining Subtasks}
\label{sec:decoupling_reo_rust}

Code generation is an unusual problem, as it introduces a spectrum of possibilities in response to questions that usually have trivial answers. For example, in which language is a concept expressed? Reo specifies the coordination behavior of the generated Rust code, but (by design) nothing more. This freedom makes room for questions of `where' and `when' the behavior that emerges at runtime is made concrete. 

Toward an answer, we begin by considering one of the possible extremes: the Reo compiler performs as much of the work (i.e., as many of the subtasks) as possible. Whatever behavior is desired in the executable program is spelled out in detail, and reflected explicitly in the Rust code the Reo compiler produces. This solution is arguably the most intuitive, and it has many advantages. For example, we are able to `front-load' as much computation work as possible, such that the generated Rust code can represent operations in a preprocessed form. We are also given fine control over the behavior of the final binary. However, this strength is what makes this approach impractical: the Reo compiler's ability to specify Rust's behavior in detail also implies a responsibility to do so. By reasoning about the Rust-compiled program directly, Reo must model Rust's language and tooling environment. Recreating this existing work is a poor use of the available software resources. Worse still, it results in Reo compiler becoming tightly coupled to the Rust language, not only syntactically, but in the fine-grained logic necessary for implementing our desired performance optimizations in full detail. At the same time, all flexibility is taken away from the user; they have no ability to influence the translation process. Essentially, this approach trivializes the contributions of Rust compiler.

As one might expect, the opposite extreme trivializes the contributions of the Reo compiler. If hardly any transformations at all are applied before Rust code is emitted, the representation can only be very similar to that of RIR. As explained previously, these forms are simply too different for the Rust compiler to use as-is. By necessity, either a new Rusty-RIR to Rust translation tool would have to be introduced, or the translation would have to occur inside the Rust-generated program at runtime. Either way, the work of performing our abstract transformations is simply postponed to later stage in the pipeline.

Between these extremes there is a vast spectrum. Ultimately, we wish to choose a balance that partitions the work between the compilers of Reo and Rust in a manner that befits the interests of the language, minimizing the extent to which Reo models Rust or vice versa. Section~\ref{sec:sub_tasks} touched on the observation that a portion of the work in translating from RIR to Rust is common to other imperative language targets. Our solution is for the Reo compiler to perform only the `abstract' subtasks ($T_{AA}$, $T_{AT}$), translating RIR to a form for which imperative computation is natural, but is otherwise as agnostic to the target language as possible. Behavior is represented symbolically for the Rust compiler to make concrete. Clearly, this abstract representation must be understood by both Reo and Rust compilers, as it is the representation that crosses the boundary between their steps in the pipeline. Section~\ref{sec:imperative_form_sec} to follow defines this representation as imperative form, embodying the behavior of an abstract imperative language.

The Reo compiler has an existing backend for generating Java code. It works by generating Java according to the structure of a \textit{template generator}, which defines a hierarchy of string macros for formatting RIR objects in Java's syntax. At first glance, this backend exemplifies the extreme of Reo modeling the target language, performing all of the subtasks itself. However, the extent of the associated coupling to Java is mitigated through the reliance on a purpose-built Java library. Within, objects are defined for structures that all Reo-generated Java programs will have in common. For example, the library defines a \code{Component} interface, for which the code generator produces a protocol-specific implementor class. This approach works to minimize the surface of the generated code by having Reo generate behavior at a higher level of abstraction. Reo generates Java in Java-specific terms, but must generate less overall.

Our approach follows the precedent set by the Java backend; we introduce Reo-rs, a purpose-built Rust library which provides Reo with significant abstractions. We reduce the burden on the Reo compiler further by reducing the granularity of the protocol representation as it appears in the Rust source code; the Reo compiler emits a single \code{entrypoint} function, which acts as a thin wrapper around the initialization of a \code{ProtoDef}. This structure is defined in Reo-rs, and corresponds with IF, as it is defined in Section~\ref{sec:imperative_form_sec}. By expressing the protocol's behavior in this form, the Reo compiler takes responsibility only of the abstract transformation steps: $T_{AA}$ and $T_{AT}$. Rust itself completes the translation to its language specifics, partly at compile time and partly at run time. Figure~\ref{fig:pipeline} gives an overview of the entire process from start to finish, ultimately resulting in objects which coordinate the components of a program written in the Rust language.

\begin{figure}
	\centering
	\includegraphics[width=0.60\textwidth]{pipeline.png}
	\caption[TODO.]{The translation pipeline from the Reo compiler's internal representation (`RIR') to the executable Rust \code{Proto} object. Translation phases correspond to subtasks defined in Section~\ref{sec:sub_tasks}. The majority of the specification is represented in the imperative form (`IF'), which serves as the representation at the boundary between Reo and Rust. The boundary between compile and run time is relative to that of the user's Reo-coordinated program.}
	\label{fig:pipeline}
\end{figure}

\subsection{Enabling Future Expansion}
Previously, we observed that the translation work from Reo to its targets can be expected to have significant overlap. For our purposes, we characterize imperative languages by defining IF in Section~\ref{sec:imperative_form_sec}, and build our translation pipeline around its use as an intermediate representation.

Performing the translation in clear stages is beneficial to both Reo and its target languages, as it becomes possible to support new language targets with less effort. The benefits to new imperative targets is clear; they may acquire Reo support with less effort than otherwise. Existing target languages are able to benefit also, as they are able to implement the same IF using different concrete translation procedures, i.e., they may implement $T_{CA}$ and $T_{CT}$ in different ways. Differently-implemented protocol objects may be secure in they are founded on the same IF specification, necessitating that they agree on their abstract action sequences, and the abstract types of their ports.

For the sake of limiting the scope of the project, we relegate IF to a tool unique to the generation of the Rust language; as far as the user is concerned, the Rust backend emits Rust directly, which they are able to use as part of their Rust programs. 

\section{Imperative Form}
\label{sec:imperative_form_sec}
In this section, we define \textit{imperative form} (`IF'), a novel intermediate representation for the behavior of Reo protocols, such that they more closely correspond to their final representation in some imperative language. In the protocol translation pipeline, this form is the result of completing translation subtasks $T_{AA}$ and $T_{AT}$, as they are defined in Section~\ref{sec:sub_tasks}. We take for granted at this stage that ports and functions have been given abstract types by the Reo compiler.

\subsection{Concept}
RIR does not ergonomically facilitate execution, primarily because it does not define the \textit{order} in which values are accessed, created and moved. Programmers using imperative, sequential languages are very used to thinking in terms of procedures which manipulate the state of variables \textit{in scope} with the order implicit in their control flow. Often, interpreters or compilers provide safety properties by tracking over the execution and emitting errors whenever a variable access is invalid.

IF makes explicit the ordering between symbolic \textit{actions}; if executed in the specified order, it is guaranteed that (1) variable accesses are always valid, and (2) it is clear at which moment the rule has \textit{fired}.

\subsubsection{Rules as Transactions}

RIR partitions the work of a rule into its \textit{guard} and \textit{assignments}. This is already a step in the direction of imperative computation, observing that some work (the guard) must be performed \textit{prior} to deciding whether the rule \textit{fires}, in which case the assignment follows. As the protocol does not define the moments when it will evaluate the guard, it is an error to define a guard whose evaluation `leaks' meaningful behavior. 

We are able to interpret a RIR rule as a two-action \textit{transaction} which \textit{commits} after the first, guaranteeing the second will occur. Prior to the moment of commitment, actions are (1) obligated to have a defined means of being \textit{reversed}, undoing their observable effects on the environment, leaving no trace of their execution, and (2) able to initiate an \textit{abort}, reversing their effects. In this view, the guard's evaluation instigates an abort if it evaluates to $false$.

IF adopts the notion of ordered actions from RIR, but generalizes it to a sequence of any length of at least one. For our purposes, it suffices to have a fixed moment of commitment: immediately before the last action, referred to also as the \textit{assignment} to mirror the terminology of RIR. All other actions are transient, and behave as described above. One final stipulation is needed: after an action's effects are reversed, its predecessor is reversed also (if they exist). The effect of an abort propagates up through the transient actions in the opposite order they were originally performed, reversing all of their effects on the state one by one. However, once the last action is reached, the rule's firing has committed, and the effects of all actions will be observed.

\subsubsection{Action Granularity}
IF represents a protocol's defined interaction as actions to be computed in the specified sequence. At this stage, our representation is still symbolic; actions do not necessarily correspond 1-to-1 with concrete operations in the target imperative language, and their representation of actions is unspecified as long as they preserve the properties of IF. We represent actions at the coarsest granularity possible to avoid overspecifying the ordering of concurrent operations by leaving for meaningful implementation choices in subtask $T_{CA}$.

The simplest IF rules can be represented with a single action; implicitly, the rule has a trivial guard, and consists entirely of some guaranteed assignment. For example, a rule with a trivial data constraint may be represented as a single, trivial action; the rule always fires to no effect.

The utility of our generalization is the ability to break up a single action into multiple in a manner we are able to represent. For example, we are able to reason about transient actions that create temporary variables; reversal is achieved by discarding the variable. To illustrate this flexibility, we represent a protocol, expressed in RBF with data constraint $X=f(X)$ and synchronization constraint $\{X\}$ with only input (putter) port~$P$. This rule can be understood as ``$X$ fires \textit{if} the results of function~$f$ on its put value is equivalent to the value itself''. Here, the result of $f$ clearly cannot be inspected until \textit{after} it is computed. We are able to represent this rule with an action sequence of length three: (1) Create temporary value $f_X$ by executing $f$ given argument $X$. (2) Trigger an abort if $f_X\neq{}X$. (3) The rule has fired; do nothing other discarding values $X$ and $f_X$. 


\subsection{Definition}
\label{sec:imperative_form_definition}
Here we define \textit{imperative form}, and explain how its definition corresponds with the intuition behind it. Firstly, an IF contains a structure which corresponds to a \textit{symbol table}; this does the work of assigning symbolic \textit{data types} to ports and memory cells. Ports must also be annotated with an explicit \textit{orientation} (i.e.,\ input or output). Other symbols are also represented here, for example, the names and the argument types for any named functions.

More interesting are the \textit{imperative rules} listed for an IF. Each rule is given by a tuple $(P,I,M)$ where:
\begin{enumerate}
	\item \textbf{Premise $P$}\\
	The premise is another tuple of three \textit{identifier} sets $(P_R, P_F, P_E)$. $P_R$~is the \textit{synchronization constraint}, i.e.,\ the set of ports identifiers whose values must be `ready'. $P_F$ and $P_E$ are the sets of \textit{memory values} which must be known to be full and empty respectively, such that it is known whether they can be read or written from. The rule can certainly not consider firing unless all ports are ready and all memory cells are in the specified states.
	
	\item \textbf{Instructions $I$}\\
	A list of reversible \textit{instructions} which are performed in sequence. These instructions have no immediately observable effects, such that they can be reverted in the event of an \textit{abort}. Concretely, each instruction is one of:
	\begin{itemize}
		\item $check(p)$\\
		Trigger an \textit{abort} if predicate $p$ over data is satisfied.
		\item $fill_P(m, p)$\\Fill an empty memory variable $m$ with the result of a predicate $p$ over available data. The value's data type is implicitly \textit{boolean}.
		\item $fill_F(m, f, a)$\\
		Fill an empty memory variable $m$ with the result of invoking function $f$ with parameters $a$, a list of references to data variables with length matching the arity of $f$. It is incorrect for $f$ to \textit{mutate} its arguments, as this would result in observable effects which cannot be rolled back.
		\item $swap(m_0,m_1)$\\
		Swap the values in two memory variables~$m_0$ and~$m_1$.
	\end{itemize}
	If an abort is triggered by $check$, any swapped memory cells are swapped back, and any memory cells whose values were created by $fill_P$ or $fill_F$ are destroyed.
	
	\item \textbf{Movements $M$}\\
	A mapping from identifiers of \textit{values} to the identifiers of getter ports and empty memory cells. This represents the final action of an imperative rule executed if and only if the rule \textit{fires}.
\end{enumerate}

An imperative rule aims to model a sequential computation from top to bottom. Instructions are able to (non-destructively) read values, create new variables, and swap the values of identifiers. Starting from the premise, one is able to populate a set of values' identifiers \textit{in scope}, and then traverse the instructions and rules. For this reason, it is beneficial to distinguish $P$ from an instruction: it establishes the initial scope.

The IF is well-formed only if no instruction no the movement breaks any of the rules. Here, it suffices to say that these rules model the usual scoping rules in an imperative language. For example, one cannot read from an uninitialized value. Other rules are in place to ensure that instructions are always reversible. For example, $fill_F$ may only be used if the value it populates is previously uninitialized. Section~\ref{sec:translation_phase_2} explains how this IF is checked by Rust, including a listing with some example errors. The full enumeration of constraints is available in the source code.

$M$ is defined with a representation that makes it trivial to distinguish the cases where values are discarded (0 destinations), moved linearly (1 destination) or replicated (multiple destinations). This design is convenient for languages that require their values to be more explicitly managed. For example, languages with \textit{affine types} (e.g.,\ Rust) must simulate the replication of values by creating new affine resources from the original, and managing the replicas explicitly.  \textit{Relevant} data types (which must be used \textit{at least once}~\cite{walker2005substructural}) must handle empty destination sets by either emitting errors, or simulating destruction.\footnote{A relevant language may simulate the destruction of a value by moving it to some \code{Destroyed} destination with special semantics.} There are many other reasons a language may want to specialize the way its values are used. For example, an implementation in C++ may need to inject \code{free} calls to avoid leaking memory in cases where pointer-values are discarded.

As an example to demonstrate intermediate representation, the RBA rule in the previous section with data constraint $X=f(X)$
and synchronization constraint $\{X\}$ can be represented in the imperative rule with:

\vspace{1em}
\noindent{}
\begin{tabular}{r|l}
	\centering
	&  value \\ \hline
	premise	&  $(\{X\}, \enskip\{\}, \enskip\{f_X\})$ \\
	instructions	& $[fill_F(f_X, f, [X]), \enskip{} check(X = f_X)]$ \\
	movements	& $\{X \rightarrow{}\emptyset{}, \enskip f_X \rightarrow{}\emptyset{}\}$ 
\end{tabular}
\vspace{1em}

\section{Translation Pipeline}
\label{sec:translation_pipeline}
This section details the implementation of the translation pipeline from RIR of Reo protocols to executable Rust. The section is structured to describe the translation process as a sequence of sequential stages. Unbeknownst to the user, the pipeline extends well after the Reo compiler has emitted Rust code. Subsections are titled according to \textit{when} the translation takes place.

\subsection{At Reo Compile-time}
\label{sec:translation_phase_1}
The Reo compiler is extended with a backend for translating RIR to a Rust source file. This translation stage is concerned with performing $T_{AA}$ and $T_{AT}$, and representing them as a single rust \textit{entrypoint} function in the emitted Rust source. The user is able to import this source as a dependency into their own project, whereby the \textit{entrypoint} serves as a means for their program to construct the Rust object which implements the appropriate Reo protocol specification, as described in Section~\ref{sec:reo_motivation}.

\subsubsection{Action Sequencing}
$T_{AA}$ necessitates transforming a each of the protocol's rules into a sequence of symbolic actions. The most significant work occurs as a result of how differently \textit{values} are represented. RIR is declarative, representing the result of a rule's firing as an \textit{assignment}, mapping \textit{destinations} (getter ports and empty memory cells) to \textit{terms}. RIR already represents a significant transformation from RBF in isolating these values on a per-destination basis. 

To begin, we describe the na\"ive approach to translate RIR to IF a rule at a time. The translation procedure initializes all three fields $\{P, I, M\}$ of an imperative rule as initially empty, and populates them incrementally by recursively traversing the RIR rule's assignments. Each such assignment is ultimately represented in~$M$, where \textit{terms} are rather represented by identifiers. For some terms the mapping to identifier is trivial. For example, the value put by a port can use the identifier of the port itself. For others, it may be necessary to introduce \textit{fresh} identifiers, representing \textit{temporary variables} to be created. In either case, the \textit{term} is traversed recursively to (1) collect these identifiers, and to (2) populate the premise~$P$ such that the rule is fired given access to all of the relevant memory cells and ports.

$I$ is populated last by three kinds of actions. Firstly, the exceptional cases for which memory variable~$q$ will be both read and written to are treated. If necessary, a fresh temporary variable is introduced by appending an instruction $swap(q, q_{temp})$ where $q_{temp}$ is some fresh variable; $q$'s previous and next values may be read and written unambiguously, distinguished by identifiers $q_{temp}$ and $q$ respectively. Second, $I$ is appended with $fill_P$ or $fill_F$ instructions to create every other temporary variable in a manner befitting the \textit{term} that represented them in the RIR's assignments, i.e.,\ the result of invoking a function with port values as arguments. Finally, $I$~ends with a single $check$ to evaluate the rule's guard, initiating an abort if it is evaluates to \textit{false}.

As it was described thus far, our procedure is able to correctly render any RIR rule in IF with the necessary properties. For the sake of minimization or performance at runtime, at least three optimization opportunities may elaborate on this procedure, producing semantically-equivalent results.

\begin{enumerate}
	\item Terms that occur repeatedly within assignments throughout the same RIR rule may have their \textbf{values deduplicated} by assigning them all the same \textit{identifier}. Care must be taken to ensure that the instruction to create its value is inserted only once, sufficiently early that its creation precedes its \textit{earliest} access. Note that each original occurrence still corresponds with a \textit{destination} in the resultant~$M$ mapping. To clarify, consider the example with getter ports~$A$ and~$B$ both assigned terms corresponding to $f(C)$ where $f$ is some function and $C$ is a putter port. Here, one temporary variable $f_C$ to store the result of $f(C)$ is sufficient; it is simply moved to two distinct destinations, reflected in the mapping $f_C\rightarrow\{A,B\}$ in~$M$.
	
	\item The large, monolithic \textit{check} instruction that acts as a guard to the rules firing can be fragmented into \textbf{numerous guard instructions}. The utility of this is the ability to specify how its parts are ordered. For best results, it is beneficial to move checks as early as possible, such that less work is performed prior to an abort whenever the check \textit{fails} at runtime. To be correct, care must be taken not to move guards so early such they precede the creation of any temporary variables their evaluation accesses. For example, consider an RIR 
	whose guard is $A\wedge{}B$, where~$A$ and~$B$ are subformulas that reason about subterms whose evaluation necessitates the creation of temporary values~$t_A$ and~$t_B$. By fragmenting $check(A\wedge{}B)$ into $check(A)$ and $check(B)$, we are able to move the former such that it follows the creation of $A$, but not of $B$. Effectively, the rule is able to \textit{short circuit} its evaluation at runtime, circumstantially avoiding the creation and destruction of the temporary value identified by~$t_B$. 
	
	\item \textbf{Static analysis} of values may conclude that a \textit{check} instruction is a tautology, making it safe to omit. Similarly, the presence of even one contradictory \textit{check} makes it possible to discard the rule entirely (as it will never fire). This optimization is particularly useful in combination with optimization (2).
\end{enumerate}

\subsubsection{Type Classification and Constraining}
Our backend performs task $T_{AT}$ to generate the IF such that the identifier of every port, memory cell, and temporary variable is assigned a symbolic type annotation, such that:
\begin{enumerate}
	\item the types of identifiers match if they exchange values or are checked for equivalence.
	\item data types are boolean if they occur in a context in which only boolean types are permitted, i.e.,\ as the predicate of a formula.
	\item the type is constrained by \textit{properties} which guarantee the type defines operations which Reo may apply to its values. 
\end{enumerate}

Ultimately, ports and functions are mapped to a set of symbolic types, each of which is annotated with properties. These properties cover the most fundamental ways Reo interacts with values of a data type, aside from moving them through ports (which we assume to be inherent to all port types). Precisely they are:
\begin{enumerate}
	\item Values may be replicated.
	\item Values may be compared for equality, returning a boolean value.
	\item A value may be initialized from a given string, i.e, parsed.
\end{enumerate}

Our backend performs this work in tandem with the work of $T_{AT}$ described in the previous section. Initially, every identifier is assigned a fresh symbolic type with no properties, representing a data type unrelated to any other, and having no need of any defined operations. In traversing the RIR rules, properties are collected and associated to the relevant types. Incrementally, \textit{type constraints} are collected, accumulating requirements for the properties of types. In some cases, a relationship between identifiers causes their types to be \textit{unified}. For example, a data movement from putter~$P$ to getter~$G$ unifies their types, resulting a new type with the union of their properties. If the requirements on types are \textit{contradictory}, an error is emitted by the Reo compiler. For example, it is an error to provide types $A$ and $B$ with different explicit data type annotations, yet have them exchange data.

Ultimately, the constructed IF associates a symbolic type with every mapping in its symbol table.

\subsubsection{Rust Formatting}
Once all the data has been prepared, the Reo compiler emits its contents formatted according to Rust's syntax. Listing~\ref{listing:generated} gives an example of the result: a single \code{instantiate} function reflecting the cumulation of the work of this phase. This function serves as the user's entrypoint for creating protocol instances with the corresponding behavior.
Observe that in this example, a single symbolic data type \code{T} was identified, and annotated with property \code{FromStr} (which ensures the type can be parsed from a string). As expected, the majority of the information is contained in the \code{ProtoDef} type (beginning on line~5), which is nothing more than a Rust-formatted rendering of the protocol's imperative form behavior specification. The sections to follow explain what happens next.

\begin{listing}[ht]
	\centering
	\inputminted[]{rust}{generated.rs}
	\caption[TODO.]{The Reo-generated Rust source given the $fifo1$ connector's Reo specification as input. Section~\ref{sec:translation_pipeline} explains how this representation bridges the gap between the Reo and Rust languages. The \code{ProtoDef} type on line~5 specifies the protocol's behavior in imperative form, as it appears embedded into Rust's syntax.}
	\label{listing:generated}
\end{listing}

\subsection{At Rust Compile-time}
A Rust programmer makes use of the generated Rust code by importing it into their own program as a library. To interface with its contents, they are required to import Reo-rs as well. Section~\ref{sec:user_facing} explains the API this library presents to users for acting on these protocol objects from their own code. 

As the name suggests, the \code{instantiate} function serves as the user's \textit{entrypoint} for instantiating protocol objects. This function is invoked from their own Rust code in the usual way. Previously, Section~\ref{sec:translation_phase_1} explained that the output of the Reo compiler is a Rust source file containing a single entrypoint function. Rather than implementing it ourselves, our solution is for the definition of this function to effectively delegate subtask $T_{CT}$ to the Rust compiler itself. From the user's perspective, the entrypoint is a function like any other; at the call-site within their own programs, they are able to specify concrete choices for the generic types themselves (Section~\ref{sec:rust_language} explains how Rust dispatches generic functions).
This approach has three benefits: (1) We make use of an existing resource, which is not only easier, but is also good practice as it avoids the fragility that would otherwise follow from redundancy, (2) the result is idiomatic for the Rust language, and ergonomic for users to use in conjunction with other generics in their own programs, and (3) once Reo has emitted the entrypoint, a Rust programmer is able to use it to construct protocol instances for any choice of concrete types.

Using the Rust compiler in this way is achieved by the Reo compiler crafting the entrypoint such that its generic type arguments are annotated with the appropriate Rust trait bounds. In effect, we communicate to the Rust compiler the operations which the user's code chosen types must support. This makes for a pleasant user experience, as invocations of \code{instantiate} will be checked for correctness by the Rust compiler as the case for all other functions.

%\subsubsection{Delegated to the Rust Compiler}
%Section~\ref{sec:temporary_simplifications} explains that our current implementation of the Rust backend for the Reo compiler makes the temporary simplification of emitting Rust source code directly. This approach adheres with the Reo compiler's idiom of code generation per target language, but also it simplifies our work overall as we are able to effectively \textit{delegate} some of the translation work to the Rust compiler itself. Both of these simplifications are inspired by Reo's Java code generator, whose direct-to-Java code generator delegates these tasks to the Java compiler in the same manner:
%\begin{enumerate}
%	\item \textbf{Parsing}\\
%	Per our design, IF should be emitted in a format agnostic to the imperative language target; good contenders are common data serialization formats such as JSON or YAML. Ultimately, IF is translated to the syntax understood by the target language such that it can be integrated into the user's programs. While Rust is the only language target, we are able to unify these steps by emitting Rust syntax as a usable dependency directly.
%	
%	\item \textbf{Type Resolution}\\
%	Our symbolic data types are exposed as \textit{generic types} in the emitted source; effectively, the user's Rust compiler makes concrete these symbolic types at the call site, as is idiomatic in the Rust language.
%\end{enumerate}
%
%The second task is most interesting, as care must be taken to represent our generic types in a manner that the Rust compiler will accept. Previously, we described how requirements on our symbolic types are discovered throughout $T_{type}$. Here, these constraints are communicated to the Rust compiler in the generated syntax. This delegates the task of enforcing these constraints to the user's Rust compiler. Listing~\ref{listing:generic_resolve} gives an example of a signature for a Reo-generated Rust function with constrained generic types~\code{X} and~\code{Y}. Observe that the majority of the functions contents are the definition of a~\code{ProtoDef} type, which is the Rust-embedding of our IF. 
%
%\begin{listing}[ht]
%	\centering
%	\inputminted[]{rust}{generic_resolve.rs}
%	\caption[Simple Reo compiler Rust output.]{Example of a Reo-generated Rust output for a simple connector which replicates values of port $P$ to ports $\{C0, C1\}$. The user is able to construct \code{ProtoHandle}, a handle to an executable protocol object by invoking function~\code{build\_protocol\_1}. The caller determines the concrete choice of the generic type~\code{T}, but the Rust compiler will enforce that this choice is constrained such that it implements~\code{Clone} (the type's values can be replicated). The contents of the function consist predominantly of the construction of an instance of \code{ProtoDef}. In combination with \code{MemInitial}, these types represent the Rust-embedding of the protocol's imperative form specification.}
%	\label{listing:generic_resolve}
%\end{listing}

\subsection{At Application Runtime}
\label{sec:translation_phase_2}

The user's program has been compiled by the Rust compiler, the resulting binary can be directly executed. Whenever \code{instantiate} is executed, an instance of \code{Proto} is constructed and returned, indirected behind a \code{ProtoHandle}. These types and how they work to implement their associated Reo protocol at runtime is explained in Section~\ref{sec:protocol_objects}. Here, it suffices to say that all Reo-generated \code{instantiate} functions return the same \code{Proto} type, but the behavior and interfaces of these instances vary to reflect that of their specification. The final subtask of protocol translation, $T_{CA}$, occurs during \code{instantiate}. Owing to Rust's imperative nature, what happens next occurs a sequence of four distinct steps, corresponding with the initialization of the four variables in the scope of \code{instantiate}, as they appear in the Listing~\ref{listing:generated}. Throughout this section we refer this listing to exemplify the translation steps.

\subsubsection{Type Erasure: \code{type\_info}}
To make it possible to represent any and all protocol objects with the single \code{Proto} type, it is necessary to \textit{erase} the types of port values and functions, representing their types as data instead. \textit{Reflection} is the counterpart to this operation, allowing the port types of \code{Proto} objects to be distinguished at runtime; this occurs elsewhere, and is explained in Section~\ref{sec:type_reflection} in the following Chapter. As can be seen in the example, this first step is trivially represented by the Reo compiler, relying on the definition of \code{TypeInfo} in Reo-rs.

\subsubsection{Memory Initialization: \code{mem\_init}}



In the original textual Reo specification, the initial values of a protocol's memory cells is defined by strings (as a result of the textual syntax). To afford the user's choice of arbitrary types, we require that the original text can be translated into a value of the correct type to initialize the protocol's memory cells. Rust defines the \code{FromStr} trait characterize types which have the property that their instances can be constructed by parsing a string at runtime. The entrypoint function is safely able to rely on the corresponding \code{from\_str} operation to be defined for the type, as care was taken to include it as a type constraint. These constraints are based on Rust's trait system (see Section~\ref{sec:rust_language}), and correspond with the symbolic type properties explained in Section~\ref{sec:translation_phase_1}.

The result is a \code{MemInitial} instance, storing instances of initialized values precisely as specified.

\subsubsection{Imperative Specification: \code{proto\_def}}
As explained previously, the Reo backend embeds the imperative form specification in Rust's syntax such that the result is a dependency which the Rust compiler can understand. At runtime, this step necessitates that a \code{ProtoDef} instance be built, only to be read on the next line and subsequently discarded. Conceptually, this step could be performed at compiler-time by defining the \code{ProtoDef} in terms of types that the Rust compiler is able to embed into the text section of the generated binary. This would avoid the work of constructing the \code{ProtoDef} with every instance, as (to follow) we see that one \code{ProtoDef} is able to instantiate any number of \code{Proto} instances. Instead, this object defined such that it requires some simple initialization at runtime. The overhead is inconsequential, particularly as \code{instantiate} is not a performance-sensitive function. However, the benefits of this dynamic definition are the ability to manipulate these definitions at runtime. 

\subsubsection{Construction: \code{built\_proto}}
The combination of \code{ProtoDef} and \code{MemInitial} represent (a specification of) the behavior, and initial state of an executable protocol object respectively. The final step is to put it all together and perform the only remaining subtask:~$T_{CA}$. Reo-rs encapsulates this work in the \code{build} method defined for the \code{ProtoDef} type, visible in Listing~\ref{listing:generated} on line~32. 

Completing subtask $T_{CA}$ in this context consists of (1) initializing a protocol object complete with auxiliary bookkeeping structures, and (2) translating the imperative form behavioral specification into something conducive to execution. \code{Proto} structures are instantiated complete with various fields to facilitate the granular operations that are defined by Reo-rs. Structures are added which have no clear parallel in the imperative form specification, but whose presence is nevertheless essential at runtime: for example, semaphores and control message channels. Imperative form rules are significantly preprocessed before being included in \code{Proto}. This performs two vital functions:

\begin{enumerate}
	\item \textbf{Optimizes Representation for Execution}\\
	\code{Proto} represents the ultimate departure from the initial Reo specification. in Chapter~\ref{sec:protocol_runtime} to follow, we explain how the contents of \code{Proto} are accessed directly while in use as a communication medium at runtime. Due to their different purposes, these types have different representations, each specialized to its own purpose. Where \code{ProtoDef} prioritizes terseness and readability in the use of symbolic port and function names, the translation to \code{Proto} resolves them to concrete data structures for cheaper access, e.g., indexes into a vector replace symbolic port names.
	
	\item \textbf{Ensures Internal Consistency}\\
	In this scope of this project, we are safe in our presumption that the Reo compiler can be trusted to create only internally consistent \code{ProtoDef} structures. However, the code generation process crosses a boundary between two compilers, and is designed to minimize their coupling by condensing the data that passes between them. As is good software development practice, Reo-rs works to minimize its dependency on the Reo compiler. In particular, Reo-rs avoids assuming that the Reo-generated \code{ProtoDef} describes \textit{some} valid, sensible protocol. This precaution is motivated because IF simply exposes more opportunities for inconsistencies than RIR (owing to its increased expressiveness), which may cause modifications to the Reo compiler to introduce bugs.\footnote{A user may tamper with their Reo-generated Rust code such that a different, consistent protocol results. We cannot distinguish this from intended behavior, and so users take responsibility for their own misfortune in tampering with generated code.}
	
	To make error handling ergonomic, and to adhere to Rust's idiom for error handling, \code{build} returns an informative error structure with information about the inconsistency. Listing~\ref{listing:build}	shows the resulting type signature of \code{build}, including some examples of possible error variants.
\end{enumerate}


\begin{listing}[ht]
	\centering
	\inputminted[]{rust}{build.rs}
	\caption[TODO.]{Signature of the~\code{build} function. Its inputs are (1) an immutable reference to a \code{ProtoDef}, which is used to determine the protocol's behavior, and (2) a \code{MemInitial}, which stores initialized memory cells to be incorporated into the protocol's state. The return result is an enumeration type, returning \code{ProtoHandle} upon success, and a tuple on failure, whose elements are, respectively (1) the index of the imperative rule where the error occurred if applicable, and (2) another sum type, communicating the nature of the error with additional information. }
	\label{listing:build}
\end{listing}

Listing~\ref{listing:generated} demonstrates how the result of \code{build} is returns the resulting protocol object. Observe that it is returned indirectly, represented by a \code{ProtoHandle}. The relationship between these objects and the definition of their behavior at runtime is detailed in Chapter~\ref{sec:protocol_runtime} to follow.
%
%
%Subtask $T\_{CA}$ represents the translation of the protocol's abstract (but imperative) behavior to a form executable in Rust. To minimize the work of the Reo compiler itself, and to avoid duplication in the user's programs, this work is extracted to Reo's supporting Rust library, Reo-rs. Within, the \code{build} function instantiates a new \code{Proto} object. This function is parameterized with a \code{MemInitial} (which is consumes), and a \code{ProtoDef} (which it reads). The majority of the entrypoint function's body concerns itself with the construction of the \code{ProtoDef}, which is nothing more than the Reo-generated imperative form embedded in Rust's syntax. 
%
%During \code{build}, Reo-rs works to preprocess its inputs
%
%\subsubsection{Internal Consistency Check}
%
%Our work follows the precedent set by the Java code generator in relying on a library in the target language to define the lion's share of the behavior for our runtime protocol objects. For Rust, these definitions are bundled into the \textbf{Reo-rs} library, which is added as a dependency to the code generated by the Reo compiler's backend. Chapter~\ref{sec:protocol_runtime} explores the architecture and behavior of our executable protocol objects in detail. For now, it suffices to say that our approach is to represent executable protocols as extensively preprocessed \textit{data structures} which then drive the behavior of a lightweight \textit{interpreter} at runtime. This data representation is often called \textit{commandification}~\cite{nystrom2014game}. 
%
%
%\subsubsection{Protocol Initialization}
%Listing~\ref{listing:generic_resolve} gives an example of Reo-generated Rust source. Previously, we explain how this representation delegates some of the work of $T_{run}$ to the Rust compiler itself. The remainder of $T_{run}$ is defined in the \code{build} procedure (visible is the listing on line~23) such that this work is performed at runtime whenever a protocol is \textit{instantiated}. As can be seen in the \textit{return value} of the function in the listing, the end result is the construction of \code{ProtoHandle}, a handle to an \textit{executable} protocol object, whose properties are explored in Chapter~\ref{sec:protocol_runtime}.
%
%At this level, the specification used to \code{build} the \code{Proto} is split into two distinct types: \code{ProtoDef} and \code{MemInitial}. The former describes its \textit{behavior}, corresponding most closely with the conceptual design of IF. The latter isolates a simple structure which contains preallocated values for the finished \textit{protocol object}; in effect, it provides the initial values of memory cells. These structures are distinguished for only one reason: \code{ProtoDef} contains no \textit{values}, such that it can be accessed by \code{build} in a read-only fashion. Although it is not taken advantage of by the Reo-generated program, one is able to define a protocol's behavior \textit{once} to be used for the construction of any number of \code{Proto} instances.
%
%\code{Proto} represents the ultimate departure from its original, declarative protocol specification whose purpose is to facilitate execution. Its creation from \code{(ProtoDef, MemInitial)} involves the last remaining subtasks of $T_{run}$:
%\begin{enumerate}
%	\item \code{Proto} is constructed along with data structures necessary for basic operations at runtime. This includes semaphores, channels for \textit{control messages} and so on. This minutia is detailed in Section~\ref{sec:protocol_object_architecture}.
%	
%	\item In construction, the behavioral specification (i.e.,\ imperative form rules) are \textit{preprocessing}  to a form more conducive to efficient execution. For example, symbolic names are replaced with indices, pointers and keys into concrete data structures. The \textit{soundness checks} in the section to follow can be considered preprocessing also, as they ensure a \code{Proto} is constructed such that it is internally consistent, ensuring various runtime properties are invariant and need not be checked at runtime.
%\end{enumerate}
%
%
%\subsubsection{Soundness Check}
%Our backend is novel in that the work of constructing the executable protocol object requires crossing an API boundary. Rather than trusting the well-formedness of the Reo-generated \code{ProtoDef}, Reo-rs will check that its input is internally consistent. By adding these checks, the dependency between the Reo compiler and Reo-rs is \textit{unidirectional}; users are free to safely construct protocol objects using Reo-rs in their applications directly. The most obvious advantage to this approach is an additional layer of safety, allowing for the compiler and Reo-rs to be maintained separately, e.g.,\ if the compiler acquires a bug from a new update, the error cannot propagate into Reo-rs unnoticed. Another advantage is the avenues for future work this opens up. Our approach treats protocol structures as data, facilitating their mutation at runtime, resulting in \textit{dynamic protocol reconfiguration}, although exploring this further is beyond the scope of this work.
%
%In native Rust, the usual variable scoping rules apply to ensure that a symbolic identifier is resolved to a meaningful memory position. These systems are so familiar to us that we usually take the complexity of their work for granted. Rules that are second nature to us require explicit enforcement to replicate the work of the checker. As \code{ProtoDef} \textit{commandifies} the behavior to be later executed, the Rust compiler does not interpret these actions in the normal way, and we must mimic its behavior manually. We take this idea a step further by relying on the \code{ProtoDef}'s \textit{premise} to facilitate a mechanism that mimics the Rust \textit{borrow checker} system; rules trace which variables are \textit{valid} (i.e.,\ initialized) throughout the rule's execution top to bottom, tracking changes as a result of actions filling or swapping their values. In this manner, we are able to catch invalid memory accesses during \code{build}, rather than encountering them at runtime. An additional perk of mimicking this system is our ability to detect the occurrence of values which \textit{must} be consumed during the rule's firing, but whose consumption is not included in the specification. For example, an \textit{imperative rule} may include some putter port $P$ in its ready set (and thus, its synchronization constraint), but associate no \textit{movement} with $P$'s value. A na\"ive implementation which overlooks such occurrences may introduce \textit{memory leaks} for such cases if it takes the specification at face value. Instead, our custom borrow checker will reach the end of of the specified actions and conclude that as $P$ was not explicitly emptied, it will insert a trivial movement $P\mapsto{} \{\}$ to ensure the value is consumed. This is analogous to how Rust's borrow checker inserts \code{drop} calls to destroy local variables which go out of scope unconsumed. By performing this extensive checking, Reo-rs affords an expressive \code{build} function, capable of giving detailed error information in response to an invalid input. The signature of this function is given in Listing~\ref{listing:build}.
%
%
%\begin{listing}[ht]
%	\centering
%	\inputminted[]{rust}{build.rs}
%	\caption[TODO.]{Signature of the~\code{build} function. Its inputs are (1) an immutable reference to a \code{ProtoDef}, which is used to determine the protocol's behavior, and (2) a \code{MemInitial}, which stores initialized memory cells to be incorporated into the protocol's state. The return result is an enumeration type, returning \code{ProtoHandle} upon success, and a tuple on failure, whose elements are, respectively (1) the index of the imperative rule where the error occurred if applicable, and (2) another sum type, communicating the nature of the error with additional information. }
%	\label{listing:build}
%\end{listing}
%
%By restricting our API such that all executable protocol objects are \textit{only} created by \code{build}, our runtime interpreter is able to rely on the properties we guarantee and avoid checking them itself. In this way, checking for soundness is also an optimization.

