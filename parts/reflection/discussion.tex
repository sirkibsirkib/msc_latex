\chapter{Discussion}
In this chapter, we reflect on the work and findings in Chapters~\ref{sec:imperative_form}--\ref{sec:benchmarking}. This includes a subjective assessment of the results of the project as a whole, and identification of promising directions for future work.

\label{sec:discussion}
\section{Future Work}
As with any project, there was insufficient time to investigate every topic we encountered. In this section, we highlight promising starting-points for future work related to Reo in general, or to our contributions in Chapters~\ref{sec:imperative_form}--\ref{sec:api}.

\subsection{Imperative Form Compiler}
Chapters~\ref{sec:imperative_form} and~\ref{sec:protocol_runtime} explain how the Reo-rs runtime makes use of a lightweight interpreter to bring life to our protocol objects at runtime according to the appropriate specification. This commandification pattern has its advantages; namely, protocol behavior is alterable at runtime by manipulating the interpreted data. However, this flexibility does not come for free. The interpretation steps incur overhead both to the protocol construction procedure, and more importantly, to the work of port operations. Fortunately, our imperative form does not necessitate the use of an interpreter. Future work could investigate replacing the \code{build} procedure of Reo-rs with another compilation step such that the behavior is represented in native, directly-executable Rust. 

Futhermore, future work might investigate the use of custom domain specific languages for compiling imperative form in a manner that it performs the same checking as in \code{build} statically. the obvious means of doing this is to build a compiler from scratch. However, other options exist that can make better use of existing tools. For example, Rust's \textit{procedural macros} allow the programmer to define arbitrary transformations of Rust's abstract syntax trees during compilation. Essentially, one is able to invoke arbitrary, pre-compiled Rust code inside the user's Rust compiler itself. In this manner, one can embed the needed domain-specific language into the Rust compiler itself.

\subsection{Distributed Components}
This work focuses on coordination between threads in shared memory. This approach can already be applied in the context of distributed components by abstracting ports behind local ones. However, we are unable to distribute our protocol components, as they presuppose a single, monolithic shared state in our current scheme. One can get around this by fragmenting protocols into smaller ones, and distributing those smaller protocols across the system. However, this cannot currently be done in all cases, as this fragmentation does not preserve synchrony. 

Reo has a rich academic history in this distributed context. Future work might investigate how our contributions (eg.\ reference-passing optimizations, static governors, etc.) can be applied in distributed systems.


\subsection{Optimize Rule Branching}
\label{sec:future_branches}
Reo-rs is able to represent protocols whose rules contain branching (ie.\ logical disjunction). Rule-based form has already shown us the correspondence between our RBA rules and propositional logic, where the formula corresponds to a protocol, with disjuncts as rules~\cite{dokter2018rule}. In the same way such terms can be manipulated until the formula is in disjunctive normal form, so too are we able to remove branching from our rules by splitting them. For example, a rule with data constraint $(P_0=C_0\vee{}P_1=C_1)\wedge{}P_2=C_2$ can be converted into two rules with data constraints $P_0=C_0\wedge{}P_2=C_2$ and $P_0=C_0\wedge{}P_2=C_2$ respectively. Such transformations are not particularly meaningful to the outside observer; clearly they have  no influence on the protocol's semantics\footnote{Changing the granularity of rules can be semantically meaningful once it affects our ability to express interesting properties. For example, fine-grained rules can be desirable when the protocol is lifted to consider \textit{preference} between nondeterministic branching.}. However, they do have interesting implications on performance. It is easy to contrive of examples for both extreme ends of the spectrum for which this splitting is either beneficial or detrimental to the performance of the protocol object, as we are able to both introduce and eliminate redundant work by splitting rules. As an example of a rule not worth splitting, consider one with very many instructions~$I$ before reaching a 3-way branch $a\vee{}b\vee{}c$ where the branch is not entirely nondeterministic (ie. there are cases for which $a$ cannot be chosen, etc.). Before splitting, $I$ is computed once, and then one of $\{a,b,c\}$ will occur. After splitting, three separate rules for $a$, $b$, and $c$ might be considered, each computing $I$ before the third fires successfully.

In our case, only the Reo compiler's internals perform manipulations on protocol rules, while Reo-rs restricts itself to the treatment of tautologies and contradictions. Future work might investigate more extensive manipulation of protocol rules to optimize rules by conditionally splitting them to remove branching.

\subsection{Runtime Governors}
Chapter~\ref{sec:api} explains how our design for static protocol governors is able to enforce protocol adherence at compile time. This approach is not always suitable, as it presupposes that we trust the compilation process enforcing the governance. If the situation calls for a degree of separation between the compilation process and its use at runtime, this may no longer be a good choice. For example, consider the use of Reo to coordinate peers in a distributed system, where the behavior of a component originates from a remote source, traveling over the network.

Our static governors also have limitations on how finely they can distinguish the states of the protocol. In a perfect world, governors would use perfect models of the protocol's state. Section~\ref{sec:approximating_rba} gives an example of some practical reasons to approximate the protocol instead, resulting in a governor that attempts to strike a non-trivial balance between accuracy and simplicity of its local automaton. Dynamic governors are given a far easier task, as they are able to make choices at runtime, when all the relevant information is available. Generally, these governors can therefore be more accurate. Future work might investigate how these two extremes of the spectrum compare, and to what extent it may be practical to use some facets of \textbf{both} to make an application more robust. There may be systems in which redundant checking is worth its cost to runtime performance.

\subsection{Further Runtime Optimization}
Section~\ref{sec:behavior_implementation} discusses various optimizations of Reo-rs's runtime performance applied in this work, chief of which is arguably the use of reference-passing inside the protocol's state as part of the implementation of rules such that it preserves Reo's value-passing semantics. Other optimization opportunities presented themselves during the project, but were not investigated thoroughly as they conflicted with our current goals, or were simply deemed less fruitful than other tasks. Future work might investigate these optimizations:

\begin{enumerate}
	\item Simplify rules in the context of a known priority ordering to break nondeterminism. For example, consider rule $r_a$ with priority over rule $r_b$. Clearly, $r_a$ must always be given a chance to fire first, allowing $r_b$ to presumes the egation of $r_a$'s guard. In practice, this can often allow rules to be meaningfully simplified, particularly when they are created by splitting nondeterministic branches as discussed in Section~\ref{sec:future_branches}. For example, consider rules with the data constraints $M_0=M_1$ and $M_0\neq{}M_1$. If they are prioritized in the order of their appearance here, the guard of the second rule becomes trivially $true$.
	
	\item Remove indirection inside Reo-rs when representing values smaller than the pointer-size, by `stuffing' the value inside the pointer field. This optimization has complex interactions with the memory storage system described in Section~\ref{sec:memory_cells}, which uses pointers as keys to look up a value's reference count. Future work may investigate either (1) conditionally using stuffed pointers when it would not interact with the memory storage system, or (2) finding a way to make the memory storage system disambiguate these stuffed pointers
	
	
	\item More extensively pre-process the imperative form as its executable object is built (explained in Section~\ref{sec:translation_phase_2}). For example, instructions can be fragmented and re-organized such that the effects of a fired rule are unaltered, but rules are able to detect and recover from unsatisfied guards by rolling back earlier. In this way, one can minimize the cost of evaluating rules with unsatisfied guards.
	
	\item Reduce the number of atomic operations used for the exchange of meta-information during data exchange (Section~\ref{sec:data_exchange}). Assuming realistic numbers of ports we are able to collapse several atomic operations into one, aggregating distinct operations by using modulo arithmetic. For example, we are able to increment two (logical) numbers using a single atomic counter by adding $1 + 2^{32}$. In this fashion, the \textit{move} and \textit{countdown} variables may be unified to reduce lock contention and further increase performance and parallelism.
	
	\item Some of the information currently exchanged between threads using atomics can be independently derived by reading the protocol's rules. For example, getters can deduce their putter and whether they are permitted to move the datum this way, rather than being told by the coordinator explicitly. It is unclear whether this is an improvement, as these threads must spend extra time recovering this information, performing work redundant to that of the coordinator. 
\end{enumerate}
\subsection{Avoid Lock Re-Entry}
Section~\ref{sec:chosen_design} motivates the lack of a dedicated coordinator thread to back protocol objects at runtime. As a consequence, port-threads must share the responsibility of manipulating a shared protocol state in accordance with the protocol's movement through its configuration space. Protocols have non-trivial configuration spaces once they involve one or more memory cells in rules. To manipulate their contents safely, locks are required around the shared `bookkeeping' structures that track these cells' states. Section~\ref{sec:data_exchange} explains how our design optimizes for the concurrency of rule-firings by moving the work of interacting with memory cells outside of the critical reason. A consequence of this approach is the occasional need for threads to re-enter the critical region to update the state of a memory cell. For example, the first lock event instigates the rule firing and updates state, but marks memory cell $M$ as `busy' to ensure it cannot be involved in a rule-firing until all data movements outside the critical region have completed. Once done, some thread has the responsibility to mark $M$ as ready once again, necessitating a second lock event.

Future work might investigate more efficient mechanisms for achieving the same effect. As the mechanism is rather intricate, a vast space of possibilities exist. For example, one might investigate the effect of forgoing the second lock-event in favor of leaving a message for a later coordinator to handle. This could take the form of an efficient parallel-queue, highly optimized for the addition of new elements in parallel. More radical changes may also result in superior performance. Perhaps the locking can be avoided entirely if all the data structures representing the protocol's state become lock-free?

\subsection{Runtime Reconfiguration}
Chapter~\ref{sec:behavior_implementation} explains how Reo-rs uses a lightweight interpreter to implement protocol behavior at runtime, reading rules from a dense data structure. A result of this approach is the ability to alter a protocol object's behavior at runtime arbitrarily by manipulating the data representing its rules. Future work might investigate the introduction of a reconfiguration procedure to change the protocol without tearing the instance down or influencing the compute components in motion. The use of an interpreter trivializes the work of manipulating the rules themselves, but care must be taken to change the protocol object's meta-state safely such that it results in a new protocol which is again internally consistent (eg.\ reconfiguring the structures used for primitive concurrency, message channels etc.).

\section{Conclusion}

The chosen design and implementation of a Rust code generator for the Reo compiler achieved satisfactory results. Although our protocol objects were usually slower than hand-written Rust programs, they were competitively performant in the case of non-trivial protocols. This is despite their data-oriented implementation, which has the added benefit of facilitating the reconfiguration of a protocol's behavior at runtime. Exploiting this feature was out of the scope of this project, but provides an entrypoint for interesting future work.

By the nature of Reo, correctness of a protocol object's behavior was always paramount. Still, this work also emphasized performance from its inception, motivating the choice of the Rust language in particular. The hope was to leverage its static ownership system to implement a powerful reference-passing optimization employed by the Java backend, but free from the associated safety problems. However, the Rust compiler was stumped by Reo's interactions transferring values between threads and between scopes. Ultimately, our solution followed the Rust idiom of manually managing ownership within a minimal unsafe scope, and wrapping it in an API that was safe once again. Here, Rust's ownership and mutual-access semantics were invaluable. This was the case for user-facing functionality in general, including that of creating and destroying protocols and ports. In the end, we were able to provide an API with strong, static safety guarantees provided the user does not intentionally circumvent Rust's semantics with unsafe code; a user can neither create nor encounter ill-formed protocol or port objects, and they cannot experience system behavior that contradicts the specification of the protocol (unintentionally or otherwise). Furthermore, our design includes other novel optimizations that result in benefits to the user. For example, protocols function without dedicated threads, increasing performance for sequentially-accessed protocols, and trivializing the detection of a protocol's termination.

Rust's affine type system was instrumental in our design of static governors, which allow a programmer to verify that their components do not threaten the liveness of the system at large. This is done almost entirely at compile-time, catching errors as early as possible, and minimizing runtime overhead. Our design demonstrates how an affine type system is able to communicate powerful correctness guarantees across an API boundary. In our case, we are able to embed a complex requirement `the component does not perform a port-action that contradicts the specification of a stateful protocol' into terms the compiler can understand and enforce: the program type-checks. Users are provided with a means to opt-into tasking their Rust compiler with performing this check, effectively allowing them to extend its verification capabilities with little more than an added library dependency. 


The complexity of the translation procedure from Reo to Rust
proved to be more complex than was expected. The imperative form intermediate representation was added out of necessity to curb the complexity of type-checking and of applying various optimizations without bloating the Reo compiler itself with Rust-specifics. Unexpectedly, the introduction of this new form became integral to our protocol object's design, enabling us to extend its capabilities beyond what was originally intended. When targeting Rust, the Reo compiler supports ergonomic and safe use of more exotic Reo primitives such as \textit{filter} and \textit{transform}, which are able to perform tentative computations as part of synchronous interactions. Imperative form also shows promise as an intermediary step for languages similar to Rust; it is conceivable that existing targets such as Java (or others not yet implemented) can leverage this representation to reduce the work of adding new imperative language targets to the Reo compiler. 

