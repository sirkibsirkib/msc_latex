\chapter{Discussion}
\label{sec:discussion}
\section{Future Work}
\hl{TODO short intro}
\subsection{Imperative Form Compiler}
Chapters~\ref{sec:imperative_form} and~\ref{sec:protocol_runtime} explain how the Reo-rs runtime makes use of a lightweight interpreter to bring life to our protocol objects at runtime according to the appropriate specification. This \textit{commandification} pattern has its advantages; namely, protocol behavior is alterable at runtime by manipulating the interpreted data. However, this flexibility does not come for free. The interpretation steps incur overhead both to the protocol construction procedure, and more importantly, to the work of \textit{port operations}. Fortunately, our \textit{imperative form} does not necessitate the use of an interpreter. Future work could investigate replacing the \code{build} procedure of Reo-rs with another compilation step such that the behavior is represented in native, directly-executable Rust. 

Futhermore, future work might investigate the use of custom \textit{domain specific languages} for compiling imperative form in a manner that it performs the same checking as in \code{build} \textit{statically}. the obvious means of doing this is to build a compiler from scratch. However, other options exist that can make better use of existing tools. For example, Rust's \textit{procedural macros} allow the programmer to define arbitrary transformations of Rust's \textit{abstract syntax trees} during compilation. Essentially, one is able to invoke arbitrary, pre-compiled Rust code \textit{inside} the user's Rust compiler itself. In this manner, one can embed the needed domain-specific language into the Rust compiler itself.

\subsection{Distributed Components}
This work focuses on coordination between threads in shared memory. This approach can already be applied in the context of distributed components by abstracting ports behind local ones. However, we are unable to distribute our protocol components, as they presuppose a single, monolithic shared state in our current scheme. One can get around this by fragmenting protocols into smaller ones, and distributing those smaller protocols across the system. However, this cannot currently be done in all cases, as this fragmentation does not preserve synchrony. 

Reo has a rich academic history in this distributed context. Future work might investigate how our contributions (eg.\ reference-passing optimizations, static governors, etc.) can be applied in distributed systems.


\subsection{Optimize Rule Branching}
\label{sec:future_branches}
Reo-rs is able to represent protocols whose rules contain \textit{branching}. Rule-based form has already shown us the correspondence between our RBA rules and propositional logic, where the formula corresponds to a protocol, with disjuncts as rules~\cite{dokter2018rule}. In the same way such terms can be manipulated until the formula is in \textit{disjunctive normal form}, so too are we able to remove branching from our rules by splitting them. For example, a rule with data constraint $(P_0=C_0\vee{}P_1=C_1)\wedge{}P_2=C_2$ can be converted into two rules with data constraints $P_0=C_0\wedge{}P_2=C_2$ and $P_0=C_0\wedge{}P_2=C_2$ respectively. Such transformations are not particularly meaningful to the outside observer; clearly they have  no influence on the protocol's semantics\footnote{Changing the granularity of rules can be semantically meaningful once it affects our ability to express interesting properties. For example, fine-grained rules can be desirable when the protocol is lifted to consider \textit{preference} between nondeterministic branching.}. However, they do have interesting implications on performance. It is easy to contrive of examples for both extreme ends of the spectrum for which this splitting is either beneficial or detrimental to the performance of the protocol object, as we are able to both introduce and eliminate redundant work by splitting rules. As an example of a rule \textit{not} worth splitting, consider one with very many \textit{instructions} $I$ before reaching a 3-way branch $a\vee{}b\vee{}c$ where the branch is not entirely nondeterministic (ie. there are cases for which $a$ cannot be chosen, etc.). Before splitting, $I$ is computed once, and then one of $\{a,b,c\}$ will occur. After splitting, three separate rules for $a$, $b$, and $c$ might be considered, each computing $I$ before the third fires successfully.

In our case, only the Reo compiler's internals perform manipulations on protocol rules, while Reo-rs restricts itself to the treatment of tautologies and contradictions. Future work might investigate more extensive manipulation of protocol rules to optimize rules by conditionally splitting them to remove branching.

\subsection{Runtime Governors}
Chapter~\ref{sec:api} explains how our design for static protocol governors is able to enforce protocol adherence at compile time. This approach is not always suitable, as it presupposes that we \textit{trust} the compilation process enforcing the governance. If the situation calls for a degree of separation between the compilation process and its use at runtime, this may no longer be a good choice. For example, consider the use of Reo to coordinate peers in a distributed system, where the behavior of a component originates from a remote source, traveling over the network.

Our static governors also have limitations on how finely they can distinguish the states of the protocol. In a perfect world, governors would use perfect models of the protocol's state. Section~\ref{sec:approximating_rba} gives an example of some practical reasons to approximate the protocol instead, resulting in a governor that attempts to strike a non-trivial balance between accuracy and simplicity of its local automaton. \textit{Dynamic} governors are given a far easier task, as they are able to make choices at runtime, when all the relevant information is available. Generally, these governors can therefore be more accurate. Future work might investigate how these two extremes of the spectrum compare, and to what extent it may be practical to use some facets of \textbf{both} to make an application more robust. There may be systems in which redundant checking is worth its cost to runtime performance.

\subsection{Further Runtime Optimization}
Section~\ref{sec:behavior_implementation} discusses various optimizations of Reo-rs's runtime performance applied in this work, chief of which is arguably the use of reference-passing inside the protocol's state as part of the implementation of rules such that it preserves Reo's value-passing semantics. Other optimization opportunities presented themselves during the project, but were not investigated thoroughly as they conflicted with our current goals, or were simply deemed less fruitful than other tasks. Future work might investigate these optimizations:

\begin{enumerate}
	\item Simply rules in the context of a known \textit{priority ordering} on the rules to break nondeterminism. For example, given that rule $r_a$ has priority over rule $r_b$, the satisfaction of these rules must be performed in the same order; if $r_a$ fails, $r_b$ can be simplified such that is \textit{presumes} that $r_a$ did not hold. This may seem particular at first glance, but occurs frequently in practice, particularly when rules are split from branches, as dicussed in Section~\ref{sec:future_branches}. For example, consider rules  with data constraints $M_0=M_1$ and $M_0\neq{}M_1$; if these rules are prioritizes in the order of their appearance here, the second rule can take the negation of the first's data constraint for granted, resulting in the second having a trivial data constraint.
	
	\item stuffed pointers for data types with representations no larger than ptr size. no need for allocator. complicates the refcounter mechanism
	\item imperative form preprocessing. some redundancy exists in how you can represent things. eg: MemSwap sometimes can be achieed just by reorganizing your movements. more examples: pruning check subtries of tautologies and contradictions. this can happen in either reo or reo-rs
\end{enumerate}
\subsection{Avoid Lock Re-Entry}
Section~\ref{sec:chosen_design} motivates the lack of a dedicated coordinator thread to back protocol objects at runtime. As a consequence, port-threads must share the responsibility of manipulating a shared protocol state in accordance with the protocol's movement through its configuration space. Protocols have non-trivial configuration spaces once they involve one or more memory cells in rules. To manipulate their contents safely, \textit{locks} are required around the shared `bookkeeping' structures that track these cells' states. Section~\ref{sec:data_exchange} explains how our design optimizes for the concurrency of rule-firings by moving the work of interacting with memory cells \textit{outside} of the critical reason. A consequence of this approach is the occasional need for threads to \textit{re-enter} the critical region to update the state of a memory cell. For example, the first lock event instigates the rule firing and updates state, but marks memory cell $M$ as `busy' to ensure it cannot be involved in a rule-firing until all \textit{data movements} outside the critical region have completed. Once done, some thread has the responsibility to mark $M$ as ready once again, necessitating a second lock event.

Future work might investigate more efficient mechanisms for achieving the same effect. As the mechanism is rather intricate, a vast space of possibilities exist. For example, one might investigate the effect of forgoing the second lock-event in favor of leaving a message for a later coordinator to handle. This could take the form of an efficient parallel-queue, highly optimized for the addition of new elements in parallel. More radical changes may also result in superior performance. Perhaps the locking can be avoided entirely if all the data structures representing the protocol's state become lock-free?

\subsection{Runtime Reconfiguration}
Chapter~\ref{sec:behavior_implementation} explains how Reo-rs uses a lightweight interpreter to implement protocol behavior at runtime, reading rules from a dense data structure. A result of this approach is the ability to alter a protocol object's behavior at runtime arbitrarily by manipulating the data representing its rules. Future work might investigate the introduction of a reconfiguration procedure to change the protocol without tearing the instance down or influencing the compute components in motion. The use of an interpreter trivializes the work of manipulating the rules themselves, but care must be taken to change the protocol object's \textit{meta-state} safely such that it results in a new protocol which is again internally consistent (eg.\ reconfiguring the structures used for primitive concurrency, message channels etc.).

\section{Conclusion}
\hl{TODO}